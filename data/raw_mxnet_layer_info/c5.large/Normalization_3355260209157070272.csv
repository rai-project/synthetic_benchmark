"model_name","layer_name","layer_index","kind","min_time","mean_time","max_time","add_flops","div_flops","cmp_flops","exp_flops","mad_flops","input_channel","input_height","input_width","output_channel","output_height","output_width","function","kernel_1","kernel_2","stride_1","stride_2","dilation_1","dilation_2","input_form","topology_hash","mad/min_time","mad/mean_time","mad/max_time","time"
"BERT Trained on BookCorpus and English Wikipedia Data","encoder/11/1/norm",785,"Normalization",0.000158,0.00016003333333333328,0.000212,"768*LengthVar[2035700533]","1536*LengthVar[2035700533]",0,"768*LengthVar[2035700533]","1536*LengthVar[2035700533]","LengthVar[2035700533]",768,"","LengthVar[2035700533]",768,"","","","","","","","","HoldForm[NormalizationLayer[""Same"", ""Epsilon"" -> 1.*^-12, ""Input"" -> {""Varying"", 768}]]","0f271m8kvd2l1","9.721518987341773*^6*LengthVar[2.035700533*^9]","9.598000416579884*^6*LengthVar[2.035700533*^9]","7.245283018867925*^6*LengthVar[2.035700533*^9]","{0.000212, 0.000163, 0.00016, 0.00016, 0.00016, 0.000159, 0.000159, 0.000174, 0.00016, 0.000181, 0.000163, 0.000159, 0.00016, 0.000158, 0.000172, 0.000164, 0.000159, 0.000163, 0.000158, 0.000159, 0.000159, 0.000159, 0.000159, 0.00016, 0.00016, 0.00016, 0.000158, 0.000159, 0.000161, 0.000159, 0.000161, 0.000159, 0.000162, 0.00016, 0.000179, 0.000165, 0.000159, 0.000161, 0.00016, 0.000158, 0.000159, 0.00016, 0.00016, 0.000161, 0.00016, 0.000161, 0.000159, 0.000159, 0.00016, 0.000175}"
