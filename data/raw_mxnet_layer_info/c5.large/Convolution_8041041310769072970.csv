"model_name","layer_name","layer_index","kind","min_time","mean_time","max_time","add_flops","div_flops","cmp_flops","exp_flops","mad_flops","input_channel","input_height","input_width","output_channel","output_height","output_width","function","kernel_1","kernel_2","stride_1","stride_2","dilation_1","dilation_2","input_form","topology_hash","mad/min_time","mad/mean_time","mad/max_time","time"
"CycleGAN Apple-to-Orange Translation Trained on ImageNet Competition Data","14/1/2",29,"Convolution",0.024478,0.02593673333333333,0.037034,0,0,0,0,603979776,128,66,66,128,64,64,"",3,3,1,1,1,1,"HoldForm[ConvolutionLayer[128, {3, 3}, ""Stride"" -> {1, 1}, ""PaddingSize"" -> {{0, 0}, {0, 0}}, ""Dilation"" -> {1, 1}, ""Input"" -> {128, 66, 66}]]","1sehkke39v8fh",2.4674392352316364e10,2.328665557985971e10,1.6308791272884378e10,"{0.037034, 0.028642, 0.026176, 0.027043, 0.026269, 0.025469, 0.02548, 0.024854, 0.026196, 0.026836, 0.025335, 0.025481, 0.027085, 0.027033, 0.026478, 0.027126, 0.026171, 0.025858, 0.026685, 0.026432, 0.025465, 0.02541, 0.025343, 0.025852, 0.025243, 0.025913, 0.02492, 0.02549, 0.024478, 0.025159, 0.025412, 0.025638, 0.026115, 0.025691, 0.02621, 0.026126, 0.024902, 0.024679, 0.025194, 0.026253, 0.026884, 0.026455, 0.028187, 0.025859, 0.024985, 0.02521, 0.025993, 0.026712, 0.026135, 0.027748}"
