"model_name","layer_name","layer_index","kind","min_time","mean_time","max_time","add_flops","div_flops","cmp_flops","exp_flops","mad_flops","input_channel","input_height","input_width","output_channel","output_height","output_width","function","kernel_1","kernel_2","stride_1","stride_2","dilation_1","dilation_2","input_form","topology_hash","mad/min_time","mad/mean_time","mad/max_time","time"
"CycleGAN Orange-to-Apple Translation Trained on ImageNet Competition Data","30",93,"Convolution",0.16265,0.1633068666666667,0.337881,0,0,0,0,308281344,32,262,262,3,256,256,"",7,7,1,1,1,1,"HoldForm[ConvolutionLayer[3, {7, 7}, ""Stride"" -> {1, 1}, ""PaddingSize"" -> {{0, 0}, {0, 0}}, ""Dilation"" -> {1, 1}, ""Input"" -> {32, 262, 262}]]","1uqm0tin4upbx",1.895366394097756e9,1.8877426913667233e9,9.123962105001465e8,"{0.337881, 0.163116, 0.162939, 0.163064, 0.163172, 0.163238, 0.164015, 0.163264, 0.163919, 0.164551, 0.164139, 0.163208, 0.162855, 0.163397, 0.163431, 0.16307, 0.163662, 0.163085, 0.163899, 0.163331, 0.163442, 0.163003, 0.163241, 0.163565, 0.163416, 0.16355, 0.163128, 0.163034, 0.163086, 0.165427, 0.163671, 0.162961, 0.163311, 0.163177, 0.163518, 0.162993, 0.163752, 0.16265, 0.163399, 0.163149, 0.163099, 0.164234, 0.163659, 0.163052, 0.163089, 0.163532, 0.163112, 0.163247, 0.163512, 0.162877}"
