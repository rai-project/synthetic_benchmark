"model_name","layer_name","layer_index","kind","min_time","mean_time","max_time","add_flops","div_flops","cmp_flops","exp_flops","mad_flops","input_channel","input_height","input_width","output_channel","output_height","output_width","function","kernel_1","kernel_2","stride_1","stride_2","dilation_1","dilation_2","input_form","topology_hash","mad/min_time","mad/mean_time","mad/max_time","time"
"GPT-2 Transformer Trained on WebText Data","decoder/10/1/attention/11/value/Net",680,"Linear",0.00007,0.00007056666666666668,0.000104,0,0,0,0,49152,768,"","",64,"","","","","","","","","","HoldForm[LinearLayer[{64}, ""Input"" -> 768]]","1ar66gqblf480",7.021714285714285e8,6.96532829475673e8,4.726153846153846e8,"{0.000104, 0.00008, 0.000074, 0.000073, 0.000071, 0.000072, 0.00007, 0.000072, 0.000071, 0.00007, 0.000071, 0.000072, 0.000095, 0.000076, 0.000071, 0.000071, 0.00007, 0.00007, 0.00007, 0.00007, 0.00007, 0.00007, 0.00007, 0.000071, 0.000072, 0.000071, 0.000071, 0.000071, 0.00007, 0.00007, 0.00007, 0.000071, 0.00007, 0.00007, 0.000071, 0.00007, 0.000071, 0.00007, 0.000071, 0.000071, 0.00007, 0.000071, 0.00007, 0.000071, 0.00007, 0.00007, 0.00007, 0.00007, 0.00007, 0.000071}"
