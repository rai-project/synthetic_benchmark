"model_name","layer_name","layer_index","kind","min_time","mean_time","max_time","add_flops","div_flops","cmp_flops","exp_flops","mad_flops","input_channel","input_height","input_width","output_channel","output_height","output_width","function","kernel_1","kernel_2","stride_1","stride_2","dilation_1","dilation_2","input_form","topology_hash","mad/min_time","mad/mean_time","mad/max_time","time"
"GPT Transformer Trained on BookCorpus Data","decoder/8/1/attention/7/query/Net",534,"Linear",0.000042,0.000043299999999999995,0.000088,0,0,0,0,49152,768,"","",64,"","","","","","","","","","HoldForm[LinearLayer[{64}, ""Input"" -> 768]]","1ar66gqblf480",1.1702857142857141e9,1.1351501154734411e9,5.585454545454545e8,"{0.000078, 0.000051, 0.000045, 0.000044, 0.000044, 0.000044, 0.000043, 0.000043, 0.000043, 0.000043, 0.000043, 0.000043, 0.000043, 0.000044, 0.000043, 0.000043, 0.000043, 0.000043, 0.000043, 0.000044, 0.000043, 0.000088, 0.000048, 0.000045, 0.000043, 0.000044, 0.000044, 0.000043, 0.000043, 0.000043, 0.000044, 0.000044, 0.000043, 0.000044, 0.000043, 0.000043, 0.000043, 0.000043, 0.000043, 0.000043, 0.000042, 0.000043, 0.000044, 0.000043, 0.000044, 0.000043, 0.000044, 0.000043, 0.000043, 0.000043}"
