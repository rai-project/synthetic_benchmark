"model_name","layer_name","layer_index","kind","min_time","mean_time","max_time","add_flops","div_flops","cmp_flops","exp_flops","mad_flops","input_channel","input_height","input_width","output_channel","output_height","output_width","function","kernel_1","kernel_2","stride_1","stride_2","dilation_1","dilation_2","input_form","topology_hash","mad/min_time","mad/mean_time","mad/max_time","time"
"GPT Transformer Trained on BookCorpus Data","decoder/4/1/attention/14/Net",280,"Linear",0.000097,0.00009889999999999998,0.000155,0,0,0,0,589824,768,"","",768,"","","","","","","","","","HoldForm[LinearLayer[{768}, ""Input"" -> 768]]","1i4k7z9majhj6",6.080659793814433e9,5.963842264914056e9,3.805316129032258e9,"{0.000155, 0.000104, 0.0001, 0.000099, 0.0001, 0.000098, 0.0001, 0.000101, 0.000098, 0.000098, 0.000098, 0.000097, 0.000099, 0.0001, 0.000098, 0.000099, 0.000098, 0.000099, 0.000098, 0.000098, 0.000097, 0.000097, 0.000097, 0.000097, 0.000097, 0.000098, 0.0001, 0.000099, 0.000097, 0.000097, 0.000099, 0.000101, 0.000124, 0.000106, 0.000099, 0.000101, 0.000098, 0.000098, 0.0001, 0.000099, 0.000098, 0.0001, 0.000098, 0.000099, 0.0001, 0.0001, 0.000101, 0.000099, 0.000099, 0.0001}"
