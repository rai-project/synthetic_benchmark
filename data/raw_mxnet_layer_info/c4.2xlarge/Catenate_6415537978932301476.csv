"model_name","layer_name","layer_index","kind","min_time","mean_time","max_time","add_flops","div_flops","cmp_flops","exp_flops","mad_flops","input_channel","input_height","input_width","output_channel","output_height","output_width","function","kernel_1","kernel_2","stride_1","stride_2","dilation_1","dilation_2","input_form","topology_hash","mad/min_time","mad/mean_time","mad/max_time","time"
"GPT Transformer Trained on BookCorpus Data","decoder/12/1/attention/13",847,"Catenate",0.000091,0.00009233333333333337,0.000124,0,0,0,0,0,"LengthVar[1992007275]",64,"","LengthVar[1992007275]",768,"","","","","","","","","HoldForm[CatenateLayer[2, ""Inputs"" -> {{""Varying"", 64}, {""Varying"", 64}, {""Varying"", 64}, {""Varying"", 64}, {""Varying"", 64}, {""Varying"", 64}, {""Varying"", 64}, {""Varying"", 64}, {""Varying"", 64}, {""Varying"", 64}, {""Varying"", 64}, {""Varying"", 64}}]]","13w9264xf7gd2",0.,0.,0.,"{0.000124, 0.000098, 0.000093, 0.000094, 0.000093, 0.000093, 0.000094, 0.000093, 0.000093, 0.000093, 0.000092, 0.000092, 0.000092, 0.000121, 0.000094, 0.000092, 0.000092, 0.000092, 0.000093, 0.000093, 0.000093, 0.000092, 0.000102, 0.000095, 0.000094, 0.000093, 0.000092, 0.000091, 0.000091, 0.000092, 0.000092, 0.000092, 0.000092, 0.000091, 0.000091, 0.000091, 0.000092, 0.000092, 0.000092, 0.000091, 0.000091, 0.000092, 0.000092, 0.000092, 0.000092, 0.000092, 0.000092, 0.000093, 0.000091, 0.000091}"
