"model_name","layer_name","layer_index","kind","min_time","mean_time","max_time","add_flops","div_flops","cmp_flops","exp_flops","mad_flops","input_channel","input_height","input_width","output_channel","output_height","output_width","function","kernel_1","kernel_2","stride_1","stride_2","dilation_1","dilation_2","input_form","topology_hash","mad/min_time","mad/mean_time","mad/max_time","time"
"BERT Trained on BookCorpus and English Wikipedia Data","encoder/11/1/norm",785,"Normalization",0.000188,0.00018913333333333331,0.000222,"768*LengthVar[1839090464]","1536*LengthVar[1839090464]",0,"768*LengthVar[1839090464]","1536*LengthVar[1839090464]","LengthVar[1839090464]",768,"","LengthVar[1839090464]",768,"","","","","","","","","HoldForm[NormalizationLayer[""Same"", ""Epsilon"" -> 1.*^-12, ""Input"" -> {""Varying"", 768}]]","0f271m8kvd2l1","8.170212765957448*^6*LengthVar[1.839090464*^9]","8.121254846669016*^6*LengthVar[1.839090464*^9]","6.918918918918919*^6*LengthVar[1.839090464*^9]","{0.000222, 0.000193, 0.00019, 0.000189, 0.000211, 0.000198, 0.000189, 0.000188, 0.00019, 0.000188, 0.000189, 0.000189, 0.000189, 0.000189, 0.000188, 0.000188, 0.000189, 0.000188, 0.000189, 0.000189, 0.000189, 0.000189, 0.000189, 0.000189, 0.000189, 0.000209, 0.000197, 0.00019, 0.000189, 0.000189, 0.000189, 0.000189, 0.000188, 0.000189, 0.000189, 0.000189, 0.000189, 0.000188, 0.000189, 0.000188, 0.000189, 0.000188, 0.000193, 0.000194, 0.000189, 0.00019, 0.000206, 0.000197, 0.000189, 0.000189}"
