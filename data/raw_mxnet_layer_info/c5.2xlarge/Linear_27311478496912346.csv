"model_name","layer_name","layer_index","kind","min_time","mean_time","max_time","add_flops","div_flops","cmp_flops","exp_flops","mad_flops","input_channel","input_height","input_width","output_channel","output_height","output_width","function","kernel_1","kernel_2","stride_1","stride_2","dilation_1","dilation_2","input_form","topology_hash","mad/min_time","mad/mean_time","mad/max_time","time"
"BERT Trained on BookCorpus and English Wikipedia Data","encoder/10/1/attention/8/key/Net",685,"Linear",0.00002,0.000020600000000000006,0.000062,0,0,0,0,49152,768,"","",64,"","","","","","","","","","HoldForm[LinearLayer[{64}, ""Input"" -> 768]]","1ar66gqblf480",2.4575999999999995e9,2.3860194174757276e9,7.92774193548387e8,"{0.000057, 0.000024, 0.000022, 0.000021, 0.00002, 0.000021, 0.000021, 0.000021, 0.00002, 0.000021, 0.000021, 0.00002, 0.00002, 0.00002, 0.000021, 0.00002, 0.00002, 0.000021, 0.000021, 0.00002, 0.00002, 0.00002, 0.00002, 0.00002, 0.000021, 0.000021, 0.000021, 0.000021, 0.00002, 0.000021, 0.000021, 0.000021, 0.00002, 0.000062, 0.000023, 0.00002, 0.000036, 0.000021, 0.00002, 0.00002, 0.000021, 0.000031, 0.000021, 0.00002, 0.00002, 0.00002, 0.00002, 0.00002, 0.000021, 0.000021}"
