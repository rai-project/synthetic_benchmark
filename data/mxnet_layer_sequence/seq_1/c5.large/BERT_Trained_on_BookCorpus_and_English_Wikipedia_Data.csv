"model_name","instance_type","start_index","end_index","sequence_length","num_runs","start_name","end_name","sequence_name","start_layer_kind","end_layer_kind","sequence_layer_kind","start_layer_path_time","mean_path_time","end_layer_path_time","raw_path_time"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",1,2,1,50,"embedding/part1","embedding/embeddingtokens","embedding/part1-embedding/embeddingtokens","Part","Embedding","Part-Embedding",19.,19.1,684.,"{684., 42., 21., 20., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 31., 20., 19., 19., 19., 19., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",3,4,1,50,"embedding/posembed","embedding/embeddingpos","embedding/posembed-embedding/embeddingpos","SequenceIndices","Embedding","SequenceIndices-Embedding",27.,28.1,785.,"{785., 37., 30., 29., 28., 28., 28., 28., 29., 28., 28., 28., 28., 28., 28., 28., 29., 28., 28., 28., 31., 29., 28., 28., 28., 28., 28., 29., 28., 28., 28., 28., 28., 28., 29., 28., 28., 28., 28., 28., 28., 29., 29., 28., 27., 28., 28., 29., 28., 28.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",5,6,1,50,"embedding/part2","embedding/Clip","embedding/part2-embedding/Clip","Part","Elementwise","Part-Elementwise",18.,18.5667,45.,"{45., 21., 19., 18., 19., 18., 20., 18., 19., 18., 18., 19., 19., 18., 18., 19., 18., 18., 18., 19., 19., 19., 19., 19., 19., 18., 18., 18., 18., 18., 19., 19., 19., 19., 19., 19., 18., 18., 18., 19., 19., 19., 18., 18., 18., 18., 19., 19., 19., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",7,7,0,50,"embedding/embeddingsegments","embedding/embeddingsegments","embedding/embeddingsegments","Embedding","Embedding","Embedding",18.,18.8333,47.,"{47., 22., 20., 19., 19., 18., 21., 19., 19., 19., 19., 19., 19., 18., 19., 18., 19., 19., 18., 19., 18., 19., 19., 18., 19., 18., 19., 19., 19., 18., 18., 19., 19., 18., 19., 18., 19., 20., 19., 19., 19., 19., 19., 18., 19., 18., 19., 18., 19., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",8,9,1,50,"embedding/inputCombine","embedding/normalize","embedding/inputCombine-embedding/normalize","Threading","Normalization","Threading-Normalization",163.,164.8667,1841.,"{1841., 182., 167., 165., 166., 165., 164., 188., 173., 165., 165., 165., 164., 164., 164., 164., 164., 164., 166., 166., 181., 169., 165., 164., 166., 163., 164., 164., 163., 165., 200., 167., 164., 164., 164., 165., 166., 163., 164., 165., 165., 165., 168., 172., 165., 164., 163., 164., 165., 164.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",10,10,0,50,"embedding/dropout","embedding/dropout","embedding/dropout","Dropout","Dropout","Dropout",18.,18.,41.,"{41., 21., 19., 19., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",11,11,0,50,"encoder/1/1/attention/1/key/Net","encoder/1/1/attention/1/key/Net","encoder/1/1/attention/1/key/Net","Linear","Linear","Linear",21.,23.900000000000002,72.,"{72., 33., 29., 23., 21., 21., 21., 21., 21., 22., 22., 21., 21., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 26., 35., 32., 21., 33., 24., 24., 24., 23., 24., 24., 24., 23., 25., 24., 26.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",12,12,0,50,"encoder/1/1/attention/1/query/Net","encoder/1/1/attention/1/query/Net","encoder/1/1/attention/1/query/Net","Linear","Linear","Linear",21.,23.3667,62.,"{62., 33., 29., 22., 22., 22., 22., 22., 21., 22., 22., 21., 22., 22., 22., 21., 22., 22., 21., 22., 22., 21., 21., 22., 34., 24., 25., 25., 24., 24., 24., 35., 25., 25., 24., 24., 24., 25., 24., 24., 24., 25., 24., 24., 24., 25., 24., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",13,13,0,50,"encoder/1/1/attention/1/elem","encoder/1/1/attention/1/elem","encoder/1/1/attention/1/elem","Elementwise","Elementwise","Elementwise",18.,18.400000000000002,465.,"{465., 24., 19., 19., 18., 19., 18., 19., 19., 18., 19., 19., 19., 19., 18., 19., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 19., 19., 18., 19., 19., 18., 18., 18., 19., 18., 18., 18., 19., 18., 19., 19., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",14,14,0,50,"encoder/1/1/attention/1/value/Net","encoder/1/1/attention/1/value/Net","encoder/1/1/attention/1/value/Net","Linear","Linear","Linear",22.,24.,60.,"{60., 32., 22., 22., 22., 34., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 23., 24., 25., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",15,15,0,50,"encoder/1/1/attention/1/attention/ScoringNet/1","encoder/1/1/attention/1/attention/ScoringNet/1","encoder/1/1/attention/1/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.4667,392.,"{392., 26., 20., 20., 19., 19., 19., 20., 20., 19., 20., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 20., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",16,16,0,50,"encoder/1/1/attention/2/key/Net","encoder/1/1/attention/2/key/Net","encoder/1/1/attention/2/key/Net","Linear","Linear","Linear",21.,24.3667,59.,"{59., 32., 29., 29., 35., 25., 24., 25., 24., 24., 24., 24., 25., 24., 24., 25., 24., 24., 24., 32., 32., 24., 26., 24., 26., 23., 32., 21., 22., 21., 22., 21., 21., 33., 24., 32., 24., 26., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",17,17,0,50,"encoder/1/1/attention/2/query/Net","encoder/1/1/attention/2/query/Net","encoder/1/1/attention/2/query/Net","Linear","Linear","Linear",22.,26.6,64.,"{57., 32., 25., 30., 29., 30., 29., 22., 29., 22., 40., 24., 31., 33., 32., 25., 24., 25., 25., 24., 32., 25., 24., 24., 25., 25., 25., 25., 24., 26., 32., 33., 24., 32., 25., 25., 31., 32., 25., 25., 26., 26., 24., 24., 24., 24., 31., 27., 23., 64.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",18,18,0,50,"encoder/1/1/attention/2/elem","encoder/1/1/attention/2/elem","encoder/1/1/attention/2/elem","Elementwise","Elementwise","Elementwise",18.,18.2333,41.,"{41., 22., 19., 19., 19., 18., 18., 18., 19., 18., 19., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 19., 19., 19., 18., 18., 18., 18., 18., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",19,19,0,50,"encoder/1/1/attention/2/value/Net","encoder/1/1/attention/2/value/Net","encoder/1/1/attention/2/value/Net","Linear","Linear","Linear",21.,27.8,68.,"{68., 33., 30., 29., 28., 29., 22., 28., 29., 23., 21., 21., 24., 32., 24., 24., 33., 33., 24., 24., 32., 24., 24., 26., 31., 33., 32., 25., 31., 25., 31., 32., 33., 33., 25., 24., 25., 31., 25., 32., 25., 24., 24., 32., 25., 31., 25., 31., 25., 36.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",20,20,0,50,"encoder/1/1/attention/2/attention/ScoringNet/1","encoder/1/1/attention/2/attention/ScoringNet/1","encoder/1/1/attention/2/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3333,44.,"{44., 34., 20., 19., 20., 20., 19., 20., 19., 19., 19., 20., 19., 20., 19., 19., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",21,21,0,50,"encoder/1/1/attention/3/key/Net","encoder/1/1/attention/3/key/Net","encoder/1/1/attention/3/key/Net","Linear","Linear","Linear",21.,23.700000000000003,48.,"{48., 36., 35., 32., 25., 24., 24., 25., 24., 24., 24., 24., 48., 29., 32., 25., 25., 33., 25., 24., 24., 24., 25., 24., 25., 24., 24., 24., 24., 32., 21., 21., 21., 22., 21., 22., 22., 21., 22., 21., 22., 21., 22., 21., 22., 22., 21., 22., 35., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",22,22,0,50,"encoder/1/1/attention/3/query/Net","encoder/1/1/attention/3/query/Net","encoder/1/1/attention/3/query/Net","Linear","Linear","Linear",21.,24.4667,58.,"{58., 32., 29., 22., 22., 21., 23., 22., 21., 22., 21., 21., 34., 24., 24., 24., 24., 26., 24., 24., 23., 25., 25., 24., 24., 32., 32., 33., 33., 25., 24., 25., 24., 38., 23., 32., 22., 21., 21., 58., 27., 24., 24., 24., 24., 25., 26., 24., 25., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",23,23,0,50,"encoder/1/1/attention/3/elem","encoder/1/1/attention/3/elem","encoder/1/1/attention/3/elem","Elementwise","Elementwise","Elementwise",18.,18.400000000000002,40.,"{39., 22., 19., 18., 19., 19., 19., 18., 18., 19., 18., 18., 19., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 19., 19., 19., 19., 18., 19., 19., 18., 19., 19., 18., 18., 18., 18., 19., 19., 18., 18., 18., 40., 20., 18., 18., 18., 18., 18., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",24,24,0,50,"encoder/1/1/attention/3/value/Net","encoder/1/1/attention/3/value/Net","encoder/1/1/attention/3/value/Net","Linear","Linear","Linear",21.,25.6,66.,"{59., 32., 30., 29., 22., 28., 22., 29., 29., 23., 28., 28., 22., 22., 28., 29., 22., 28., 21., 21., 22., 21., 21., 21., 21., 22., 45., 31., 29., 36., 24., 24., 24., 24., 24., 32., 25., 24., 24., 25., 24., 25., 24., 25., 24., 24., 66., 34., 32., 32.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",25,25,0,50,"encoder/1/1/attention/3/attention/ScoringNet/1","encoder/1/1/attention/3/attention/ScoringNet/1","encoder/1/1/attention/3/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3333,44.,"{44., 35., 20., 20., 19., 19., 20., 20., 19., 19., 20., 20., 19., 19., 20., 19., 20., 19., 20., 20., 24., 20., 19., 20., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",26,26,0,50,"encoder/1/1/attention/4/key/Net","encoder/1/1/attention/4/key/Net","encoder/1/1/attention/4/key/Net","Linear","Linear","Linear",21.,24.2667,59.,"{59., 27., 24., 22., 22., 22., 23., 22., 22., 33., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 36., 33., 37., 32., 21., 32., 30., 29., 22., 33., 24., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",27,27,0,50,"encoder/1/1/attention/4/query/Net","encoder/1/1/attention/4/query/Net","encoder/1/1/attention/4/query/Net","Linear","Linear","Linear",21.,23.8333,58.,"{58., 31., 23., 29., 23., 23., 22., 29., 29., 22., 23., 21., 22., 22., 23., 28., 28., 22., 21., 29., 22., 28., 22., 23., 21., 28., 22., 22., 22., 28., 22., 22., 21., 34., 24., 24., 23., 34., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",28,28,0,50,"encoder/1/1/attention/4/elem","encoder/1/1/attention/4/elem","encoder/1/1/attention/4/elem","Elementwise","Elementwise","Elementwise",18.,18.,40.,"{40., 22., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 21., 21., 19., 18., 18., 27., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",29,29,0,50,"encoder/1/1/attention/4/value/Net","encoder/1/1/attention/4/value/Net","encoder/1/1/attention/4/value/Net","Linear","Linear","Linear",24.,27.8333,48.,"{48., 32., 29., 33., 32., 25., 25., 25., 24., 24., 24., 24., 32., 32., 33., 25., 25., 32., 32., 25., 25., 24., 32., 33., 33., 32., 32., 25., 32., 32., 25., 24., 24., 24., 24., 24., 26., 31., 33., 32., 25., 24., 24., 25., 32., 33., 32., 25., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",30,30,0,50,"encoder/1/1/attention/4/attention/ScoringNet/1","encoder/1/1/attention/4/attention/ScoringNet/1","encoder/1/1/attention/4/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3333,46.,"{46., 22., 20., 20., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 20., 20., 19., 44., 21., 19., 19., 20., 19., 20., 28., 20., 20., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",31,31,0,50,"encoder/1/1/attention/5/key/Net","encoder/1/1/attention/5/key/Net","encoder/1/1/attention/5/key/Net","Linear","Linear","Linear",20.,21.,59.,"{59., 32., 29., 29., 22., 21., 22., 21., 21., 21., 22., 21., 21., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 20., 21., 21., 21., 21., 21., 21., 21., 21., 22., 21., 21., 21., 22.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",32,32,0,50,"encoder/1/1/attention/5/query/Net","encoder/1/1/attention/5/query/Net","encoder/1/1/attention/5/query/Net","Linear","Linear","Linear",23.,24.,58.,"{58., 36., 27., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 52., 35., 27., 24., 24., 24., 24., 24., 23., 24., 24., 23., 24., 24., 24., 24., 23., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",33,33,0,50,"encoder/1/1/attention/5/elem","encoder/1/1/attention/5/elem","encoder/1/1/attention/5/elem","Elementwise","Elementwise","Elementwise",18.,18.1,40.,"{40., 22., 19., 18., 18., 18., 18., 18., 18., 19., 18., 19., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 19., 18., 19., 19., 18., 19., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",34,34,0,50,"encoder/1/1/attention/5/value/Net","encoder/1/1/attention/5/value/Net","encoder/1/1/attention/5/value/Net","Linear","Linear","Linear",21.,23.0667,58.,"{58., 25., 22., 22., 21., 28., 23., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 22., 21., 21., 33., 24., 24., 24., 23., 24., 24., 24., 24., 24., 23., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",35,35,0,50,"encoder/1/1/attention/5/attention/ScoringNet/1","encoder/1/1/attention/5/attention/ScoringNet/1","encoder/1/1/attention/5/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2,44.,"{44., 22., 20., 20., 19., 20., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 20., 20., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",36,36,0,50,"encoder/1/1/attention/6/key/Net","encoder/1/1/attention/6/key/Net","encoder/1/1/attention/6/key/Net","Linear","Linear","Linear",21.,28.666700000000002,59.,"{59., 33., 30., 24., 28., 28., 22., 21., 22., 28., 23., 21., 28., 29., 30., 23., 22., 54., 30., 32., 33., 26., 32., 26., 24., 24., 32., 32., 25., 24., 24., 32., 26., 31., 24., 32., 33., 32., 33., 32., 33., 32., 24., 24., 31., 25., 32., 31., 32., 38.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",37,37,0,50,"encoder/1/1/attention/6/query/Net","encoder/1/1/attention/6/query/Net","encoder/1/1/attention/6/query/Net","Linear","Linear","Linear",21.,26.3667,66.,"{58., 31., 24., 21., 22., 22., 28., 28., 28., 22., 28., 29., 22., 21., 28., 21., 28., 23., 28., 22., 28., 23., 21., 28., 22., 28., 23., 28., 22., 32., 24., 32., 24., 31., 32., 32., 32., 32., 25., 23., 32., 26., 66., 35., 32., 25., 25., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",38,38,0,50,"encoder/1/1/attention/6/elem","encoder/1/1/attention/6/elem","encoder/1/1/attention/6/elem","Elementwise","Elementwise","Elementwise",17.,18.,42.,"{39., 21., 18., 18., 18., 18., 18., 19., 19., 19., 18., 18., 18., 18., 18., 19., 33., 42., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",39,39,0,50,"encoder/1/1/attention/6/value/Net","encoder/1/1/attention/6/value/Net","encoder/1/1/attention/6/value/Net","Linear","Linear","Linear",21.,23.7333,58.,"{58., 32., 22., 28., 22., 22., 21., 43., 30., 22., 21., 22., 29., 29., 29., 28., 22., 21., 22., 21., 21., 21., 21., 32., 24., 24., 24., 24., 24., 23., 24., 24., 24., 23., 24., 24., 24., 23., 24., 24., 24., 23., 24., 24., 25., 35., 32., 22., 21., 23.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",40,40,0,50,"encoder/1/1/attention/6/attention/ScoringNet/1","encoder/1/1/attention/6/attention/ScoringNet/1","encoder/1/1/attention/6/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3,44.,"{44., 23., 20., 20., 20., 19., 19., 20., 19., 19., 19., 20., 19., 20., 19., 19., 19., 19., 20., 19., 19., 20., 40., 21., 19., 20., 19., 20., 19., 19., 19., 19., 19., 19., 20., 20., 19., 19., 19., 19., 19., 20., 20., 19., 20., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",41,41,0,50,"encoder/1/1/attention/7/key/Net","encoder/1/1/attention/7/key/Net","encoder/1/1/attention/7/key/Net","Linear","Linear","Linear",21.,25.2667,59.,"{59., 31., 29., 22., 29., 23., 22., 49., 30., 30., 28., 23., 22., 21., 23., 22., 28., 29., 29., 28., 28., 28., 28., 22., 21., 21., 28., 22., 21., 28., 30., 28., 23., 28., 22., 21., 28., 23., 21., 21., 21., 21., 22., 28., 29., 28., 29., 23., 22., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",42,42,0,50,"encoder/1/1/attention/7/query/Net","encoder/1/1/attention/7/query/Net","encoder/1/1/attention/7/query/Net","Linear","Linear","Linear",21.,27.7667,58.,"{58., 32., 43., 32., 33., 32., 26., 24., 24., 24., 24., 32., 33., 26., 24., 31., 34., 25., 32., 26., 32., 32., 33., 32., 31., 24., 26., 24., 24., 25., 24., 31., 25., 32., 26., 24., 24., 24., 31., 37., 39., 22., 21., 28., 29., 23., 27., 28., 23., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",43,43,0,50,"encoder/1/1/attention/7/elem","encoder/1/1/attention/7/elem","encoder/1/1/attention/7/elem","Elementwise","Elementwise","Elementwise",18.,18.0667,38.,"{38., 21., 19., 18., 18., 19., 19., 19., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",44,44,0,50,"encoder/1/1/attention/7/value/Net","encoder/1/1/attention/7/value/Net","encoder/1/1/attention/7/value/Net","Linear","Linear","Linear",21.,25.433300000000003,48.,"{47., 31., 23., 29., 22., 22., 21., 34., 24., 24., 23., 24., 32., 24., 32., 25., 24., 24., 31., 25., 31., 25., 31., 26., 24., 23., 24., 24., 25., 24., 24., 31., 26., 24., 24., 24., 24., 24., 24., 24., 24., 48., 34., 26., 36., 32., 22., 21., 21., 34.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",45,45,0,50,"encoder/1/1/attention/7/attention/ScoringNet/1","encoder/1/1/attention/7/attention/ScoringNet/1","encoder/1/1/attention/7/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.433300000000003,43.,"{43., 23., 21., 22., 20., 20., 19., 20., 19., 20., 27., 20., 20., 19., 19., 19., 20., 19., 20., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 19., 19., 20., 20., 19., 20., 19., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",46,46,0,50,"encoder/1/1/attention/8/key/Net","encoder/1/1/attention/8/key/Net","encoder/1/1/attention/8/key/Net","Linear","Linear","Linear",24.,25.433300000000003,49.,"{48., 32., 30., 29., 29., 43., 33., 26., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 34., 32., 33., 32., 32., 32., 33., 25., 49., 27., 24., 24., 24., 24., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",47,47,0,50,"encoder/1/1/attention/8/query/Net","encoder/1/1/attention/8/query/Net","encoder/1/1/attention/8/query/Net","Linear","Linear","Linear",21.,24.,53.,"{47., 32., 29., 23., 28., 24., 21., 34., 24., 35., 27., 24., 24., 24., 24., 23., 24., 24., 53., 34., 25., 24., 24., 24., 24., 23., 24., 24., 23., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 23., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",48,48,0,50,"encoder/1/1/attention/8/elem","encoder/1/1/attention/8/elem","encoder/1/1/attention/8/elem","Elementwise","Elementwise","Elementwise",18.,18.,39.,"{39., 21., 18., 19., 19., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",49,49,0,50,"encoder/1/1/attention/8/value/Net","encoder/1/1/attention/8/value/Net","encoder/1/1/attention/8/value/Net","Linear","Linear","Linear",21.,23.5667,47.,"{47., 31., 30., 29., 24., 22., 21., 21., 32., 25., 24., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 33., 21., 21., 21., 22., 21., 21., 21., 21., 21., 29., 29., 23., 21., 21., 22.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",50,50,0,50,"encoder/1/1/attention/8/attention/ScoringNet/1","encoder/1/1/attention/8/attention/ScoringNet/1","encoder/1/1/attention/8/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.133300000000002,45.,"{45., 23., 20., 20., 19., 20., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 20., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",51,51,0,50,"encoder/1/1/attention/9/key/Net","encoder/1/1/attention/9/key/Net","encoder/1/1/attention/9/key/Net","Linear","Linear","Linear",21.,23.5667,48.,"{48., 32., 24., 22., 22., 21., 21., 22., 22., 21., 22., 22., 21., 35., 33., 25., 26., 32., 25., 32., 25., 25., 25., 24., 25., 24., 24., 24., 24., 24., 24., 33., 25., 25., 35., 33., 23., 22., 22., 21., 22., 21., 22., 21., 21., 21., 22., 21., 33., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",52,52,0,50,"encoder/1/1/attention/9/query/Net","encoder/1/1/attention/9/query/Net","encoder/1/1/attention/9/query/Net","Linear","Linear","Linear",21.,26.466700000000003,62.,"{47., 43., 22., 29., 31., 30., 22., 22., 21., 22., 22., 21., 21., 34., 24., 24., 33., 25., 33., 25., 32., 25., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24., 24., 31., 32., 33., 26., 32., 34., 25., 62., 37., 46., 34., 25., 31., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",53,53,0,50,"encoder/1/1/attention/9/elem","encoder/1/1/attention/9/elem","encoder/1/1/attention/9/elem","Elementwise","Elementwise","Elementwise",17.,18.,39.,"{39., 21., 19., 19., 17., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",54,54,0,50,"encoder/1/1/attention/9/value/Net","encoder/1/1/attention/9/value/Net","encoder/1/1/attention/9/value/Net","Linear","Linear","Linear",21.,24.7667,58.,"{58., 32., 24., 29., 23., 29., 23., 28., 22., 22., 21., 22., 21., 22., 23., 21., 22., 21., 22., 21., 28., 28., 28., 22., 28., 35., 24., 25., 32., 26., 24., 24., 24., 24., 24., 24., 24., 24., 32., 25., 25., 24., 24., 24., 24., 24., 31., 32., 31., 47.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",55,55,0,50,"encoder/1/1/attention/9/attention/ScoringNet/1","encoder/1/1/attention/9/attention/ScoringNet/1","encoder/1/1/attention/9/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2667,44.,"{44., 34., 20., 20., 20., 19., 20., 19., 20., 19., 19., 19., 19., 20., 19., 19., 42., 21., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",56,56,0,50,"encoder/1/1/attention/10/key/Net","encoder/1/1/attention/10/key/Net","encoder/1/1/attention/10/key/Net","Linear","Linear","Linear",21.,22.133300000000002,48.,"{48., 32., 29., 22., 21., 21., 21., 21., 21., 22., 22., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 22., 21., 21., 21., 22., 21., 21., 34., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 25., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",57,57,0,50,"encoder/1/1/attention/10/query/Net","encoder/1/1/attention/10/query/Net","encoder/1/1/attention/10/query/Net","Linear","Linear","Linear",21.,23.400000000000002,58.,"{58., 32., 24., 21., 21., 31., 29., 29., 22., 21., 21., 21., 21., 22., 28., 29., 29., 22., 21., 21., 21., 22., 21., 22., 21., 22., 21., 32., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",58,58,0,50,"encoder/1/1/attention/10/elem","encoder/1/1/attention/10/elem","encoder/1/1/attention/10/elem","Elementwise","Elementwise","Elementwise",17.,18.,42.,"{38., 21., 19., 18., 18., 19., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 42., 19., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",59,59,0,50,"encoder/1/1/attention/10/value/Net","encoder/1/1/attention/10/value/Net","encoder/1/1/attention/10/value/Net","Linear","Linear","Linear",21.,25.6,58.,"{58., 32., 29., 22., 28., 22., 42., 25., 24., 32., 25., 25., 33., 25., 32., 24., 25., 31., 24., 26., 24., 24., 24., 31., 25., 57., 35., 27., 23., 32., 21., 22., 22., 28., 22., 23., 28., 22., 21., 21., 21., 28., 28., 30., 29., 22., 21., 21., 28., 22.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",60,60,0,50,"encoder/1/1/attention/10/attention/ScoringNet/1","encoder/1/1/attention/10/attention/ScoringNet/1","encoder/1/1/attention/10/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.,68.,"{44., 33., 68., 23., 20., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",61,61,0,50,"encoder/1/1/attention/11/key/Net","encoder/1/1/attention/11/key/Net","encoder/1/1/attention/11/key/Net","Linear","Linear","Linear",23.,25.8333,58.,"{58., 32., 29., 29., 29., 29., 29., 28., 29., 36., 24., 24., 24., 24., 24., 24., 31., 33., 32., 32., 32., 26., 32., 24., 24., 49., 26., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 32., 25., 24., 24., 32., 25., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",62,62,0,50,"encoder/1/1/attention/11/query/Net","encoder/1/1/attention/11/query/Net","encoder/1/1/attention/11/query/Net","Linear","Linear","Linear",21.,24.1,58.,"{58., 32., 24., 22., 22., 21., 21., 33., 24., 24., 24., 24., 24., 24., 25., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 32., 24., 25., 24., 24., 24., 24., 32., 25., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",63,63,0,50,"encoder/1/1/attention/11/elem","encoder/1/1/attention/11/elem","encoder/1/1/attention/11/elem","Elementwise","Elementwise","Elementwise",17.,18.,39.,"{39., 21., 19., 19., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",64,64,0,50,"encoder/1/1/attention/11/value/Net","encoder/1/1/attention/11/value/Net","encoder/1/1/attention/11/value/Net","Linear","Linear","Linear",21.,25.133300000000002,58.,"{58., 34., 29., 30., 29., 29., 23., 28., 22., 28., 22., 28., 22., 21., 28., 22., 21., 22., 23., 28., 22., 23., 21., 22., 21., 22., 22., 23., 28., 30., 29., 22., 28., 28., 21., 22., 21., 29., 28., 42., 25., 25., 26., 24., 24., 25., 24., 31., 25., 31.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",65,65,0,50,"encoder/1/1/attention/11/attention/ScoringNet/1","encoder/1/1/attention/11/attention/ScoringNet/1","encoder/1/1/attention/11/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3,50.,"{42., 34., 20., 19., 20., 20., 19., 19., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 19., 19., 19., 19., 20., 19., 20., 50., 21., 19., 19., 20., 20., 19., 19., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",66,66,0,50,"encoder/1/1/attention/12/key/Net","encoder/1/1/attention/12/key/Net","encoder/1/1/attention/12/key/Net","Linear","Linear","Linear",21.,24.0667,60.,"{60., 32., 29., 30., 24., 34., 23., 21., 41., 42., 26., 25., 23., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 32., 21., 21., 21., 33., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",67,67,0,50,"encoder/1/1/attention/12/query/Net","encoder/1/1/attention/12/query/Net","encoder/1/1/attention/12/query/Net","Linear","Linear","Linear",23.,24.666700000000002,57.,"{57., 32., 23., 35., 25., 25., 25., 25., 24., 25., 24., 25., 24., 25., 24., 25., 24., 24., 25., 24., 24., 24., 49., 35., 33., 25., 26., 25., 32., 25., 25., 24., 24., 24., 25., 24., 24., 25., 24., 55., 26., 25., 25., 25., 24., 25., 24., 24., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",68,68,0,50,"encoder/1/1/attention/12/elem","encoder/1/1/attention/12/elem","encoder/1/1/attention/12/elem","Elementwise","Elementwise","Elementwise",17.,18.,40.,"{40., 21., 19., 18., 18., 18., 18., 18., 19., 19., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",69,69,0,50,"encoder/1/1/attention/12/value/Net","encoder/1/1/attention/12/value/Net","encoder/1/1/attention/12/value/Net","Linear","Linear","Linear",21.,27.0333,65.,"{59., 32., 24., 22., 21., 29., 30., 22., 22., 40., 32., 25., 25., 32., 24., 24., 24., 32., 24., 32., 24., 24., 24., 32., 24., 24., 32., 26., 25., 23., 47., 22., 21., 28., 35., 32., 25., 23., 24., 32., 25., 31., 65., 28., 32., 34., 26., 31., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",70,70,0,50,"encoder/1/1/attention/12/attention/ScoringNet/1","encoder/1/1/attention/12/attention/ScoringNet/1","encoder/1/1/attention/12/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3333,54.,"{44., 54., 22., 20., 19., 20., 19., 19., 20., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 20., 19., 19., 20., 19., 20., 19., 19., 20., 20., 19., 19., 19., 19., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",71,71,0,50,"encoder/1/1/attention/13","encoder/1/1/attention/13","encoder/1/1/attention/13","Catenate","Catenate","Catenate",56.,56.033300000000004,80.,"{79., 59., 57., 80., 57., 56., 56., 56., 56., 56., 56., 56., 57., 64., 57., 57., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 57., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 57., 56., 56.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",72,72,0,50,"encoder/1/1/attention/14/Net","encoder/1/1/attention/14/Net","encoder/1/1/attention/14/Net","Linear","Linear","Linear",136.,138.26670000000001,267.,"{267., 196., 143., 139., 139., 137., 138., 141., 138., 138., 140., 138., 138., 139., 138., 137., 139., 136., 138., 137., 137., 138., 138., 137., 138., 158., 140., 139., 139., 138., 138., 137., 138., 170., 141., 138., 138., 138., 139., 138., 138., 137., 138., 139., 139., 138., 138., 138., 137., 138.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",73,73,0,50,"encoder/1/1/dropout","encoder/1/1/dropout","encoder/1/1/dropout","Dropout","Dropout","Dropout",18.,18.5,37.,"{37., 21., 19., 18., 18., 19., 18., 18., 18., 19., 19., 19., 19., 18., 18., 19., 19., 19., 19., 19., 18., 18., 19., 19., 18., 18., 18., 19., 19., 18., 18., 19., 19., 18., 18., 19., 19., 19., 19., 18., 18., 18., 18., 18., 19., 18., 18., 19., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",74,75,1,50,"encoder/1/1/add","encoder/1/1/norm","encoder/1/1/add-encoder/1/1/norm","Threading","Normalization","Threading-Normalization",161.,163.0333,211.,"{211., 168., 163., 163., 162., 162., 162., 163., 173., 163., 161., 161., 183., 166., 163., 162., 162., 162., 192., 165., 163., 162., 162., 162., 163., 162., 161., 162., 163., 162., 162., 161., 163., 163., 162., 177., 166., 162., 162., 162., 163., 162., 183., 167., 165., 165., 164., 164., 165., 166.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",76,76,0,50,"encoder/1/2/linear1/Net","encoder/1/2/linear1/Net","encoder/1/2/linear1/Net","Linear","Linear","Linear",439.,444.7667,779.,"{779., 714., 510., 459., 441., 442., 440., 441., 474., 442., 441., 440., 441., 450., 442., 463., 441., 467., 440., 440., 440., 440., 439., 440., 445., 440., 465., 445., 444., 444., 446., 447., 444., 445., 444., 476., 445., 456., 446., 444., 443., 443., 445., 466., 445., 444., 450., 444., 450., 444.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",77,77,0,50,"encoder/1/2/gelu","encoder/1/2/gelu","encoder/1/2/gelu","Elementwise","Elementwise","Elementwise",105.,105.30000000000001,927.,"{927., 112., 107., 107., 106., 106., 105., 105., 105., 106., 105., 105., 105., 105., 105., 124., 108., 105., 105., 105., 105., 116., 108., 105., 105., 105., 105., 105., 105., 105., 109., 106., 105., 105., 105., 106., 124., 109., 106., 105., 105., 106., 105., 105., 105., 105., 105., 105., 105., 105.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",78,78,0,50,"encoder/1/2/linear2/Net","encoder/1/2/linear2/Net","encoder/1/2/linear2/Net","Linear","Linear","Linear",431.,434.8,486.,"{486., 485., 441., 433., 450., 433., 431., 433., 431., 431., 463., 432., 431., 431., 432., 441., 432., 432., 454., 460., 434., 432., 432., 431., 432., 431., 432., 438., 457., 432., 432., 432., 432., 434., 432., 432., 432., 456., 446., 437., 435., 447., 436., 435., 435., 436., 460., 436., 436., 441.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",79,79,0,50,"encoder/1/2/dropout","encoder/1/2/dropout","encoder/1/2/dropout","Dropout","Dropout","Dropout",20.,20.2,41.,"{41., 23., 21., 20., 20., 20., 21., 20., 21., 20., 20., 20., 21., 20., 20., 20., 21., 20., 20., 20., 21., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 21., 20., 20., 20., 20., 21., 21., 20., 20., 20., 20., 28., 21., 21., 20., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",80,81,1,50,"encoder/1/2/add","encoder/1/2/norm","encoder/1/2/add-encoder/1/2/norm","Threading","Normalization","Threading-Normalization",161.,162.63330000000002,215.,"{215., 168., 164., 162., 162., 163., 163., 163., 162., 163., 163., 163., 163., 162., 163., 162., 161., 162., 162., 186., 165., 165., 162., 161., 163., 163., 162., 163., 162., 163., 195., 164., 163., 161., 162., 162., 162., 162., 162., 162., 162., 163., 163., 189., 164., 173., 165., 162., 161., 161.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",82,82,0,50,"encoder/2/1/attention/1/key/Net","encoder/2/1/attention/1/key/Net","encoder/2/1/attention/1/key/Net","Linear","Linear","Linear",21.,23.5,66.,"{66., 32., 23., 21., 21., 22., 21., 28., 22., 21., 21., 22., 21., 21., 22., 21., 21., 21., 21., 21., 33., 24., 24., 24., 62., 34., 24., 24., 66., 27., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",83,83,0,50,"encoder/2/1/attention/1/query/Net","encoder/2/1/attention/1/query/Net","encoder/2/1/attention/1/query/Net","Linear","Linear","Linear",21.,23.933300000000003,59.,"{59., 32., 23., 22., 22., 22., 21., 21., 33., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 23., 24., 24., 31., 21., 21., 34., 24., 25., 23., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",84,84,0,50,"encoder/2/1/attention/1/elem","encoder/2/1/attention/1/elem","encoder/2/1/attention/1/elem","Elementwise","Elementwise","Elementwise",17.,18.,44.,"{41., 22., 19., 18., 18., 44., 21., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 19., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",85,85,0,50,"encoder/2/1/attention/1/value/Net","encoder/2/1/attention/1/value/Net","encoder/2/1/attention/1/value/Net","Linear","Linear","Linear",21.,22.933300000000003,58.,"{58., 32., 37., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 32., 26., 25., 24., 23., 24., 24., 35., 33., 21., 22., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 22., 21., 21., 22., 21., 21., 21., 21., 21., 21., 32., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",86,86,0,50,"encoder/2/1/attention/1/attention/ScoringNet/1","encoder/2/1/attention/1/attention/ScoringNet/1","encoder/2/1/attention/1/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.166700000000002,62.,"{45., 23., 20., 19., 20., 19., 19., 19., 20., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 62., 21., 20., 19., 19., 20., 19., 20., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",87,87,0,50,"encoder/2/1/attention/2/key/Net","encoder/2/1/attention/2/key/Net","encoder/2/1/attention/2/key/Net","Linear","Linear","Linear",21.,23.7667,59.,"{59., 31., 30., 29., 29., 29., 23., 21., 21., 21., 22., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 32., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 23., 24., 24., 24., 32., 32., 32., 26., 23., 32., 26., 23., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",88,88,0,50,"encoder/2/1/attention/2/query/Net","encoder/2/1/attention/2/query/Net","encoder/2/1/attention/2/query/Net","Linear","Linear","Linear",23.,24.166700000000002,58.,"{58., 31., 45., 26., 25., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 35., 32., 26., 24., 24., 24., 24., 24., 24., 24., 23., 24., 32., 32., 33., 32., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",89,89,0,50,"encoder/2/1/attention/2/elem","encoder/2/1/attention/2/elem","encoder/2/1/attention/2/elem","Elementwise","Elementwise","Elementwise",17.,18.,40.,"{40., 21., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",90,90,0,50,"encoder/2/1/attention/2/value/Net","encoder/2/1/attention/2/value/Net","encoder/2/1/attention/2/value/Net","Linear","Linear","Linear",21.,24.,71.,"{59., 32., 30., 23., 22., 22., 21., 22., 21., 21., 33., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 25., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 71.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",91,91,0,50,"encoder/2/1/attention/2/attention/ScoringNet/1","encoder/2/1/attention/2/attention/ScoringNet/1","encoder/2/1/attention/2/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2,46.,"{46., 23., 20., 19., 20., 19., 19., 20., 20., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 41., 20., 19., 19., 20., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",92,92,0,50,"encoder/2/1/attention/3/key/Net","encoder/2/1/attention/3/key/Net","encoder/2/1/attention/3/key/Net","Linear","Linear","Linear",21.,24.,58.,"{58., 33., 29., 23., 21., 22., 34., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 40., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",93,93,0,50,"encoder/2/1/attention/3/query/Net","encoder/2/1/attention/3/query/Net","encoder/2/1/attention/3/query/Net","Linear","Linear","Linear",21.,23.0667,58.,"{58., 32., 38., 24., 22., 22., 22., 22., 21., 21., 22., 41., 33., 32., 32., 25., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 36., 23., 32., 22., 21., 21., 22., 21., 22., 21., 21., 21., 22., 21., 22., 21., 21., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",94,94,0,50,"encoder/2/1/attention/3/elem","encoder/2/1/attention/3/elem","encoder/2/1/attention/3/elem","Elementwise","Elementwise","Elementwise",18.,18.0333,40.,"{40., 21., 19., 19., 18., 18., 18., 40., 20., 38., 20., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",95,95,0,50,"encoder/2/1/attention/3/value/Net","encoder/2/1/attention/3/value/Net","encoder/2/1/attention/3/value/Net","Linear","Linear","Linear",21.,25.,83.,"{83., 34., 30., 31., 30., 31., 29., 29., 23., 22., 22., 21., 21., 21., 22., 33., 24., 24., 24., 25., 25., 24., 24., 24., 25., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 31., 33., 33., 32., 32., 25., 25., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",96,96,0,50,"encoder/2/1/attention/3/attention/ScoringNet/1","encoder/2/1/attention/3/attention/ScoringNet/1","encoder/2/1/attention/3/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3333,44.,"{44., 34., 20., 20., 19., 20., 20., 19., 19., 19., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 20., 19., 19., 19., 20., 42., 21., 20., 19., 20., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",97,97,0,50,"encoder/2/1/attention/4/key/Net","encoder/2/1/attention/4/key/Net","encoder/2/1/attention/4/key/Net","Linear","Linear","Linear",21.,24.1,67.,"{59., 31., 24., 22., 21., 21., 21., 33., 24., 32., 67., 28., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 46., 35., 25., 24., 31., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 23., 24., 23., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",98,98,0,50,"encoder/2/1/attention/4/query/Net","encoder/2/1/attention/4/query/Net","encoder/2/1/attention/4/query/Net","Linear","Linear","Linear",21.,23.900000000000002,58.,"{58., 31., 24., 21., 21., 21., 22., 22., 21., 22., 21., 21., 21., 34., 24., 24., 24., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 23., 33., 21., 34., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",99,99,0,50,"encoder/2/1/attention/4/elem","encoder/2/1/attention/4/elem","encoder/2/1/attention/4/elem","Elementwise","Elementwise","Elementwise",17.,18.,40.,"{40., 21., 19., 18., 19., 18., 18., 18., 18., 18., 19., 18., 18., 18., 19., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 19., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",100,100,0,50,"encoder/2/1/attention/4/value/Net","encoder/2/1/attention/4/value/Net","encoder/2/1/attention/4/value/Net","Linear","Linear","Linear",22.,25.,58.,"{58., 32., 23., 22., 22., 22., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 33., 33., 32., 32., 32., 32., 25., 48., 26., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 26., 36., 33., 34.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",101,101,0,50,"encoder/2/1/attention/4/attention/ScoringNet/1","encoder/2/1/attention/4/attention/ScoringNet/1","encoder/2/1/attention/4/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.133300000000002,52.,"{43., 34., 20., 19., 19., 20., 19., 20., 52., 23., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",102,102,0,50,"encoder/2/1/attention/5/key/Net","encoder/2/1/attention/5/key/Net","encoder/2/1/attention/5/key/Net","Linear","Linear","Linear",24.,30.933300000000003,59.,"{58., 31., 33., 25., 25., 25., 24., 24., 25., 24., 24., 25., 25., 24., 24., 24., 24., 24., 25., 24., 24., 25., 24., 24., 59., 37., 35., 34., 34., 36., 35., 35., 36., 35., 35., 35., 35., 35., 35., 36., 34., 35., 35., 36., 35., 36., 35., 35., 36., 35.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",103,103,0,50,"encoder/2/1/attention/5/query/Net","encoder/2/1/attention/5/query/Net","encoder/2/1/attention/5/query/Net","Linear","Linear","Linear",21.,24.8333,47.,"{47., 31., 31., 29., 29., 29., 30., 29., 23., 23., 21., 21., 21., 23., 21., 33., 25., 24., 25., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 31., 32., 33., 25., 24., 24., 26., 24., 24., 32., 25., 25., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",104,104,0,50,"encoder/2/1/attention/5/elem","encoder/2/1/attention/5/elem","encoder/2/1/attention/5/elem","Elementwise","Elementwise","Elementwise",18.,18.133300000000002,38.,"{38., 22., 19., 18., 19., 19., 18., 19., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 19., 19., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",105,105,0,50,"encoder/2/1/attention/5/value/Net","encoder/2/1/attention/5/value/Net","encoder/2/1/attention/5/value/Net","Linear","Linear","Linear",21.,23.4667,58.,"{58., 31., 23., 22., 22., 21., 21., 21., 21., 21., 21., 21., 21., 21., 22., 21., 22., 21., 22., 33., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 37., 25., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",106,106,0,50,"encoder/2/1/attention/5/attention/ScoringNet/1","encoder/2/1/attention/5/attention/ScoringNet/1","encoder/2/1/attention/5/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.7,44.,"{44., 34., 21., 20., 20., 20., 41., 22., 20., 19., 20., 20., 20., 19., 29., 20., 20., 20., 19., 20., 19., 19., 19., 20., 19., 20., 20., 19., 20., 19., 20., 20., 19., 19., 20., 19., 20., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",107,107,0,50,"encoder/2/1/attention/6/key/Net","encoder/2/1/attention/6/key/Net","encoder/2/1/attention/6/key/Net","Linear","Linear","Linear",21.,24.5667,64.,"{59., 32., 23., 34., 25., 25., 24., 25., 24., 25., 24., 33., 25., 25., 24., 25., 24., 25., 25., 25., 25., 24., 24., 25., 32., 22., 21., 21., 22., 22., 33., 24., 25., 24., 24., 25., 24., 24., 25., 25., 24., 64., 35., 25., 24., 24., 25., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",108,108,0,50,"encoder/2/1/attention/6/query/Net","encoder/2/1/attention/6/query/Net","encoder/2/1/attention/6/query/Net","Linear","Linear","Linear",24.,24.2667,60.,"{58., 31., 44., 25., 50., 35., 25., 25., 24., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 60., 37., 25., 24., 24., 24., 25., 24., 24., 26., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",109,109,0,50,"encoder/2/1/attention/6/elem","encoder/2/1/attention/6/elem","encoder/2/1/attention/6/elem","Elementwise","Elementwise","Elementwise",18.,18.4667,39.,"{39., 21., 19., 18., 19., 18., 18., 18., 19., 19., 19., 19., 18., 18., 19., 19., 19., 18., 18., 19., 19., 19., 19., 19., 19., 19., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 19., 19., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",110,110,0,50,"encoder/2/1/attention/6/value/Net","encoder/2/1/attention/6/value/Net","encoder/2/1/attention/6/value/Net","Linear","Linear","Linear",21.,24.1,59.,"{59., 32., 43., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 35., 21., 21., 21., 22., 21., 21., 29., 29., 29., 22., 22., 22., 39., 27., 32., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",111,111,0,50,"encoder/2/1/attention/6/attention/ScoringNet/1","encoder/2/1/attention/6/attention/ScoringNet/1","encoder/2/1/attention/6/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.5,44.,"{44., 23., 20., 20., 20., 20., 19., 20., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 19., 19., 20., 19., 20., 19., 19., 19., 20., 23., 20., 20., 19., 20., 19., 19., 19., 19., 19., 19., 20., 19., 19., 20., 19., 20., 19., 20., 19., 20., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",112,112,0,50,"encoder/2/1/attention/7/key/Net","encoder/2/1/attention/7/key/Net","encoder/2/1/attention/7/key/Net","Linear","Linear","Linear",21.,24.400000000000002,60.,"{60., 32., 23., 22., 21., 22., 22., 30., 29., 22., 21., 32., 25., 24., 24., 24., 25., 24., 24., 24., 25., 25., 24., 24., 25., 24., 24., 25., 24., 32., 32., 25., 25., 24., 25., 25., 24., 24., 25., 24., 24., 25., 24., 25., 25., 24., 24., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",113,113,0,50,"encoder/2/1/attention/7/query/Net","encoder/2/1/attention/7/query/Net","encoder/2/1/attention/7/query/Net","Linear","Linear","Linear",21.,24.933300000000003,59.,"{57., 31., 23., 21., 21., 21., 21., 21., 33., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 59., 27., 24., 24., 24., 24., 33., 36., 21., 33., 24., 24., 23., 24., 24., 23., 24., 32., 32., 32., 32., 34., 33., 26.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",114,114,0,50,"encoder/2/1/attention/7/elem","encoder/2/1/attention/7/elem","encoder/2/1/attention/7/elem","Elementwise","Elementwise","Elementwise",17.,18.,40.,"{40., 21., 19., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 19., 18., 25., 19., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 17., 19., 18., 18., 18., 18., 18., 18., 18., 26., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",115,115,0,50,"encoder/2/1/attention/7/value/Net","encoder/2/1/attention/7/value/Net","encoder/2/1/attention/7/value/Net","Linear","Linear","Linear",21.,24.400000000000002,59.,"{59., 32., 29., 24., 29., 23., 28., 29., 29., 23., 21., 22., 22., 21., 21., 22., 22., 33., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 33., 25., 24., 24., 24., 24., 24., 24., 25., 36., 33., 22., 33., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",116,116,0,50,"encoder/2/1/attention/7/attention/ScoringNet/1","encoder/2/1/attention/7/attention/ScoringNet/1","encoder/2/1/attention/7/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2,44.,"{44., 33., 20., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 20., 20., 37., 21., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 20., 20., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",117,117,0,50,"encoder/2/1/attention/8/key/Net","encoder/2/1/attention/8/key/Net","encoder/2/1/attention/8/key/Net","Linear","Linear","Linear",24.,27.900000000000002,47.,"{47., 32., 42., 27., 24., 32., 25., 32., 32., 33., 32., 25., 24., 32., 25., 25., 24., 24., 25., 24., 24., 24., 31., 33., 26., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 32., 26., 32., 32., 32., 34., 32., 32., 33., 32., 32., 32., 29., 29.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",118,118,0,50,"encoder/2/1/attention/8/query/Net","encoder/2/1/attention/8/query/Net","encoder/2/1/attention/8/query/Net","Linear","Linear","Linear",21.,24.0333,50.,"{50., 32., 23., 21., 28., 28., 22., 21., 33., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 25., 23., 47., 34., 33., 32., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",119,119,0,50,"encoder/2/1/attention/8/elem","encoder/2/1/attention/8/elem","encoder/2/1/attention/8/elem","Elementwise","Elementwise","Elementwise",17.,18.1,53.,"{40., 22., 19., 18., 18., 18., 18., 18., 19., 18., 19., 19., 18., 19., 18., 18., 20., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 53., 20., 18., 18., 19., 19., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",120,120,0,50,"encoder/2/1/attention/8/value/Net","encoder/2/1/attention/8/value/Net","encoder/2/1/attention/8/value/Net","Linear","Linear","Linear",24.,24.200000000000003,60.,"{60., 36., 38., 25., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 26., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 26., 32., 25., 31., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",121,121,0,50,"encoder/2/1/attention/8/attention/ScoringNet/1","encoder/2/1/attention/8/attention/ScoringNet/1","encoder/2/1/attention/8/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.166700000000002,44.,"{44., 34., 21., 19., 20., 19., 20., 19., 19., 19., 20., 20., 19., 19., 19., 19., 19., 19., 20., 20., 19., 19., 19., 20., 19., 19., 19., 20., 20., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",122,122,0,50,"encoder/2/1/attention/9/key/Net","encoder/2/1/attention/9/key/Net","encoder/2/1/attention/9/key/Net","Linear","Linear","Linear",23.,24.133300000000002,59.,"{49., 34., 27., 25., 25., 24., 24., 24., 24., 24., 24., 26., 59., 36., 25., 25., 24., 25., 23., 24., 24., 24., 24., 24., 24., 26., 24., 24., 24., 23., 24., 24., 24., 24., 23., 24., 24., 24., 34., 25., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",123,123,0,50,"encoder/2/1/attention/9/query/Net","encoder/2/1/attention/9/query/Net","encoder/2/1/attention/9/query/Net","Linear","Linear","Linear",21.,24.,58.,"{58., 31., 31., 30., 22., 21., 22., 21., 21., 21., 21., 21., 22., 21., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 32., 25., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",124,124,0,50,"encoder/2/1/attention/9/elem","encoder/2/1/attention/9/elem","encoder/2/1/attention/9/elem","Elementwise","Elementwise","Elementwise",18.,20.2,39.,"{39., 22., 19., 18., 18., 18., 19., 18., 18., 18., 18., 22., 20., 20., 20., 20., 20., 20., 27., 21., 20., 20., 20., 20., 21., 20., 20., 21., 20., 20., 20., 21., 21., 20., 21., 20., 20., 21., 20., 20., 21., 20., 20., 20., 21., 21., 21., 20., 20., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",125,125,0,50,"encoder/2/1/attention/9/value/Net","encoder/2/1/attention/9/value/Net","encoder/2/1/attention/9/value/Net","Linear","Linear","Linear",24.,24.2667,59.,"{59., 25., 35., 25., 25., 24., 25., 24., 25., 24., 24., 25., 25., 25., 24., 25., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",126,126,0,50,"encoder/2/1/attention/9/attention/ScoringNet/1","encoder/2/1/attention/9/attention/ScoringNet/1","encoder/2/1/attention/9/attention/ScoringNet/1","Dot","Dot","Dot",21.,21.5667,47.,"{47., 36., 22., 22., 21., 21., 22., 21., 22., 21., 22., 21., 22., 21., 21., 22., 21., 22., 21., 21., 21., 21., 21., 21., 22., 21., 21., 22., 29., 22., 21., 21., 21., 22., 22., 22., 22., 22., 22., 22., 22., 22., 22., 21., 21., 21., 21., 22., 22., 22.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",127,127,0,50,"encoder/2/1/attention/10/key/Net","encoder/2/1/attention/10/key/Net","encoder/2/1/attention/10/key/Net","Linear","Linear","Linear",21.,25.133300000000002,48.,"{48., 31., 23., 22., 22., 21., 28., 29., 30., 28., 28., 28., 23., 22., 28., 23., 21., 28., 23., 21., 28., 44., 38., 32., 32., 31., 25., 24., 32., 26., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 26., 24., 24., 24., 24., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",128,128,0,50,"encoder/2/1/attention/10/query/Net","encoder/2/1/attention/10/query/Net","encoder/2/1/attention/10/query/Net","Linear","Linear","Linear",21.,21.3667,47.,"{47., 32., 29., 29., 29., 29., 22., 21., 22., 21., 21., 21., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 22., 21., 21., 22., 21., 21., 21., 22., 21., 21., 21., 34., 24., 25., 23., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",129,129,0,50,"encoder/2/1/attention/10/elem","encoder/2/1/attention/10/elem","encoder/2/1/attention/10/elem","Elementwise","Elementwise","Elementwise",18.,18.,39.,"{39., 21., 18., 38., 19., 19., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 20., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",130,130,0,50,"encoder/2/1/attention/10/value/Net","encoder/2/1/attention/10/value/Net","encoder/2/1/attention/10/value/Net","Linear","Linear","Linear",24.,25.6,58.,"{58., 31., 43., 32., 34., 33., 33., 34., 33., 33., 25., 32., 25., 25., 24., 49., 34., 27., 31., 33., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",131,131,0,50,"encoder/2/1/attention/10/attention/ScoringNet/1","encoder/2/1/attention/10/attention/ScoringNet/1","encoder/2/1/attention/10/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.133300000000002,43.,"{43., 23., 20., 19., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19., 43., 20., 19., 19., 19., 20., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",132,132,0,50,"encoder/2/1/attention/11/key/Net","encoder/2/1/attention/11/key/Net","encoder/2/1/attention/11/key/Net","Linear","Linear","Linear",21.,24.0333,51.,"{47., 32., 24., 22., 22., 22., 21., 22., 21., 21., 21., 22., 21., 21., 45., 30., 51., 35., 33., 26., 24., 24., 24., 25., 24., 24., 24., 25., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",133,133,0,50,"encoder/2/1/attention/11/query/Net","encoder/2/1/attention/11/query/Net","encoder/2/1/attention/11/query/Net","Linear","Linear","Linear",21.,24.,47.,"{47., 31., 24., 22., 22., 21., 21., 22., 32., 24., 24., 24., 24., 24., 24., 23., 25., 24., 24., 24., 24., 24., 24., 23., 24., 25., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 23., 24., 24., 24., 24., 24., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",134,134,0,50,"encoder/2/1/attention/11/elem","encoder/2/1/attention/11/elem","encoder/2/1/attention/11/elem","Elementwise","Elementwise","Elementwise",17.,18.0667,39.,"{39., 22., 19., 19., 19., 19., 18., 18., 18., 18., 19., 19., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",135,135,0,50,"encoder/2/1/attention/11/value/Net","encoder/2/1/attention/11/value/Net","encoder/2/1/attention/11/value/Net","Linear","Linear","Linear",21.,24.200000000000003,60.,"{58., 32., 35., 25., 24., 25., 24., 24., 24., 25., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 35., 32., 21., 21., 22., 21., 21., 33., 24., 24., 24., 24., 24., 24., 60., 28., 24., 24., 24., 25., 34., 24., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",136,136,0,50,"encoder/2/1/attention/11/attention/ScoringNet/1","encoder/2/1/attention/11/attention/ScoringNet/1","encoder/2/1/attention/11/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3667,77.,"{77., 24., 21., 20., 19., 19., 20., 20., 48., 21., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 20., 48., 21., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",137,137,0,50,"encoder/2/1/attention/12/key/Net","encoder/2/1/attention/12/key/Net","encoder/2/1/attention/12/key/Net","Linear","Linear","Linear",21.,23.933300000000003,59.,"{59., 32., 30., 23., 22., 21., 21., 21., 22., 21., 23., 21., 22., 21., 21., 21., 34., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 32., 32., 25., 24., 24., 24., 24., 24., 25., 24., 38., 33., 33., 26., 25., 24., 24., 24., 24., 24., 23., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",138,138,0,50,"encoder/2/1/attention/12/query/Net","encoder/2/1/attention/12/query/Net","encoder/2/1/attention/12/query/Net","Linear","Linear","Linear",21.,24.400000000000002,80.,"{80., 35., 31., 29., 29., 23., 22., 22., 34., 24., 25., 24., 32., 25., 24., 25., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 25., 24., 25., 24., 24., 24., 36., 22., 21., 22., 21., 21., 34., 25., 24., 24., 24., 25., 24., 24., 24., 52., 27.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",139,139,0,50,"encoder/2/1/attention/12/elem","encoder/2/1/attention/12/elem","encoder/2/1/attention/12/elem","Elementwise","Elementwise","Elementwise",18.,18.4667,38.,"{38., 22., 19., 18., 18., 18., 19., 18., 18., 19., 19., 18., 18., 19., 19., 18., 18., 18., 18., 19., 19., 19., 19., 18., 18., 19., 19., 18., 18., 18., 18., 19., 19., 19., 18., 18., 18., 18., 18., 18., 19., 19., 18., 19., 19., 18., 18., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",140,140,0,50,"encoder/2/1/attention/12/value/Net","encoder/2/1/attention/12/value/Net","encoder/2/1/attention/12/value/Net","Linear","Linear","Linear",21.,25.3333,57.,"{57., 34., 30., 29., 29., 44., 33., 25., 25., 24., 24., 25., 24., 24., 26., 24., 24., 24., 32., 32., 26., 24., 24., 24., 25., 24., 26., 24., 24., 32., 26., 24., 32., 29., 29., 23., 21., 22., 23., 21., 22., 22., 21., 22., 21., 33., 37., 26., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",141,141,0,50,"encoder/2/1/attention/12/attention/ScoringNet/1","encoder/2/1/attention/12/attention/ScoringNet/1","encoder/2/1/attention/12/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.400000000000002,69.,"{45., 33., 21., 20., 20., 19., 69., 22., 19., 20., 19., 20., 20., 19., 19., 19., 19., 19., 20., 19., 21., 19., 20., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 19., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",142,142,0,50,"encoder/2/1/attention/13","encoder/2/1/attention/13","encoder/2/1/attention/13","Catenate","Catenate","Catenate",55.,56.,80.,"{80., 59., 57., 56., 57., 56., 56., 57., 56., 56., 57., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 55., 56., 57., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 57., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",143,143,0,50,"encoder/2/1/attention/14/Net","encoder/2/1/attention/14/Net","encoder/2/1/attention/14/Net","Linear","Linear","Linear",137.,138.5333,265.,"{265., 189., 143., 138., 139., 139., 139., 138., 140., 138., 139., 139., 139., 138., 149., 139., 139., 138., 138., 137., 137., 138., 138., 137., 138., 139., 173., 140., 138., 139., 138., 138., 138., 137., 138., 137., 139., 137., 139., 137., 138., 137., 138., 139., 162., 142., 156., 139., 140., 138.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",144,144,0,50,"encoder/2/1/dropout","encoder/2/1/dropout","encoder/2/1/dropout","Dropout","Dropout","Dropout",18.,18.2667,50.,"{37., 22., 19., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 19., 19., 18., 19., 18., 19., 19., 19., 19., 18., 18., 18., 19., 19., 18., 19., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 50.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",145,146,1,50,"encoder/2/1/add","encoder/2/1/norm","encoder/2/1/add-encoder/2/1/norm","Threading","Normalization","Threading-Normalization",161.,162.8667,214.,"{214., 167., 164., 164., 163., 163., 163., 163., 162., 163., 180., 188., 165., 164., 163., 162., 162., 163., 162., 162., 161., 163., 162., 162., 171., 164., 163., 163., 162., 163., 162., 163., 163., 163., 180., 165., 163., 162., 163., 162., 163., 163., 163., 163., 163., 162., 161., 161., 163., 162.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",147,147,0,50,"encoder/2/2/linear1/Net","encoder/2/2/linear1/Net","encoder/2/2/linear1/Net","Linear","Linear","Linear",440.,445.5667,757.,"{757., 715., 516., 451., 445., 482., 445., 464., 442., 442., 440., 441., 441., 441., 473., 445., 446., 444., 444., 453., 445., 444., 444., 471., 443., 445., 445., 444., 443., 458., 445., 469., 443., 441., 441., 441., 448., 444., 442., 445., 481., 445., 445., 445., 445., 445., 444., 445., 444., 467.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",148,148,0,50,"encoder/2/2/gelu","encoder/2/2/gelu","encoder/2/2/gelu","Elementwise","Elementwise","Elementwise",104.,105.03330000000001,136.,"{136., 109., 106., 106., 105., 114., 106., 105., 105., 105., 105., 105., 106., 105., 105., 105., 105., 104., 105., 105., 105., 129., 107., 105., 105., 105., 104., 104., 105., 105., 105., 105., 105., 105., 105., 105., 105., 106., 105., 105., 105., 105., 105., 105., 105., 105., 105., 105., 105., 134.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",149,149,0,50,"encoder/2/2/linear2/Net","encoder/2/2/linear2/Net","encoder/2/2/linear2/Net","Linear","Linear","Linear",431.,436.5333,518.,"{518., 483., 443., 435., 434., 433., 432., 433., 458., 434., 442., 436., 432., 433., 432., 433., 434., 476., 437., 436., 436., 446., 435., 436., 437., 459., 433., 432., 432., 436., 446., 433., 431., 445., 468., 439., 436., 436., 437., 436., 439., 436., 436., 471., 446., 436., 435., 436., 436., 436.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",150,150,0,50,"encoder/2/2/dropout","encoder/2/2/dropout","encoder/2/2/dropout","Dropout","Dropout","Dropout",18.,18.3,39.,"{39., 22., 19., 19., 18., 19., 18., 19., 19., 18., 18., 19., 18., 19., 18., 18., 19., 19., 19., 18., 19., 18., 18., 18., 18., 19., 19., 18., 18., 18., 19., 18., 18., 19., 18., 18., 19., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",151,152,1,50,"encoder/2/2/add","encoder/2/2/norm","encoder/2/2/add-encoder/2/2/norm","Threading","Normalization","Threading-Normalization",161.,163.8333,218.,"{218., 168., 163., 163., 163., 175., 163., 182., 167., 162., 186., 164., 162., 162., 162., 161., 163., 164., 161., 162., 162., 162., 161., 162., 164., 168., 161., 162., 161., 163., 162., 162., 162., 181., 168., 167., 165., 165., 165., 165., 164., 165., 166., 165., 165., 165., 166., 164., 166., 165.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",153,153,0,50,"encoder/3/1/attention/1/key/Net","encoder/3/1/attention/1/key/Net","encoder/3/1/attention/1/key/Net","Linear","Linear","Linear",21.,24.200000000000003,68.,"{68., 32., 30., 29., 29., 24., 28., 22., 21., 22., 21., 21., 22., 21., 29., 22., 22., 22., 21., 22., 21., 22., 21., 28., 23., 22., 21., 29., 42., 33., 25., 26., 24., 24., 24., 24., 25., 24., 43., 33., 25., 24., 24., 24., 24., 24., 24., 24., 32., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",154,154,0,50,"encoder/3/1/attention/1/query/Net","encoder/3/1/attention/1/query/Net","encoder/3/1/attention/1/query/Net","Linear","Linear","Linear",21.,23.9667,61.,"{61., 32., 30., 29., 23., 22., 22., 21., 21., 21., 21., 22., 21., 22., 32., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 25., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",155,155,0,50,"encoder/3/1/attention/1/elem","encoder/3/1/attention/1/elem","encoder/3/1/attention/1/elem","Elementwise","Elementwise","Elementwise",18.,18.,42.,"{42., 22., 18., 19., 18., 40., 19., 18., 18., 20., 18., 18., 18., 18., 19., 18., 18., 18., 18., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",156,156,0,50,"encoder/3/1/attention/1/value/Net","encoder/3/1/attention/1/value/Net","encoder/3/1/attention/1/value/Net","Linear","Linear","Linear",21.,23.8333,59.,"{59., 32., 24., 22., 22., 22., 22., 21., 21., 22., 22., 22., 22., 21., 22., 22., 21., 21., 33., 24., 25., 25., 25., 25., 24., 24., 25., 24., 25., 24., 25., 25., 24., 24., 24., 25., 25., 24., 24., 24., 24., 25., 24., 24., 25., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",157,157,0,50,"encoder/3/1/attention/1/attention/ScoringNet/1","encoder/3/1/attention/1/attention/ScoringNet/1","encoder/3/1/attention/1/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3333,45.,"{45., 34., 20., 20., 19., 19., 20., 20., 19., 20., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 19., 20., 30., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",158,158,0,50,"encoder/3/1/attention/2/key/Net","encoder/3/1/attention/2/key/Net","encoder/3/1/attention/2/key/Net","Linear","Linear","Linear",21.,21.3333,59.,"{59., 32., 24., 22., 22., 22., 21., 21., 22., 22., 21., 22., 21., 21., 21., 22., 21., 21., 22., 22., 21., 21., 22., 21., 22., 21., 21., 21., 21., 21., 22., 21., 22., 21., 21., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 22., 22., 21., 22.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",159,159,0,50,"encoder/3/1/attention/2/query/Net","encoder/3/1/attention/2/query/Net","encoder/3/1/attention/2/query/Net","Linear","Linear","Linear",21.,24.,57.,"{57., 31., 24., 22., 22., 21., 21., 22., 21., 22., 21., 21., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 44., 34., 32., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 32., 32., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",160,160,0,50,"encoder/3/1/attention/2/elem","encoder/3/1/attention/2/elem","encoder/3/1/attention/2/elem","Elementwise","Elementwise","Elementwise",18.,18.2333,41.,"{39., 21., 19., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 19., 18., 18., 19., 19., 19., 19., 19., 41., 20., 18., 18., 18., 18., 18., 19., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",161,161,0,50,"encoder/3/1/attention/2/value/Net","encoder/3/1/attention/2/value/Net","encoder/3/1/attention/2/value/Net","Linear","Linear","Linear",21.,24.166700000000002,59.,"{59., 32., 23., 22., 21., 21., 21., 21., 22., 22., 21., 34., 24., 24., 25., 24., 24., 24., 24., 54., 26., 25., 24., 24., 24., 25., 25., 24., 25., 24., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 25., 25., 24., 24., 24., 25., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",162,162,0,50,"encoder/3/1/attention/2/attention/ScoringNet/1","encoder/3/1/attention/2/attention/ScoringNet/1","encoder/3/1/attention/2/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2667,44.,"{44., 22., 20., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 20., 19., 19., 20., 20., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",163,163,0,50,"encoder/3/1/attention/3/key/Net","encoder/3/1/attention/3/key/Net","encoder/3/1/attention/3/key/Net","Linear","Linear","Linear",21.,23.9667,70.,"{48., 31., 23., 21., 21., 21., 22., 22., 21., 21., 22., 21., 21., 22., 70., 36., 33., 25., 25., 24., 24., 24., 24., 25., 24., 24., 25., 24., 24., 24., 25., 24., 24., 24., 25., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",164,164,0,50,"encoder/3/1/attention/3/query/Net","encoder/3/1/attention/3/query/Net","encoder/3/1/attention/3/query/Net","Linear","Linear","Linear",21.,24.133300000000002,46.,"{46., 41., 30., 30., 22., 21., 22., 22., 21., 44., 32., 29., 22., 21., 21., 21., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 25., 24., 24., 25., 25., 24., 24., 24., 24., 33.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",165,165,0,50,"encoder/3/1/attention/3/elem","encoder/3/1/attention/3/elem","encoder/3/1/attention/3/elem","Elementwise","Elementwise","Elementwise",18.,18.3667,40.,"{40., 21., 19., 18., 18., 18., 19., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 19., 18., 18., 19., 19., 18., 19., 18., 18., 18., 19., 19., 18., 19., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 19., 19., 19., 19., 18., 18., 19., 19., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",166,166,0,50,"encoder/3/1/attention/3/value/Net","encoder/3/1/attention/3/value/Net","encoder/3/1/attention/3/value/Net","Linear","Linear","Linear",24.,24.3667,60.,"{60., 32., 30., 33., 33., 26., 46., 28., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 52., 25., 24., 25., 25., 24., 32., 25., 25., 25., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",167,167,0,50,"encoder/3/1/attention/3/attention/ScoringNet/1","encoder/3/1/attention/3/attention/ScoringNet/1","encoder/3/1/attention/3/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3333,45.,"{45., 23., 20., 20., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 20., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",168,168,0,50,"encoder/3/1/attention/4/key/Net","encoder/3/1/attention/4/key/Net","encoder/3/1/attention/4/key/Net","Linear","Linear","Linear",21.,21.8,58.,"{58., 32., 30., 29., 23., 22., 21., 22., 22., 21., 22., 21., 21., 21., 22., 21., 22., 21., 22., 21., 21., 22., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21., 45., 31., 22., 22., 22., 21., 21., 22., 21., 34., 24., 25., 24., 24., 25., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",169,169,0,50,"encoder/3/1/attention/4/query/Net","encoder/3/1/attention/4/query/Net","encoder/3/1/attention/4/query/Net","Linear","Linear","Linear",21.,24.433300000000003,82.,"{82., 35., 23., 22., 21., 21., 21., 22., 21., 22., 21., 58., 26., 25., 25., 24., 25., 25., 25., 25., 24., 25., 24., 25., 24., 24., 24., 24., 25., 24., 24., 24., 25., 24., 25., 25., 24., 24., 25., 24., 25., 25., 24., 24., 25., 24., 25., 25., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",170,170,0,50,"encoder/3/1/attention/4/elem","encoder/3/1/attention/4/elem","encoder/3/1/attention/4/elem","Elementwise","Elementwise","Elementwise",18.,18.,39.,"{39., 21., 19., 18., 19., 18., 18., 18., 18., 19., 19., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",171,171,0,50,"encoder/3/1/attention/4/value/Net","encoder/3/1/attention/4/value/Net","encoder/3/1/attention/4/value/Net","Linear","Linear","Linear",21.,26.6,64.,"{58., 32., 23., 29., 28., 22., 21., 22., 34., 64., 38., 33., 25., 24., 24., 24., 24., 31., 26., 24., 32., 32., 25., 31., 24., 24., 25., 31., 32., 24., 24., 24., 32., 33., 32., 25., 31., 24., 25., 24., 31., 26., 24., 24., 24., 24., 24., 25., 24., 32.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",172,172,0,50,"encoder/3/1/attention/4/attention/ScoringNet/1","encoder/3/1/attention/4/attention/ScoringNet/1","encoder/3/1/attention/4/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.5333,51.,"{45., 34., 20., 20., 19., 20., 19., 20., 19., 20., 19., 19., 19., 20., 19., 20., 51., 21., 19., 20., 20., 19., 20., 19., 20., 19., 20., 20., 19., 20., 20., 19., 20., 19., 20., 19., 19., 19., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",173,173,0,50,"encoder/3/1/attention/5/key/Net","encoder/3/1/attention/5/key/Net","encoder/3/1/attention/5/key/Net","Linear","Linear","Linear",21.,24.133300000000002,59.,"{59., 31., 30., 24., 21., 21., 21., 33., 25., 25., 24., 24., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 37., 26., 24., 24., 24., 24., 24., 24., 24., 24., 24., 26., 23., 24., 24., 24., 24., 24., 25., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",174,174,0,50,"encoder/3/1/attention/5/query/Net","encoder/3/1/attention/5/query/Net","encoder/3/1/attention/5/query/Net","Linear","Linear","Linear",21.,24.0667,49.,"{47., 31., 37., 24., 24., 24., 33., 32., 32., 24., 24., 24., 24., 24., 24., 49., 26., 24., 24., 24., 24., 37., 22., 32., 21., 21., 21., 21., 33., 23., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 23., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",175,175,0,50,"encoder/3/1/attention/5/elem","encoder/3/1/attention/5/elem","encoder/3/1/attention/5/elem","Elementwise","Elementwise","Elementwise",18.,18.0333,38.,"{38., 21., 19., 18., 18., 19., 18., 31., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 25., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",176,176,0,50,"encoder/3/1/attention/5/value/Net","encoder/3/1/attention/5/value/Net","encoder/3/1/attention/5/value/Net","Linear","Linear","Linear",21.,23.900000000000002,58.,"{58., 32., 30., 22., 22., 22., 22., 23., 22., 21., 21., 21., 25., 24., 25., 24., 24., 24., 25., 25., 24., 24., 24., 25., 25., 25., 24., 25., 24., 24., 24., 25., 37., 23., 32., 21., 22., 22., 28., 29., 22., 22., 22., 22., 34., 25., 25., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",177,177,0,50,"encoder/3/1/attention/5/attention/ScoringNet/1","encoder/3/1/attention/5/attention/ScoringNet/1","encoder/3/1/attention/5/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3333,44.,"{44., 33., 20., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19., 20., 19., 20., 19., 19., 19., 20., 25., 20., 19., 19., 19., 19., 19., 19., 19., 20., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 40., 21., 20., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",178,178,0,50,"encoder/3/1/attention/6/key/Net","encoder/3/1/attention/6/key/Net","encoder/3/1/attention/6/key/Net","Linear","Linear","Linear",22.,24.200000000000003,47.,"{47., 31., 23., 22., 34., 25., 24., 24., 24., 24., 24., 24., 25., 24., 24., 25., 25., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 25., 47., 33., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",179,179,0,50,"encoder/3/1/attention/6/query/Net","encoder/3/1/attention/6/query/Net","encoder/3/1/attention/6/query/Net","Linear","Linear","Linear",21.,24.5,58.,"{58., 32., 30., 29., 23., 22., 22., 21., 33., 24., 24., 24., 25., 32., 27., 25., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 26., 24., 50., 34., 34., 27., 25., 24., 24., 24., 32., 25., 25., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",180,180,0,50,"encoder/3/1/attention/6/elem","encoder/3/1/attention/6/elem","encoder/3/1/attention/6/elem","Elementwise","Elementwise","Elementwise",18.,18.2,44.,"{39., 21., 19., 19., 18., 19., 18., 44., 20., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 19., 19., 19., 18., 18., 18., 18., 18., 19., 18., 18., 19., 19., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",181,181,0,50,"encoder/3/1/attention/6/value/Net","encoder/3/1/attention/6/value/Net","encoder/3/1/attention/6/value/Net","Linear","Linear","Linear",22.,24.,59.,"{59., 31., 24., 22., 22., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 33., 32., 32., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",182,182,0,50,"encoder/3/1/attention/6/attention/ScoringNet/1","encoder/3/1/attention/6/attention/ScoringNet/1","encoder/3/1/attention/6/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.400000000000002,57.,"{45., 35., 20., 20., 20., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 57., 22., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",183,183,0,50,"encoder/3/1/attention/7/key/Net","encoder/3/1/attention/7/key/Net","encoder/3/1/attention/7/key/Net","Linear","Linear","Linear",21.,23.700000000000003,59.,"{59., 32., 24., 22., 22., 21., 22., 21., 22., 22., 21., 22., 21., 21., 21., 32., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 23., 24., 23.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",184,184,0,50,"encoder/3/1/attention/7/query/Net","encoder/3/1/attention/7/query/Net","encoder/3/1/attention/7/query/Net","Linear","Linear","Linear",21.,21.2,60.,"{60., 32., 29., 24., 22., 21., 21., 22., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 22., 21., 21., 21., 21., 22., 21., 21., 22., 21., 21., 22., 21., 22., 21., 21., 21., 21., 21., 22., 21., 22., 21., 21., 47.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",185,185,0,50,"encoder/3/1/attention/7/elem","encoder/3/1/attention/7/elem","encoder/3/1/attention/7/elem","Elementwise","Elementwise","Elementwise",18.,18.,63.,"{63., 22., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",186,186,0,50,"encoder/3/1/attention/7/value/Net","encoder/3/1/attention/7/value/Net","encoder/3/1/attention/7/value/Net","Linear","Linear","Linear",21.,23.7333,59.,"{59., 26., 22., 22., 22., 22., 22., 21., 21., 22., 22., 21., 22., 21., 21., 22., 22., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 34., 33., 45., 33., 32.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",187,187,0,50,"encoder/3/1/attention/7/attention/ScoringNet/1","encoder/3/1/attention/7/attention/ScoringNet/1","encoder/3/1/attention/7/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2333,45.,"{45., 33., 20., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 20., 20., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",188,188,0,50,"encoder/3/1/attention/8/key/Net","encoder/3/1/attention/8/key/Net","encoder/3/1/attention/8/key/Net","Linear","Linear","Linear",21.,24.,60.,"{60., 32., 23., 22., 22., 22., 22., 22., 21., 21., 22., 21., 21., 33., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 25., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",189,189,0,50,"encoder/3/1/attention/8/query/Net","encoder/3/1/attention/8/query/Net","encoder/3/1/attention/8/query/Net","Linear","Linear","Linear",24.,24.3,70.,"{47., 32., 37., 24., 24., 24., 25., 24., 24., 24., 25., 25., 24., 24., 24., 25., 24., 25., 24., 24., 24., 24., 24., 25., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 25., 25., 25., 70., 27., 24., 24., 32.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",190,190,0,50,"encoder/3/1/attention/8/elem","encoder/3/1/attention/8/elem","encoder/3/1/attention/8/elem","Elementwise","Elementwise","Elementwise",18.,18.3667,42.,"{39., 22., 19., 18., 18., 19., 19., 18., 18., 19., 19., 42., 19., 19., 19., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 19., 31., 20., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 19., 19., 19., 19., 18., 19., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",191,191,0,50,"encoder/3/1/attention/8/value/Net","encoder/3/1/attention/8/value/Net","encoder/3/1/attention/8/value/Net","Linear","Linear","Linear",21.,23.900000000000002,67.,"{58., 31., 29., 29., 24., 21., 21., 22., 22., 22., 22., 21., 21., 22., 21., 21., 22., 21., 32., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 25., 25., 24., 67., 27., 24., 25., 24., 24., 24., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",192,192,0,50,"encoder/3/1/attention/8/attention/ScoringNet/1","encoder/3/1/attention/8/attention/ScoringNet/1","encoder/3/1/attention/8/attention/ScoringNet/1","Dot","Dot","Dot",18.,19.2667,44.,"{44., 34., 20., 19., 20., 19., 20., 20., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 20., 20., 19., 20., 19., 19., 19., 19., 19., 19., 20., 18., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",193,193,0,50,"encoder/3/1/attention/9/key/Net","encoder/3/1/attention/9/key/Net","encoder/3/1/attention/9/key/Net","Linear","Linear","Linear",21.,24.,60.,"{60., 31., 30., 29., 29., 29., 23., 22., 22., 21., 22., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 35.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",194,194,0,50,"encoder/3/1/attention/9/query/Net","encoder/3/1/attention/9/query/Net","encoder/3/1/attention/9/query/Net","Linear","Linear","Linear",21.,23.4667,58.,"{58., 31., 23., 21., 22., 23., 22., 22., 21., 22., 21., 23., 22., 21., 23., 22., 21., 22., 22., 21., 22., 21., 34., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 26., 24., 24., 32., 24., 25., 25., 24., 25., 24., 24., 26., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",195,195,0,50,"encoder/3/1/attention/9/elem","encoder/3/1/attention/9/elem","encoder/3/1/attention/9/elem","Elementwise","Elementwise","Elementwise",17.,18.2,42.,"{40., 21., 19., 18., 19., 18., 18., 18., 19., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 19., 18., 19., 42., 20., 19., 18., 18., 22., 22., 18., 27., 18., 19., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",196,196,0,50,"encoder/3/1/attention/9/value/Net","encoder/3/1/attention/9/value/Net","encoder/3/1/attention/9/value/Net","Linear","Linear","Linear",21.,24.3667,58.,"{58., 32., 29., 29., 29., 29., 29., 53., 32., 22., 22., 21., 22., 23., 41., 25., 25., 24., 25., 24., 24., 24., 25., 25., 24., 24., 24., 25., 24., 24., 25., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",197,197,0,50,"encoder/3/1/attention/9/attention/ScoringNet/1","encoder/3/1/attention/9/attention/ScoringNet/1","encoder/3/1/attention/9/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3333,44.,"{44., 22., 20., 19., 20., 19., 20., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 19., 19., 19., 19., 19., 20., 19., 20., 19., 20., 19., 19., 19., 19., 20., 21., 25., 19., 20., 19., 19., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",198,198,0,50,"encoder/3/1/attention/10/key/Net","encoder/3/1/attention/10/key/Net","encoder/3/1/attention/10/key/Net","Linear","Linear","Linear",21.,27.166700000000002,59.,"{59., 32., 43., 27., 24., 25., 33., 25., 24., 24., 25., 24., 32., 25., 32., 25., 24., 24., 25., 32., 32., 37., 39., 22., 22., 21., 22., 28., 28., 21., 22., 21., 33., 24., 32., 33., 25., 24., 32., 32., 25., 24., 24., 24., 32., 32., 27., 45., 33., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",199,199,0,50,"encoder/3/1/attention/10/query/Net","encoder/3/1/attention/10/query/Net","encoder/3/1/attention/10/query/Net","Linear","Linear","Linear",21.,24.,57.,"{57., 31., 31., 30., 22., 22., 22., 21., 22., 32., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 25., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",200,200,0,50,"encoder/3/1/attention/10/elem","encoder/3/1/attention/10/elem","encoder/3/1/attention/10/elem","Elementwise","Elementwise","Elementwise",17.,18.2667,44.,"{39., 22., 19., 18., 18., 19., 19., 19., 18., 18., 19., 19., 18., 19., 18., 18., 18., 18., 18., 18., 18., 19., 19., 19., 44., 20., 19., 18., 17., 18., 18., 18., 18., 36., 20., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",201,201,0,50,"encoder/3/1/attention/10/value/Net","encoder/3/1/attention/10/value/Net","encoder/3/1/attention/10/value/Net","Linear","Linear","Linear",21.,24.3,58.,"{58., 32., 23., 22., 22., 21., 22., 22., 22., 21., 21., 22., 34., 36., 25., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 32., 32., 25., 25., 24., 32., 25., 25., 24., 24., 24., 25., 25., 24., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",202,202,0,50,"encoder/3/1/attention/10/attention/ScoringNet/1","encoder/3/1/attention/10/attention/ScoringNet/1","encoder/3/1/attention/10/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2667,44.,"{44., 34., 20., 20., 19., 19., 20., 19., 19., 20., 20., 20., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 20., 41., 21., 19., 20., 19., 20., 20., 19., 19., 19., 20., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",203,203,0,50,"encoder/3/1/attention/11/key/Net","encoder/3/1/attention/11/key/Net","encoder/3/1/attention/11/key/Net","Linear","Linear","Linear",21.,23.5,58.,"{58., 31., 50., 30., 29., 29., 30., 29., 30., 23., 21., 22., 22., 21., 22., 21., 21., 22., 21., 22., 22., 21., 21., 21., 21., 21., 21., 34., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",204,204,0,50,"encoder/3/1/attention/11/query/Net","encoder/3/1/attention/11/query/Net","encoder/3/1/attention/11/query/Net","Linear","Linear","Linear",24.,27.133300000000002,58.,"{58., 32., 38., 33., 34., 27., 25., 32., 25., 24., 32., 33., 32., 26., 24., 24., 25., 24., 24., 25., 25., 24., 24., 24., 25., 24., 24., 24., 25., 24., 24., 32., 32., 32., 42., 27., 24., 24., 36., 34., 33., 26., 38., 33., 33., 25., 25., 24., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",205,205,0,50,"encoder/3/1/attention/11/elem","encoder/3/1/attention/11/elem","encoder/3/1/attention/11/elem","Elementwise","Elementwise","Elementwise",18.,18.166700000000002,42.,"{39., 21., 19., 18., 19., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 19., 19., 19., 19., 18., 18., 18., 18., 42., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 19., 20., 19., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",206,206,0,50,"encoder/3/1/attention/11/value/Net","encoder/3/1/attention/11/value/Net","encoder/3/1/attention/11/value/Net","Linear","Linear","Linear",21.,24.2667,58.,"{58., 32., 30., 29., 30., 22., 22., 22., 22., 21., 21., 29., 22., 22., 22., 28., 29., 23., 23., 46., 23., 21., 21., 21., 21., 22., 28., 23., 34., 24., 24., 24., 24., 24., 24., 24., 25., 42., 25., 25., 33., 25., 25., 24., 25., 25., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",207,207,0,50,"encoder/3/1/attention/11/attention/ScoringNet/1","encoder/3/1/attention/11/attention/ScoringNet/1","encoder/3/1/attention/11/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.4667,43.,"{43., 34., 20., 20., 20., 19., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 19., 19., 20., 19., 20., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",208,208,0,50,"encoder/3/1/attention/12/key/Net","encoder/3/1/attention/12/key/Net","encoder/3/1/attention/12/key/Net","Linear","Linear","Linear",21.,24.2667,58.,"{47., 31., 29., 29., 30., 22., 22., 22., 22., 21., 58., 26., 24., 25., 24., 25., 25., 24., 24., 24., 24., 25., 25., 24., 24., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 25., 24., 24., 25., 24., 24., 24., 24., 25., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",209,209,0,50,"encoder/3/1/attention/12/query/Net","encoder/3/1/attention/12/query/Net","encoder/3/1/attention/12/query/Net","Linear","Linear","Linear",21.,23.666700000000002,64.,"{58., 31., 30., 30., 28., 22., 21., 21., 22., 22., 22., 22., 21., 21., 21., 22., 21., 21., 21., 22., 22., 22., 33., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 25., 25., 24., 24., 24., 24., 24., 26., 23., 64., 28., 24., 26.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",210,210,0,50,"encoder/3/1/attention/12/elem","encoder/3/1/attention/12/elem","encoder/3/1/attention/12/elem","Elementwise","Elementwise","Elementwise",18.,18.0667,39.,"{39., 21., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 19., 19., 19., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",211,211,0,50,"encoder/3/1/attention/12/value/Net","encoder/3/1/attention/12/value/Net","encoder/3/1/attention/12/value/Net","Linear","Linear","Linear",24.,24.433300000000003,61.,"{59., 32., 24., 34., 24., 25., 24., 24., 25., 24., 25., 24., 24., 24., 25., 24., 24., 25., 24., 24., 25., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 25., 61., 25., 25., 24., 25., 24., 24., 59., 35., 32., 25., 32., 32., 24., 25., 24., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",212,212,0,50,"encoder/3/1/attention/12/attention/ScoringNet/1","encoder/3/1/attention/12/attention/ScoringNet/1","encoder/3/1/attention/12/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.133300000000002,44.,"{44., 33., 20., 20., 19., 19., 19., 20., 20., 19., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 20., 20., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 20., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",213,213,0,50,"encoder/3/1/attention/13","encoder/3/1/attention/13","encoder/3/1/attention/13","Catenate","Catenate","Catenate",55.,56.,79.,"{79., 59., 56., 56., 56., 56., 56., 57., 56., 56., 56., 56., 56., 56., 55., 56., 56., 56., 56., 56., 56., 56., 57., 56., 57., 56., 55., 56., 56., 56., 55., 56., 56., 57., 56., 78., 59., 56., 56., 56., 56., 57., 56., 56., 56., 56., 56., 56., 57., 56.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",214,214,0,50,"encoder/3/1/attention/14/Net","encoder/3/1/attention/14/Net","encoder/3/1/attention/14/Net","Linear","Linear","Linear",137.,138.8333,235.,"{235., 200., 147., 140., 138., 138., 139., 149., 139., 138., 140., 159., 140., 139., 138., 137., 139., 139., 138., 163., 140., 138., 138., 139., 139., 138., 138., 140., 138., 139., 139., 138., 138., 139., 138., 139., 139., 138., 140., 139., 138., 138., 137., 138., 138., 140., 164., 140., 140., 138.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",215,215,0,50,"encoder/3/1/dropout","encoder/3/1/dropout","encoder/3/1/dropout","Dropout","Dropout","Dropout",18.,18.133300000000002,45.,"{37., 45., 20., 19., 18., 18., 18., 19., 18., 25., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 21., 18., 19., 19., 18., 19., 18., 18., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",216,217,1,50,"encoder/3/1/add","encoder/3/1/norm","encoder/3/1/add-encoder/3/1/norm","Threading","Normalization","Threading-Normalization",161.,162.66670000000002,213.,"{213., 167., 164., 161., 185., 164., 162., 163., 182., 166., 164., 163., 163., 163., 163., 163., 161., 170., 163., 162., 162., 162., 177., 166., 163., 162., 162., 163., 189., 164., 162., 162., 163., 162., 163., 162., 162., 162., 163., 163., 162., 162., 161., 162., 161., 161., 163., 162., 162., 161.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",218,218,0,50,"encoder/3/2/linear1/Net","encoder/3/2/linear1/Net","encoder/3/2/linear1/Net","Linear","Linear","Linear",440.,446.6,757.,"{751., 757., 544., 468., 447., 446., 443., 442., 443., 442., 440., 477., 444., 465., 444., 442., 453., 441., 457., 441., 467., 442., 442., 442., 442., 441., 441., 441., 461., 447., 447., 447., 447., 447., 447., 459., 449., 474., 456., 445., 450., 446., 444., 442., 444., 445., 468., 445., 444., 444.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",219,219,0,50,"encoder/3/2/gelu","encoder/3/2/gelu","encoder/3/2/gelu","Elementwise","Elementwise","Elementwise",104.,105.2667,135.,"{135., 108., 119., 110., 106., 105., 105., 105., 129., 108., 106., 105., 105., 105., 105., 105., 106., 105., 105., 104., 105., 105., 106., 105., 105., 105., 105., 105., 105., 105., 105., 105., 106., 105., 105., 105., 105., 105., 106., 105., 105., 106., 105., 105., 122., 107., 106., 106., 105., 106.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",220,220,0,50,"encoder/3/2/linear2/Net","encoder/3/2/linear2/Net","encoder/3/2/linear2/Net","Linear","Linear","Linear",432.,436.7667,505.,"{505., 479., 445., 435., 461., 436., 433., 433., 433., 432., 432., 433., 433., 461., 436., 434., 455., 433., 443., 433., 433., 449., 459., 438., 436., 436., 436., 435., 435., 434., 435., 462., 436., 435., 435., 435., 436., 436., 448., 437., 468., 436., 436., 442., 436., 435., 436., 435., 435., 461.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",221,221,0,50,"encoder/3/2/dropout","encoder/3/2/dropout","encoder/3/2/dropout","Dropout","Dropout","Dropout",18.,19.,40.,"{40., 22., 20., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 18., 19., 19., 18., 19., 18., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 18., 19., 19., 18., 19., 19., 19., 19., 19., 18., 19., 19., 30., 22., 19., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",222,223,1,50,"encoder/3/2/add","encoder/3/2/norm","encoder/3/2/add-encoder/3/2/norm","Threading","Normalization","Threading-Normalization",161.,162.66670000000002,245.,"{245., 170., 165., 162., 164., 162., 162., 162., 161., 163., 164., 161., 163., 161., 162., 162., 163., 161., 163., 161., 184., 167., 163., 182., 173., 163., 163., 164., 163., 162., 161., 162., 162., 174., 162., 162., 163., 162., 161., 161., 163., 163., 163., 161., 163., 163., 162., 190., 163., 163.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",224,224,0,50,"encoder/4/1/attention/1/key/Net","encoder/4/1/attention/1/key/Net","encoder/4/1/attention/1/key/Net","Linear","Linear","Linear",24.,24.2333,68.,"{68., 32., 30., 43., 33., 33., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 56., 25., 25., 24., 32., 24., 24., 24., 24., 35., 33., 25., 24., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",225,225,0,50,"encoder/4/1/attention/1/query/Net","encoder/4/1/attention/1/query/Net","encoder/4/1/attention/1/query/Net","Linear","Linear","Linear",21.,24.3667,61.,"{61., 32., 23., 22., 22., 22., 34., 25., 25., 25., 25., 24., 24., 25., 24., 24., 24., 25., 24., 24., 24., 25., 24., 24., 24., 25., 25., 25., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 25., 25., 25., 24., 26., 23., 33., 21., 21., 22., 22., 33.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",226,226,0,50,"encoder/4/1/attention/1/elem","encoder/4/1/attention/1/elem","encoder/4/1/attention/1/elem","Elementwise","Elementwise","Elementwise",17.,18.0333,42.,"{42., 21., 18., 19., 18., 18., 19., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 17., 18., 19., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 19., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",227,227,0,50,"encoder/4/1/attention/1/value/Net","encoder/4/1/attention/1/value/Net","encoder/4/1/attention/1/value/Net","Linear","Linear","Linear",21.,24.0333,59.,"{59., 31., 24., 23., 35., 29., 22., 22., 22., 21., 21., 22., 21., 22., 34., 24., 24., 24., 25., 25., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 58., 34.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",228,228,0,50,"encoder/4/1/attention/1/attention/ScoringNet/1","encoder/4/1/attention/1/attention/ScoringNet/1","encoder/4/1/attention/1/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.166700000000002,45.,"{45., 45., 23., 20., 20., 19., 20., 20., 19., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 20., 20., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",229,229,0,50,"encoder/4/1/attention/2/key/Net","encoder/4/1/attention/2/key/Net","encoder/4/1/attention/2/key/Net","Linear","Linear","Linear",21.,24.5333,60.,"{60., 31., 24., 22., 22., 22., 22., 28., 22., 22., 23., 22., 22., 21., 21., 33., 24., 25., 24., 24., 25., 24., 25., 25., 25., 25., 25., 25., 60., 38., 26., 24., 24., 24., 47., 35., 32., 34., 25., 24., 33., 24., 24., 26., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",230,230,0,50,"encoder/4/1/attention/2/query/Net","encoder/4/1/attention/2/query/Net","encoder/4/1/attention/2/query/Net","Linear","Linear","Linear",21.,23.7667,59.,"{59., 31., 30., 22., 22., 22., 21., 21., 22., 21., 22., 21., 21., 21., 21., 21., 33., 24., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",231,231,0,50,"encoder/4/1/attention/2/elem","encoder/4/1/attention/2/elem","encoder/4/1/attention/2/elem","Elementwise","Elementwise","Elementwise",18.,18.,40.,"{40., 21., 20., 18., 18., 19., 26., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",232,232,0,50,"encoder/4/1/attention/2/value/Net","encoder/4/1/attention/2/value/Net","encoder/4/1/attention/2/value/Net","Linear","Linear","Linear",21.,23.4667,61.,"{61., 32., 24., 22., 22., 21., 22., 22., 22., 21., 22., 21., 21., 22., 21., 21., 22., 22., 21., 22., 21., 33., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",233,233,0,50,"encoder/4/1/attention/2/attention/ScoringNet/1","encoder/4/1/attention/2/attention/ScoringNet/1","encoder/4/1/attention/2/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.5,50.,"{45., 34., 20., 20., 20., 50., 21., 22., 20., 20., 19., 20., 19., 20., 27., 20., 20., 19., 20., 19., 20., 19., 19., 19., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",234,234,0,50,"encoder/4/1/attention/3/key/Net","encoder/4/1/attention/3/key/Net","encoder/4/1/attention/3/key/Net","Linear","Linear","Linear",23.,24.0667,59.,"{59., 33., 36., 25., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 26., 24., 24., 24., 24., 23., 25., 24., 24., 24., 24., 24., 37., 33., 25., 24., 25., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",235,235,0,50,"encoder/4/1/attention/3/query/Net","encoder/4/1/attention/3/query/Net","encoder/4/1/attention/3/query/Net","Linear","Linear","Linear",21.,24.2667,58.,"{58., 35., 31., 45., 27., 25., 25., 25., 24., 25., 32., 25., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 36., 21., 21., 21., 22., 22., 21., 21., 33., 24., 24., 24., 24., 25., 24., 25., 25., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",236,236,0,50,"encoder/4/1/attention/3/elem","encoder/4/1/attention/3/elem","encoder/4/1/attention/3/elem","Elementwise","Elementwise","Elementwise",18.,18.,39.,"{39., 21., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 19., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",237,237,0,50,"encoder/4/1/attention/3/value/Net","encoder/4/1/attention/3/value/Net","encoder/4/1/attention/3/value/Net","Linear","Linear","Linear",21.,24.,61.,"{61., 32., 23., 22., 22., 21., 21., 21., 21., 21., 22., 21., 32., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 25., 24., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",238,238,0,50,"encoder/4/1/attention/3/attention/ScoringNet/1","encoder/4/1/attention/3/attention/ScoringNet/1","encoder/4/1/attention/3/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3667,44.,"{44., 33., 20., 19., 20., 19., 20., 20., 19., 20., 19., 20., 19., 19., 19., 20., 41., 21., 19., 19., 19., 20., 19., 20., 20., 19., 19., 20., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 20., 20., 19., 19., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",239,239,0,50,"encoder/4/1/attention/4/key/Net","encoder/4/1/attention/4/key/Net","encoder/4/1/attention/4/key/Net","Linear","Linear","Linear",21.,24.4667,59.,"{59., 32., 36., 27., 32., 32., 33., 33., 25., 24., 25., 25., 25., 24., 25., 25., 24., 25., 24., 24., 24., 24., 32., 22., 21., 21., 22., 22., 22., 33., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 56., 25., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",240,240,0,50,"encoder/4/1/attention/4/query/Net","encoder/4/1/attention/4/query/Net","encoder/4/1/attention/4/query/Net","Linear","Linear","Linear",22.,25.133300000000002,68.,"{46., 43., 23., 22., 22., 22., 33., 25., 36., 27., 24., 24., 24., 33., 68., 35., 33., 32., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 34., 33., 32., 32., 26., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",241,241,0,50,"encoder/4/1/attention/4/elem","encoder/4/1/attention/4/elem","encoder/4/1/attention/4/elem","Elementwise","Elementwise","Elementwise",17.,18.,39.,"{39., 21., 18., 19., 18., 19., 18., 18., 18., 18., 18., 18., 19., 18., 18., 19., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 17., 18., 17., 18., 18., 19., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",242,242,0,50,"encoder/4/1/attention/4/value/Net","encoder/4/1/attention/4/value/Net","encoder/4/1/attention/4/value/Net","Linear","Linear","Linear",21.,24.0333,58.,"{58., 32., 23., 31., 22., 21., 22., 54., 34., 32., 34., 32., 25., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 23., 25., 24., 24., 24., 23., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",243,243,0,50,"encoder/4/1/attention/4/attention/ScoringNet/1","encoder/4/1/attention/4/attention/ScoringNet/1","encoder/4/1/attention/4/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.166700000000002,45.,"{45., 34., 20., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 45., 20., 19., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 20., 19., 19., 19., 19., 19., 20., 19., 20., 20., 20., 19., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",244,244,0,50,"encoder/4/1/attention/5/key/Net","encoder/4/1/attention/5/key/Net","encoder/4/1/attention/5/key/Net","Linear","Linear","Linear",21.,23.6,57.,"{57., 32., 24., 43., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 25., 24., 24., 24., 25., 24., 24., 24., 25., 23., 24., 24., 24., 24., 32., 22., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",245,245,0,50,"encoder/4/1/attention/5/query/Net","encoder/4/1/attention/5/query/Net","encoder/4/1/attention/5/query/Net","Linear","Linear","Linear",21.,23.9667,59.,"{59., 32., 24., 22., 21., 21., 21., 21., 22., 22., 22., 21., 21., 22., 21., 29., 35., 25., 25., 24., 24., 25., 24., 24., 24., 25., 24., 24., 24., 24., 25., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 25., 24., 24., 25., 24., 24., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",246,246,0,50,"encoder/4/1/attention/5/elem","encoder/4/1/attention/5/elem","encoder/4/1/attention/5/elem","Elementwise","Elementwise","Elementwise",17.,17.9667,38.,"{38., 21., 19., 18., 18., 18., 17., 17., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 17., 18., 17., 18., 18., 17., 18., 18., 18., 18., 17., 18., 17., 18., 18., 18., 18., 18., 17., 18., 17., 18., 17., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",247,247,0,50,"encoder/4/1/attention/5/value/Net","encoder/4/1/attention/5/value/Net","encoder/4/1/attention/5/value/Net","Linear","Linear","Linear",21.,24.8667,59.,"{59., 31., 30., 43., 32., 34., 34., 33., 32., 33., 26., 32., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 25., 24., 24., 32., 22., 21., 21., 21., 21., 33.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",248,248,0,50,"encoder/4/1/attention/5/attention/ScoringNet/1","encoder/4/1/attention/5/attention/ScoringNet/1","encoder/4/1/attention/5/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3333,45.,"{45., 34., 21., 20., 19., 20., 19., 20., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 43., 22., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 20., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",249,249,0,50,"encoder/4/1/attention/6/key/Net","encoder/4/1/attention/6/key/Net","encoder/4/1/attention/6/key/Net","Linear","Linear","Linear",21.,24.,68.,"{66., 32., 23., 22., 21., 21., 21., 32., 25., 24., 24., 24., 24., 68., 36., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 25., 23., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",250,250,0,50,"encoder/4/1/attention/6/query/Net","encoder/4/1/attention/6/query/Net","encoder/4/1/attention/6/query/Net","Linear","Linear","Linear",23.,24.3333,46.,"{46., 32., 36., 24., 25., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 35., 27., 24., 25., 25., 24., 24., 24., 24., 25., 23., 25., 32., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 25., 25., 25., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",251,251,0,50,"encoder/4/1/attention/6/elem","encoder/4/1/attention/6/elem","encoder/4/1/attention/6/elem","Elementwise","Elementwise","Elementwise",17.,18.,40.,"{40., 20., 20., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",252,252,0,50,"encoder/4/1/attention/6/value/Net","encoder/4/1/attention/6/value/Net","encoder/4/1/attention/6/value/Net","Linear","Linear","Linear",21.,24.,47.,"{47., 32., 22., 21., 34., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",253,253,0,50,"encoder/4/1/attention/6/attention/ScoringNet/1","encoder/4/1/attention/6/attention/ScoringNet/1","encoder/4/1/attention/6/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.400000000000002,44.,"{44., 22., 20., 20., 20., 19., 19., 20., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 20., 19., 19., 20., 19., 19., 44., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 20., 20., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",254,254,0,50,"encoder/4/1/attention/7/key/Net","encoder/4/1/attention/7/key/Net","encoder/4/1/attention/7/key/Net","Linear","Linear","Linear",21.,24.,59.,"{59., 32., 23., 34., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 26., 23., 33., 22., 21., 21., 21., 21., 33., 24., 24., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",255,255,0,50,"encoder/4/1/attention/7/query/Net","encoder/4/1/attention/7/query/Net","encoder/4/1/attention/7/query/Net","Linear","Linear","Linear",21.,26.166700000000002,58.,"{58., 32., 29., 23., 21., 21., 21., 21., 21., 21., 33., 25., 25., 23., 24., 25., 24., 24., 23., 24., 49., 34., 33., 32., 32., 32., 32., 32., 32., 25., 24., 24., 24., 32., 31., 33., 32., 32., 26., 23., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",256,256,0,50,"encoder/4/1/attention/7/elem","encoder/4/1/attention/7/elem","encoder/4/1/attention/7/elem","Elementwise","Elementwise","Elementwise",17.,18.,38.,"{38., 21., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 27., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",257,257,0,50,"encoder/4/1/attention/7/value/Net","encoder/4/1/attention/7/value/Net","encoder/4/1/attention/7/value/Net","Linear","Linear","Linear",21.,24.,47.,"{47., 32., 29., 29., 24., 21., 21., 22., 21., 34., 25., 24., 24., 25., 25., 25., 23., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",258,258,0,50,"encoder/4/1/attention/7/attention/ScoringNet/1","encoder/4/1/attention/7/attention/ScoringNet/1","encoder/4/1/attention/7/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.133300000000002,46.,"{46., 23., 20., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 20., 20., 19., 19., 19., 19., 19., 20., 19., 42., 21., 20., 19., 19., 19., 19., 19., 27., 20., 19., 19., 19., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",259,259,0,50,"encoder/4/1/attention/8/key/Net","encoder/4/1/attention/8/key/Net","encoder/4/1/attention/8/key/Net","Linear","Linear","Linear",21.,24.8667,59.,"{59., 32., 23., 21., 22., 22., 21., 22., 21., 23., 22., 28., 28., 22., 28., 29., 28., 29., 29., 28., 29., 29., 28., 28., 28., 28., 22., 22., 21., 21., 21., 29., 28., 22., 22., 21., 21., 21., 22., 21., 41., 25., 24., 24., 24., 25., 25., 24., 31., 32.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",260,260,0,50,"encoder/4/1/attention/8/query/Net","encoder/4/1/attention/8/query/Net","encoder/4/1/attention/8/query/Net","Linear","Linear","Linear",21.,24.,57.,"{57., 32., 24., 22., 22., 21., 21., 21., 34., 23., 24., 24., 24., 24., 24., 24., 24., 25., 24., 47., 34., 33., 26., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 23., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",261,261,0,50,"encoder/4/1/attention/8/elem","encoder/4/1/attention/8/elem","encoder/4/1/attention/8/elem","Elementwise","Elementwise","Elementwise",18.,18.166700000000002,39.,"{39., 21., 18., 18., 18., 18., 19., 18., 18., 18., 18., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",262,262,0,50,"encoder/4/1/attention/8/value/Net","encoder/4/1/attention/8/value/Net","encoder/4/1/attention/8/value/Net","Linear","Linear","Linear",21.,24.1,59.,"{59., 33., 29., 29., 29., 23., 21., 21., 21., 21., 22., 22., 24., 25., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24., 24., 25., 25., 25., 24., 24., 24., 24., 24., 24., 26., 23., 32., 21., 22., 22., 21., 22., 21., 22., 22., 34., 38., 33., 32., 34.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",263,263,0,50,"encoder/4/1/attention/8/attention/ScoringNet/1","encoder/4/1/attention/8/attention/ScoringNet/1","encoder/4/1/attention/8/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.166700000000002,44.,"{44., 23., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 20., 19., 42., 21., 19., 20., 19., 19., 20., 19., 19., 19., 20., 20., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",264,264,0,50,"encoder/4/1/attention/9/key/Net","encoder/4/1/attention/9/key/Net","encoder/4/1/attention/9/key/Net","Linear","Linear","Linear",21.,24.,59.,"{59., 31., 29., 28., 29., 23., 22., 33., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 23., 24., 24., 23., 24., 24., 24., 24., 24., 24., 32., 21., 21., 21., 21., 22., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",265,265,0,50,"encoder/4/1/attention/9/query/Net","encoder/4/1/attention/9/query/Net","encoder/4/1/attention/9/query/Net","Linear","Linear","Linear",21.,24.,57.,"{57., 31., 23., 21., 21., 22., 21., 22., 21., 21., 21., 22., 21., 21., 21., 33., 24., 24., 24., 25., 25., 24., 24., 50., 35., 25., 24., 24., 24., 35., 26., 25., 24., 24., 24., 25., 25., 32., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",266,266,0,50,"encoder/4/1/attention/9/elem","encoder/4/1/attention/9/elem","encoder/4/1/attention/9/elem","Elementwise","Elementwise","Elementwise",18.,18.,39.,"{39., 22., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",267,267,0,50,"encoder/4/1/attention/9/value/Net","encoder/4/1/attention/9/value/Net","encoder/4/1/attention/9/value/Net","Linear","Linear","Linear",21.,24.0667,46.,"{46., 43., 29., 24., 29., 23., 22., 21., 21., 22., 21., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 37., 21., 22., 21., 22., 21., 34., 25., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",268,268,0,50,"encoder/4/1/attention/9/attention/ScoringNet/1","encoder/4/1/attention/9/attention/ScoringNet/1","encoder/4/1/attention/9/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.433300000000003,45.,"{42., 23., 21., 19., 20., 19., 20., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 20., 19., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 45., 20., 19., 20., 19., 19., 20., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",269,269,0,50,"encoder/4/1/attention/10/key/Net","encoder/4/1/attention/10/key/Net","encoder/4/1/attention/10/key/Net","Linear","Linear","Linear",21.,21.8333,59.,"{59., 31., 29., 28., 23., 21., 22., 21., 22., 21., 21., 21., 21., 22., 21., 22., 21., 21., 22., 21., 22., 21., 21., 21., 21., 22., 21., 22., 21., 21., 21., 21., 22., 21., 21., 22., 21., 21., 22., 21., 33., 24., 24., 24., 24., 24., 24., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",270,270,0,50,"encoder/4/1/attention/10/query/Net","encoder/4/1/attention/10/query/Net","encoder/4/1/attention/10/query/Net","Linear","Linear","Linear",21.,24.933300000000003,60.,"{57., 32., 29., 28., 23., 21., 22., 21., 21., 22., 21., 22., 21., 22., 21., 22., 21., 22., 21., 29., 29., 23., 21., 21., 32., 24., 24., 32., 32., 26., 24., 24., 24., 60., 33., 33., 32., 33., 32., 32., 26., 25., 25., 25., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",271,271,0,50,"encoder/4/1/attention/10/elem","encoder/4/1/attention/10/elem","encoder/4/1/attention/10/elem","Elementwise","Elementwise","Elementwise",18.,18.2333,38.,"{38., 21., 19., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 19., 18., 19., 18., 18., 18., 18., 18., 21., 19., 18., 18., 18., 18., 18., 18., 18., 19., 19., 19., 19., 19., 19., 18., 18., 18., 19., 18., 18., 18., 18., 19., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",272,272,0,50,"encoder/4/1/attention/10/value/Net","encoder/4/1/attention/10/value/Net","encoder/4/1/attention/10/value/Net","Linear","Linear","Linear",21.,23.0333,58.,"{58., 33., 24., 22., 21., 21., 22., 22., 21., 22., 22., 21., 22., 22., 21., 21., 21., 21., 22., 21., 21., 21., 21., 22., 21., 22., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 25., 24., 25., 25., 25., 24., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",273,273,0,50,"encoder/4/1/attention/10/attention/ScoringNet/1","encoder/4/1/attention/10/attention/ScoringNet/1","encoder/4/1/attention/10/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2667,45.,"{43., 23., 20., 19., 19., 19., 20., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 20., 20., 19., 19., 19., 19., 19., 20., 20., 19., 19., 45., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19., 20., 19., 20., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",274,274,0,50,"encoder/4/1/attention/11/key/Net","encoder/4/1/attention/11/key/Net","encoder/4/1/attention/11/key/Net","Linear","Linear","Linear",21.,24.,47.,"{47., 31., 23., 21., 21., 22., 22., 33., 25., 24., 24., 25., 24., 24., 24., 24., 24., 24., 34., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 25., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",275,275,0,50,"encoder/4/1/attention/11/query/Net","encoder/4/1/attention/11/query/Net","encoder/4/1/attention/11/query/Net","Linear","Linear","Linear",21.,24.133300000000002,58.,"{58., 31., 22., 23., 28., 22., 21., 21., 21., 21., 28., 21., 22., 28., 22., 28., 28., 30., 30., 22., 21., 21., 28., 22., 35., 24., 24., 24., 23., 24., 24., 24., 23., 24., 24., 24., 24., 24., 50., 26., 24., 24., 24., 24., 25., 35., 32., 21., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",276,276,0,50,"encoder/4/1/attention/11/elem","encoder/4/1/attention/11/elem","encoder/4/1/attention/11/elem","Elementwise","Elementwise","Elementwise",18.,18.0667,38.,"{38., 21., 19., 19., 19., 19., 19., 18., 19., 19., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",277,277,0,50,"encoder/4/1/attention/11/value/Net","encoder/4/1/attention/11/value/Net","encoder/4/1/attention/11/value/Net","Linear","Linear","Linear",21.,24.0667,58.,"{58., 32., 23., 29., 22., 21., 33., 24., 25., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 26., 36., 32., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",278,278,0,50,"encoder/4/1/attention/11/attention/ScoringNet/1","encoder/4/1/attention/11/attention/ScoringNet/1","encoder/4/1/attention/11/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.1,43.,"{43., 34., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 20., 20., 19., 20., 19., 19., 19., 19., 19., 20., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",279,279,0,50,"encoder/4/1/attention/12/key/Net","encoder/4/1/attention/12/key/Net","encoder/4/1/attention/12/key/Net","Linear","Linear","Linear",21.,22.633300000000002,48.,"{48., 44., 43., 26., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 36., 33., 21., 21., 21., 21., 21., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 33.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",280,280,0,50,"encoder/4/1/attention/12/query/Net","encoder/4/1/attention/12/query/Net","encoder/4/1/attention/12/query/Net","Linear","Linear","Linear",21.,23.4667,59.,"{59., 32., 30., 22., 22., 21., 22., 21., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 33., 24., 23., 24., 24., 24., 24., 24., 23., 24., 24., 24., 33., 33., 32., 25., 24., 24., 24., 24., 46., 27., 24., 24., 23., 47., 25., 24., 23., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",281,281,0,50,"encoder/4/1/attention/12/elem","encoder/4/1/attention/12/elem","encoder/4/1/attention/12/elem","Elementwise","Elementwise","Elementwise",17.,18.,39.,"{39., 21., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",282,282,0,50,"encoder/4/1/attention/12/value/Net","encoder/4/1/attention/12/value/Net","encoder/4/1/attention/12/value/Net","Linear","Linear","Linear",21.,24.1,58.,"{58., 32., 22., 22., 22., 22., 21., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 39., 33., 25., 24., 24., 25., 25., 25., 25., 24., 24., 24., 24., 24., 25., 24., 24., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",283,283,0,50,"encoder/4/1/attention/12/attention/ScoringNet/1","encoder/4/1/attention/12/attention/ScoringNet/1","encoder/4/1/attention/12/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.,43.,"{43., 22., 21., 20., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20., 20., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",284,284,0,50,"encoder/4/1/attention/13","encoder/4/1/attention/13","encoder/4/1/attention/13","Catenate","Catenate","Catenate",55.,56.1,81.,"{80., 60., 81., 59., 57., 57., 56., 56., 57., 56., 56., 57., 56., 56., 56., 56., 56., 56., 56., 55., 56., 56., 56., 56., 56., 56., 56., 56., 56., 57., 56., 56., 56., 57., 56., 56., 56., 56., 64., 57., 57., 56., 56., 56., 56., 56., 55., 56., 56., 56.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",285,285,0,50,"encoder/4/1/attention/14/Net","encoder/4/1/attention/14/Net","encoder/4/1/attention/14/Net","Linear","Linear","Linear",137.,138.63330000000002,237.,"{237., 200., 142., 139., 139., 165., 141., 138., 137., 138., 138., 139., 137., 139., 138., 140., 138., 137., 138., 139., 139., 139., 137., 140., 138., 139., 137., 139., 138., 138., 137., 139., 164., 151., 139., 138., 137., 138., 139., 139., 138., 139., 137., 139., 138., 139., 139., 137., 162., 142.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",286,286,0,50,"encoder/4/1/dropout","encoder/4/1/dropout","encoder/4/1/dropout","Dropout","Dropout","Dropout",18.,18.1,36.,"{36., 21., 19., 19., 18., 18., 18., 19., 19., 19., 19., 18., 19., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",287,288,1,50,"encoder/4/1/add","encoder/4/1/norm","encoder/4/1/add-encoder/4/1/norm","Threading","Normalization","Threading-Normalization",161.,165.,214.,"{214., 168., 163., 163., 179., 166., 163., 162., 161., 163., 161., 162., 162., 162., 163., 186., 167., 165., 165., 165., 165., 165., 165., 165., 166., 165., 165., 165., 165., 166., 166., 165., 165., 165., 164., 165., 165., 164., 182., 174., 167., 166., 165., 164., 165., 166., 165., 165., 165., 166.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",289,289,0,50,"encoder/4/2/linear1/Net","encoder/4/2/linear1/Net","encoder/4/2/linear1/Net","Linear","Linear","Linear",439.,446.5667,758.,"{758., 717., 530., 463., 445., 443., 477., 465., 443., 439., 440., 455., 441., 440., 464., 441., 442., 443., 442., 441., 442., 441., 440., 486., 453., 445., 445., 444., 445., 457., 445., 444., 468., 450., 444., 445., 443., 444., 443., 444., 444., 469., 448., 444., 444., 502., 444., 442., 441., 467.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",290,290,0,50,"encoder/4/2/gelu","encoder/4/2/gelu","encoder/4/2/gelu","Elementwise","Elementwise","Elementwise",105.,105.36670000000001,137.,"{137., 109., 106., 106., 106., 106., 105., 105., 105., 106., 105., 105., 105., 105., 105., 106., 105., 105., 106., 128., 108., 114., 106., 105., 105., 105., 105., 105., 105., 105., 106., 105., 105., 105., 105., 106., 105., 105., 106., 105., 105., 105., 105., 105., 106., 127., 110., 106., 106., 105.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",291,291,0,50,"encoder/4/2/linear2/Net","encoder/4/2/linear2/Net","encoder/4/2/linear2/Net","Linear","Linear","Linear",433.,438.3333,534.,"{534., 507., 464., 439., 434., 433., 469., 436., 434., 448., 451., 440., 451., 437., 436., 458., 453., 439., 437., 436., 436., 436., 436., 435., 471., 437., 436., 435., 436., 435., 436., 449., 437., 460., 443., 436., 437., 436., 435., 436., 436., 436., 461., 435., 435., 436., 436., 444., 436., 436.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",292,292,0,50,"encoder/4/2/dropout","encoder/4/2/dropout","encoder/4/2/dropout","Dropout","Dropout","Dropout",18.,18.4667,53.,"{38., 21., 19., 19., 19., 19., 18., 19., 19., 18., 18., 19., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 53., 19., 18., 18., 19., 19., 18., 18., 18., 19., 19., 19., 18., 18., 19., 18., 19., 19., 19., 19., 19., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",293,294,1,50,"encoder/4/2/add","encoder/4/2/norm","encoder/4/2/add-encoder/4/2/norm","Threading","Normalization","Threading-Normalization",161.,162.5667,230.,"{217., 189., 168., 163., 163., 184., 166., 163., 163., 163., 176., 165., 162., 162., 162., 163., 162., 163., 163., 162., 161., 162., 163., 163., 162., 162., 163., 162., 162., 230., 167., 163., 162., 163., 162., 162., 163., 162., 163., 162., 162., 161., 172., 162., 163., 163., 161., 161., 161., 162.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",295,295,0,50,"encoder/5/1/attention/1/key/Net","encoder/5/1/attention/1/key/Net","encoder/5/1/attention/1/key/Net","Linear","Linear","Linear",21.,24.,66.,"{66., 32., 23., 22., 22., 22., 21., 22., 21., 33., 24., 24., 24., 25., 23., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",296,296,0,50,"encoder/5/1/attention/1/query/Net","encoder/5/1/attention/1/query/Net","encoder/5/1/attention/1/query/Net","Linear","Linear","Linear",21.,26.8,62.,"{58., 31., 23., 21., 62., 28., 25., 24., 24., 24., 24., 24., 24., 24., 32., 25., 24., 24., 24., 58., 34., 33., 33., 32., 33., 31., 31., 32., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 32., 32., 32., 35., 37., 32., 32., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",297,297,0,50,"encoder/5/1/attention/1/elem","encoder/5/1/attention/1/elem","encoder/5/1/attention/1/elem","Elementwise","Elementwise","Elementwise",17.,18.,42.,"{42., 21., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 28., 18., 18., 18., 18., 18., 18., 19., 18., 18., 19., 18., 18., 17., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",298,298,0,50,"encoder/5/1/attention/1/value/Net","encoder/5/1/attention/1/value/Net","encoder/5/1/attention/1/value/Net","Linear","Linear","Linear",21.,24.2333,58.,"{58., 25., 23., 22., 22., 22., 21., 21., 22., 33., 25., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24., 25., 38., 26., 25., 24., 25., 24., 24., 25., 24., 24., 25., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",299,299,0,50,"encoder/5/1/attention/1/attention/ScoringNet/1","encoder/5/1/attention/1/attention/ScoringNet/1","encoder/5/1/attention/1/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.400000000000002,55.,"{46., 22., 20., 20., 19., 20., 19., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 20., 55., 21., 20., 19., 19., 20., 19., 27., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 20., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",300,300,0,50,"encoder/5/1/attention/2/key/Net","encoder/5/1/attention/2/key/Net","encoder/5/1/attention/2/key/Net","Linear","Linear","Linear",23.,24.1,58.,"{58., 32., 31., 37., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 25., 23., 24., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 25., 34., 33., 33., 32., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",301,301,0,50,"encoder/5/1/attention/2/query/Net","encoder/5/1/attention/2/query/Net","encoder/5/1/attention/2/query/Net","Linear","Linear","Linear",21.,24.,47.,"{47., 43., 24., 21., 22., 21., 33., 24., 24., 24., 24., 24., 23., 34., 32., 32., 34., 33., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",302,302,0,50,"encoder/5/1/attention/2/elem","encoder/5/1/attention/2/elem","encoder/5/1/attention/2/elem","Elementwise","Elementwise","Elementwise",17.,18.,39.,"{39., 22., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",303,303,0,50,"encoder/5/1/attention/2/value/Net","encoder/5/1/attention/2/value/Net","encoder/5/1/attention/2/value/Net","Linear","Linear","Linear",21.,23.8667,58.,"{58., 32., 29., 30., 23., 22., 22., 21., 21., 22., 21., 21., 21., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 23., 33., 21., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",304,304,0,50,"encoder/5/1/attention/2/attention/ScoringNet/1","encoder/5/1/attention/2/attention/ScoringNet/1","encoder/5/1/attention/2/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3,44.,"{44., 23., 20., 19., 20., 19., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19., 20., 19., 19., 19., 20., 22., 20., 19., 19., 20., 19., 19., 20., 20., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",305,305,0,50,"encoder/5/1/attention/3/key/Net","encoder/5/1/attention/3/key/Net","encoder/5/1/attention/3/key/Net","Linear","Linear","Linear",21.,24.8333,59.,"{59., 31., 30., 28., 29., 30., 28., 23., 21., 22., 21., 22., 21., 21., 22., 21., 21., 23., 28., 29., 42., 25., 32., 25., 25., 25., 32., 32., 47., 36., 25., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",306,306,0,50,"encoder/5/1/attention/3/query/Net","encoder/5/1/attention/3/query/Net","encoder/5/1/attention/3/query/Net","Linear","Linear","Linear",21.,24.666700000000002,47.,"{47., 31., 31., 29., 30., 43., 32., 32., 26., 24., 35., 27., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 25., 36., 32., 21., 21., 21., 21., 21., 22., 21., 22., 32., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 23.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",307,307,0,50,"encoder/5/1/attention/3/elem","encoder/5/1/attention/3/elem","encoder/5/1/attention/3/elem","Elementwise","Elementwise","Elementwise",17.,18.2,41.,"{41., 21., 19., 19., 18., 18., 18., 19., 18., 18., 18., 19., 19., 19., 18., 18., 18., 18., 19., 19., 17., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 19., 17., 18., 19., 19., 18., 19., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",308,308,0,50,"encoder/5/1/attention/3/value/Net","encoder/5/1/attention/3/value/Net","encoder/5/1/attention/3/value/Net","Linear","Linear","Linear",22.,24.3333,58.,"{58., 32., 23., 22., 32., 31., 28., 29., 30., 36., 24., 25., 24., 24., 24., 24., 24., 24., 25., 25., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 25., 24., 24., 24., 24., 25., 24., 24., 25., 25., 25., 25., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",309,309,0,50,"encoder/5/1/attention/3/attention/ScoringNet/1","encoder/5/1/attention/3/attention/ScoringNet/1","encoder/5/1/attention/3/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.400000000000002,46.,"{46., 34., 20., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19., 44., 20., 19., 20., 19., 20., 19., 20., 19., 19., 19., 20., 19., 20., 19., 19., 20., 19., 20., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",310,310,0,50,"encoder/5/1/attention/4/key/Net","encoder/5/1/attention/4/key/Net","encoder/5/1/attention/4/key/Net","Linear","Linear","Linear",21.,23.6,67.,"{59., 33., 24., 29., 22., 21., 22., 21., 23., 21., 22., 21., 22., 21., 21., 22., 21., 22., 22., 21., 22., 23., 28., 30., 22., 34., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 32., 25., 24., 24., 24., 25., 25., 24., 24., 67., 35.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",311,311,0,50,"encoder/5/1/attention/4/query/Net","encoder/5/1/attention/4/query/Net","encoder/5/1/attention/4/query/Net","Linear","Linear","Linear",21.,24.4667,58.,"{58., 32., 29., 29., 28., 52., 32., 29., 28., 28., 28., 22., 21., 21., 22., 22., 21., 33., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 25., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",312,312,0,50,"encoder/5/1/attention/4/elem","encoder/5/1/attention/4/elem","encoder/5/1/attention/4/elem","Elementwise","Elementwise","Elementwise",18.,18.1,53.,"{40., 21., 19., 18., 19., 18., 18., 18., 18., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 53., 20., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 19., 19., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",313,313,0,50,"encoder/5/1/attention/4/value/Net","encoder/5/1/attention/4/value/Net","encoder/5/1/attention/4/value/Net","Linear","Linear","Linear",22.,24.3667,58.,"{58., 32., 31., 23., 22., 22., 22., 33., 24., 25., 25., 25., 24., 24., 33., 26., 24., 24., 24., 25., 24., 24., 24., 24., 26., 24., 24., 24., 25., 25., 24., 32., 33., 27., 24., 25., 24., 24., 25., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",314,314,0,50,"encoder/5/1/attention/4/attention/ScoringNet/1","encoder/5/1/attention/4/attention/ScoringNet/1","encoder/5/1/attention/4/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.5333,56.,"{44., 24., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 42., 21., 20., 20., 19., 20., 20., 19., 20., 19., 20., 19., 56., 21., 20., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",315,315,0,50,"encoder/5/1/attention/5/key/Net","encoder/5/1/attention/5/key/Net","encoder/5/1/attention/5/key/Net","Linear","Linear","Linear",21.,23.5,58.,"{58., 32., 30., 24., 22., 21., 22., 22., 21., 22., 22., 21., 21., 21., 21., 22., 23., 22., 22., 21., 22., 21., 32., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 48., 34., 33., 25., 24., 24., 24., 24., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",316,316,0,50,"encoder/5/1/attention/5/query/Net","encoder/5/1/attention/5/query/Net","encoder/5/1/attention/5/query/Net","Linear","Linear","Linear",21.,22.5,59.,"{59., 32., 23., 22., 22., 22., 22., 22., 23., 29., 22., 21., 23., 22., 21., 22., 21., 22., 21., 22., 28., 21., 28., 28., 22., 21., 22., 28., 30., 29., 22., 22., 21., 21., 22., 21., 22., 21., 21., 21., 22., 22., 33., 24., 25., 23., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",317,317,0,50,"encoder/5/1/attention/5/elem","encoder/5/1/attention/5/elem","encoder/5/1/attention/5/elem","Elementwise","Elementwise","Elementwise",17.,18.,38.,"{38., 21., 18., 19., 18., 18., 18., 18., 17., 19., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 19., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",318,318,0,50,"encoder/5/1/attention/5/value/Net","encoder/5/1/attention/5/value/Net","encoder/5/1/attention/5/value/Net","Linear","Linear","Linear",21.,24.0333,59.,"{59., 31., 24., 29., 29., 29., 22., 28., 21., 32., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 32., 25., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 23., 24., 25., 23., 32., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",319,319,0,50,"encoder/5/1/attention/5/attention/ScoringNet/1","encoder/5/1/attention/5/attention/ScoringNet/1","encoder/5/1/attention/5/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2,44.,"{44., 33., 20., 19., 20., 19., 20., 19., 42., 22., 19., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",320,320,0,50,"encoder/5/1/attention/6/key/Net","encoder/5/1/attention/6/key/Net","encoder/5/1/attention/6/key/Net","Linear","Linear","Linear",21.,23.2667,60.,"{59., 32., 23., 29., 23., 28., 22., 22., 28., 22., 22., 22., 28., 22., 22., 21., 22., 21., 21., 22., 22., 22., 21., 22., 21., 21., 22., 21., 22., 21., 34., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 60., 28., 25., 25., 24., 24., 32., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",321,321,0,50,"encoder/5/1/attention/6/query/Net","encoder/5/1/attention/6/query/Net","encoder/5/1/attention/6/query/Net","Linear","Linear","Linear",21.,23.2667,67.,"{57., 32., 29., 33., 23., 21., 21., 21., 22., 21., 22., 21., 21., 22., 21., 21., 22., 21., 22., 21., 21., 22., 21., 21., 34., 67., 34., 27., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 26., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",322,322,0,50,"encoder/5/1/attention/6/elem","encoder/5/1/attention/6/elem","encoder/5/1/attention/6/elem","Elementwise","Elementwise","Elementwise",17.,18.,39.,"{39., 21., 18., 19., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 29., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",323,323,0,50,"encoder/5/1/attention/6/value/Net","encoder/5/1/attention/6/value/Net","encoder/5/1/attention/6/value/Net","Linear","Linear","Linear",21.,23.3333,67.,"{58., 31., 29., 30., 22., 22., 21., 22., 21., 22., 32., 24., 24., 23., 24., 24., 67., 34., 24., 23., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 36., 21., 21., 21., 21., 21., 21., 21., 21., 22., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",324,324,0,50,"encoder/5/1/attention/6/attention/ScoringNet/1","encoder/5/1/attention/6/attention/ScoringNet/1","encoder/5/1/attention/6/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2,44.,"{44., 33., 20., 20., 19., 19., 19., 20., 19., 19., 19., 19., 41., 21., 19., 20., 19., 19., 19., 19., 26., 20., 19., 19., 20., 19., 19., 19., 20., 20., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",325,325,0,50,"encoder/5/1/attention/7/key/Net","encoder/5/1/attention/7/key/Net","encoder/5/1/attention/7/key/Net","Linear","Linear","Linear",21.,24.200000000000003,58.,"{58., 32., 24., 22., 22., 33., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 25., 24., 25., 25., 25., 24., 23., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 23., 24., 26., 34., 32., 22., 21., 21., 32., 30., 30., 24., 21., 22.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",326,326,0,50,"encoder/5/1/attention/7/query/Net","encoder/5/1/attention/7/query/Net","encoder/5/1/attention/7/query/Net","Linear","Linear","Linear",24.,24.3333,61.,"{58., 32., 30., 36., 61., 33., 32., 26., 25., 25., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 31., 33., 33., 26., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",327,327,0,50,"encoder/5/1/attention/7/elem","encoder/5/1/attention/7/elem","encoder/5/1/attention/7/elem","Elementwise","Elementwise","Elementwise",17.,18.,39.,"{39., 20., 18., 19., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 17.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",328,328,0,50,"encoder/5/1/attention/7/value/Net","encoder/5/1/attention/7/value/Net","encoder/5/1/attention/7/value/Net","Linear","Linear","Linear",22.,26.133300000000002,59.,"{59., 31., 23., 22., 22., 33., 24., 24., 32., 33., 32., 32., 32., 25., 32., 25., 26., 24., 32., 32., 25., 24., 31., 32., 25., 24., 24., 24., 24., 24., 24., 32., 32., 25., 24., 24., 32., 26., 24., 24., 32., 25., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",329,329,0,50,"encoder/5/1/attention/7/attention/ScoringNet/1","encoder/5/1/attention/7/attention/ScoringNet/1","encoder/5/1/attention/7/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3667,45.,"{45., 22., 20., 20., 19., 41., 21., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 20., 20., 19., 19., 19., 20., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",330,330,0,50,"encoder/5/1/attention/8/key/Net","encoder/5/1/attention/8/key/Net","encoder/5/1/attention/8/key/Net","Linear","Linear","Linear",23.,24.5667,64.,"{59., 31., 30., 29., 30., 59., 34., 25., 24., 24., 24., 24., 23., 32., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 64., 28., 25., 24., 24., 51., 34., 27., 24., 24., 25., 25., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",331,331,0,50,"encoder/5/1/attention/8/query/Net","encoder/5/1/attention/8/query/Net","encoder/5/1/attention/8/query/Net","Linear","Linear","Linear",21.,24.633300000000002,59.,"{59., 32., 30., 29., 28., 28., 29., 29., 29., 22., 22., 28., 28., 28., 21., 21., 22., 21., 22., 21., 22., 34., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 23., 24., 25., 24., 25., 23., 32.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",332,332,0,50,"encoder/5/1/attention/8/elem","encoder/5/1/attention/8/elem","encoder/5/1/attention/8/elem","Elementwise","Elementwise","Elementwise",17.,18.0333,49.,"{49., 21., 19., 18., 18., 18., 19., 18., 18., 18., 19., 18., 18., 18., 19., 19., 19., 19., 18., 18., 18., 18., 18., 18., 48., 19., 18., 18., 18., 18., 17., 18., 18., 18., 18., 17., 18., 18., 18., 18., 17., 18., 18., 17., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",333,333,0,50,"encoder/5/1/attention/8/value/Net","encoder/5/1/attention/8/value/Net","encoder/5/1/attention/8/value/Net","Linear","Linear","Linear",21.,23.5,59.,"{58., 31., 24., 22., 22., 21., 21., 21., 21., 21., 22., 21., 22., 21., 21., 21., 21., 22., 21., 33., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 59., 34., 25., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",334,334,0,50,"encoder/5/1/attention/8/attention/ScoringNet/1","encoder/5/1/attention/8/attention/ScoringNet/1","encoder/5/1/attention/8/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.0667,45.,"{45., 39., 21., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 20., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",335,335,0,50,"encoder/5/1/attention/9/key/Net","encoder/5/1/attention/9/key/Net","encoder/5/1/attention/9/key/Net","Linear","Linear","Linear",21.,24.0333,60.,"{60., 32., 23., 22., 22., 22., 21., 31., 25., 24., 24., 24., 24., 32., 32., 25., 24., 25., 24., 25., 60., 33., 33., 33., 33., 32., 25., 24., 24., 24., 24., 25., 24., 26., 22., 32., 21., 21., 22., 21., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",336,336,0,50,"encoder/5/1/attention/9/query/Net","encoder/5/1/attention/9/query/Net","encoder/5/1/attention/9/query/Net","Linear","Linear","Linear",21.,24.0667,47.,"{47., 31., 29., 23., 22., 22., 21., 22., 22., 35., 24., 24., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 25., 25., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24., 35.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",337,337,0,50,"encoder/5/1/attention/9/elem","encoder/5/1/attention/9/elem","encoder/5/1/attention/9/elem","Elementwise","Elementwise","Elementwise",18.,18.133300000000002,40.,"{40., 21., 19., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 19., 38., 20., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",338,338,0,50,"encoder/5/1/attention/9/value/Net","encoder/5/1/attention/9/value/Net","encoder/5/1/attention/9/value/Net","Linear","Linear","Linear",24.,25.,59.,"{59., 32., 26., 25., 24., 25., 31., 32., 33., 25., 25., 24., 24., 24., 24., 25., 25., 24., 25., 31., 25., 25., 24., 24., 48., 35., 35., 25., 24., 24., 42., 25., 32., 32., 25., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",339,339,0,50,"encoder/5/1/attention/9/attention/ScoringNet/1","encoder/5/1/attention/9/attention/ScoringNet/1","encoder/5/1/attention/9/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3,58.,"{45., 22., 20., 19., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 20., 20., 19., 19., 20., 19., 19., 20., 19., 58., 22., 20., 19., 20., 19., 19., 20., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",340,340,0,50,"encoder/5/1/attention/10/key/Net","encoder/5/1/attention/10/key/Net","encoder/5/1/attention/10/key/Net","Linear","Linear","Linear",21.,23.9667,61.,"{61., 31., 24., 21., 21., 22., 21., 21., 21., 21., 33., 23., 24., 24., 24., 24., 24., 24., 25., 24., 25., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 26., 24., 24., 24., 24., 24., 23., 24., 24., 23., 24., 24., 24., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",341,341,0,50,"encoder/5/1/attention/10/query/Net","encoder/5/1/attention/10/query/Net","encoder/5/1/attention/10/query/Net","Linear","Linear","Linear",21.,24.0333,58.,"{58., 34., 36., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24., 25., 23., 33., 21., 21., 21., 22., 21., 22., 21., 34.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",342,342,0,50,"encoder/5/1/attention/10/elem","encoder/5/1/attention/10/elem","encoder/5/1/attention/10/elem","Elementwise","Elementwise","Elementwise",18.,18.0333,41.,"{39., 21., 19., 18., 19., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 19., 18., 18., 18., 18., 41., 20., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",343,343,0,50,"encoder/5/1/attention/10/value/Net","encoder/5/1/attention/10/value/Net","encoder/5/1/attention/10/value/Net","Linear","Linear","Linear",21.,24.2333,55.,"{48., 32., 55., 35., 27., 25., 24., 24., 24., 24., 24., 24., 25., 25., 23., 24., 25., 24., 25., 24., 24., 24., 24., 24., 32., 29., 22., 21., 22., 21., 21., 22., 21., 21., 32., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 33., 34., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",344,344,0,50,"encoder/5/1/attention/10/attention/ScoringNet/1","encoder/5/1/attention/10/attention/ScoringNet/1","encoder/5/1/attention/10/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.5,44.,"{44., 34., 21., 20., 20., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 20., 20., 19., 20., 19., 19., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 19., 19., 19., 20., 19., 20., 19., 20., 19., 20., 20., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",345,345,0,50,"encoder/5/1/attention/11/key/Net","encoder/5/1/attention/11/key/Net","encoder/5/1/attention/11/key/Net","Linear","Linear","Linear",21.,23.9667,47.,"{47., 31., 29., 29., 23., 21., 21., 21., 28., 22., 30., 22., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 23., 25., 24., 23., 23., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",346,346,0,50,"encoder/5/1/attention/11/query/Net","encoder/5/1/attention/11/query/Net","encoder/5/1/attention/11/query/Net","Linear","Linear","Linear",21.,22.5667,52.,"{50., 31., 24., 22., 21., 21., 21., 22., 21., 21., 21., 21., 21., 22., 21., 21., 21., 21., 21., 22., 21., 21., 21., 22., 21., 21., 21., 21., 34., 23., 24., 24., 52., 33., 25., 24., 24., 24., 24., 24., 23., 24., 24., 24., 23., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",347,347,0,50,"encoder/5/1/attention/11/elem","encoder/5/1/attention/11/elem","encoder/5/1/attention/11/elem","Elementwise","Elementwise","Elementwise",18.,18.633300000000002,42.,"{40., 22., 19., 19., 18., 42., 20., 19., 19., 19., 19., 18., 19., 18., 19., 19., 18., 19., 19., 18., 19., 19., 18., 18., 19., 18., 18., 19., 18., 18., 19., 18., 19., 19., 18., 19., 19., 18., 18., 19., 18., 19., 18., 19., 18., 18., 19., 18., 19., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",348,348,0,50,"encoder/5/1/attention/11/value/Net","encoder/5/1/attention/11/value/Net","encoder/5/1/attention/11/value/Net","Linear","Linear","Linear",23.,24.0667,59.,"{59., 33., 24., 42., 25., 25., 24., 24., 24., 25., 24., 37., 33., 27., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",349,349,0,50,"encoder/5/1/attention/11/attention/ScoringNet/1","encoder/5/1/attention/11/attention/ScoringNet/1","encoder/5/1/attention/11/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2,45.,"{45., 22., 20., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 20., 19., 19., 19., 19., 20., 20., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 20., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",350,350,0,50,"encoder/5/1/attention/12/key/Net","encoder/5/1/attention/12/key/Net","encoder/5/1/attention/12/key/Net","Linear","Linear","Linear",21.,23.5667,60.,"{60., 32., 29., 29., 29., 30., 23., 21., 21., 28., 22., 22., 22., 21., 22., 21., 22., 21., 22., 21., 21., 22., 21., 22., 32., 24., 24., 24., 26., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",351,351,0,50,"encoder/5/1/attention/12/query/Net","encoder/5/1/attention/12/query/Net","encoder/5/1/attention/12/query/Net","Linear","Linear","Linear",21.,24.133300000000002,59.,"{59., 32., 30., 22., 34., 25., 24., 26., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 23., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 26., 36., 22., 21., 54., 56., 33., 22., 22., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",352,352,0,50,"encoder/5/1/attention/12/elem","encoder/5/1/attention/12/elem","encoder/5/1/attention/12/elem","Elementwise","Elementwise","Elementwise",18.,18.3333,40.,"{40., 21., 20., 18., 19., 18., 18., 19., 18., 18., 19., 18., 19., 18., 18., 18., 19., 19., 19., 18., 18., 18., 19., 19., 19., 18., 18., 18., 18., 18., 18., 18., 19., 19., 19., 19., 18., 19., 18., 18., 18., 18., 18., 18., 18., 19., 18., 19., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",353,353,0,50,"encoder/5/1/attention/12/value/Net","encoder/5/1/attention/12/value/Net","encoder/5/1/attention/12/value/Net","Linear","Linear","Linear",24.,26.8,59.,"{59., 33., 44., 35., 33., 34., 27., 32., 26., 33., 32., 34., 32., 32., 33., 33., 32., 32., 33., 25., 24., 25., 24., 39., 40., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",354,354,0,50,"encoder/5/1/attention/12/attention/ScoringNet/1","encoder/5/1/attention/12/attention/ScoringNet/1","encoder/5/1/attention/12/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3333,44.,"{44., 34., 20., 19., 19., 20., 20., 19., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 20., 19., 20., 19., 19., 19., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 22., 20., 19., 19., 19., 20., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",355,355,0,50,"encoder/5/1/attention/13","encoder/5/1/attention/13","encoder/5/1/attention/13","Catenate","Catenate","Catenate",55.,56.,79.,"{79., 59., 57., 57., 56., 56., 55., 56., 56., 56., 55., 56., 56., 57., 56., 56., 57., 56., 57., 56., 56., 56., 55., 56., 56., 56., 55., 56., 56., 56., 56., 56., 56., 56., 56., 55., 57., 57., 56., 56., 56., 56., 56., 57., 55., 55., 56., 56., 56., 56.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",356,356,0,50,"encoder/5/1/attention/14/Net","encoder/5/1/attention/14/Net","encoder/5/1/attention/14/Net","Linear","Linear","Linear",137.,138.4,282.,"{282., 201., 143., 139., 140., 138., 139., 139., 139., 138., 138., 138., 138., 139., 150., 138., 138., 139., 138., 138., 140., 139., 138., 138., 138., 138., 164., 140., 140., 138., 139., 138., 139., 139., 138., 138., 139., 138., 138., 138., 138., 137., 138., 138., 140., 137., 138., 137., 138., 139.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",357,357,0,50,"encoder/5/1/dropout","encoder/5/1/dropout","encoder/5/1/dropout","Dropout","Dropout","Dropout",17.,18.,38.,"{38., 21., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 17., 18., 18., 18., 18., 18., 20., 19., 18., 18., 18., 19., 19., 18., 26., 18., 18., 18., 17., 18., 18., 18., 17., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",358,359,1,50,"encoder/5/1/add","encoder/5/1/norm","encoder/5/1/add-encoder/5/1/norm","Threading","Normalization","Threading-Normalization",161.,162.6,214.,"{214., 168., 165., 162., 184., 163., 163., 184., 165., 162., 163., 163., 162., 162., 163., 163., 163., 162., 163., 162., 173., 163., 163., 162., 163., 161., 163., 163., 162., 162., 162., 187., 165., 162., 162., 163., 162., 163., 162., 163., 161., 161., 163., 162., 163., 162., 162., 161., 162., 163.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",360,360,0,50,"encoder/5/2/linear1/Net","encoder/5/2/linear1/Net","encoder/5/2/linear1/Net","Linear","Linear","Linear",439.,444.1333,758.,"{758., 714., 513., 490., 448., 444., 445., 441., 443., 476., 456., 475., 440., 441., 440., 441., 452., 443., 441., 441., 471., 443., 440., 443., 443., 441., 439., 440., 441., 468., 440., 489., 447., 442., 444., 441., 444., 441., 473., 443., 441., 441., 441., 440., 439., 441., 468., 441., 442., 442.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",361,361,0,50,"encoder/5/2/gelu","encoder/5/2/gelu","encoder/5/2/gelu","Elementwise","Elementwise","Elementwise",105.,105.1667,135.,"{135., 108., 106., 106., 106., 106., 105., 131., 108., 106., 105., 105., 105., 105., 105., 105., 105., 106., 105., 105., 105., 105., 105., 105., 105., 105., 105., 105., 105., 105., 105., 105., 105., 105., 105., 105., 106., 105., 105., 105., 105., 105., 105., 122., 107., 106., 106., 105., 105., 105.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",362,362,0,50,"encoder/5/2/linear2/Net","encoder/5/2/linear2/Net","encoder/5/2/linear2/Net","Linear","Linear","Linear",431.,435.73330000000004,525.,"{525., 496., 448., 466., 434., 432., 435., 433., 433., 435., 457., 435., 488., 435., 433., 433., 432., 446., 433., 441., 432., 460., 437., 436., 436., 436., 436., 436., 436., 436., 462., 437., 450., 435., 438., 433., 432., 431., 431., 467., 433., 433., 432., 433., 432., 432., 432., 433., 459., 434.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",363,363,0,50,"encoder/5/2/dropout","encoder/5/2/dropout","encoder/5/2/dropout","Dropout","Dropout","Dropout",18.,18.4667,40.,"{40., 21., 19., 19., 18., 19., 19., 19., 18., 19., 18., 19., 18., 19., 18., 19., 18., 18., 19., 18., 18., 19., 18., 18., 19., 18., 18., 18., 19., 18., 18., 18., 19., 19., 18., 18., 19., 18., 19., 18., 18., 19., 19., 18., 18., 18., 19., 27., 19., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",364,365,1,50,"encoder/5/2/add","encoder/5/2/norm","encoder/5/2/add-encoder/5/2/norm","Threading","Normalization","Threading-Normalization",161.,163.0333,217.,"{217., 167., 212., 169., 164., 162., 176., 166., 164., 163., 161., 163., 163., 163., 163., 161., 162., 161., 191., 173., 163., 163., 164., 162., 162., 163., 163., 161., 161., 162., 164., 161., 163., 162., 162., 163., 162., 163., 162., 164., 162., 163., 182., 165., 163., 163., 162., 162., 179., 165.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",366,366,0,50,"encoder/6/1/attention/1/key/Net","encoder/6/1/attention/1/key/Net","encoder/6/1/attention/1/key/Net","Linear","Linear","Linear",21.,24.,71.,"{71., 32., 30., 23., 21., 21., 21., 21., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 23., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",367,367,0,50,"encoder/6/1/attention/1/query/Net","encoder/6/1/attention/1/query/Net","encoder/6/1/attention/1/query/Net","Linear","Linear","Linear",24.,27.7667,49.,"{49., 32., 30., 32., 25., 24., 24., 31., 32., 26., 32., 34., 27., 24., 48., 36., 25., 32., 32., 26., 24., 24., 24., 32., 24., 32., 32., 32., 32., 32., 25., 24., 31., 24., 24., 24., 32., 33., 32., 33., 25., 24., 25., 24., 24., 24., 24., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",368,368,0,50,"encoder/6/1/attention/1/elem","encoder/6/1/attention/1/elem","encoder/6/1/attention/1/elem","Elementwise","Elementwise","Elementwise",18.,18.3333,44.,"{44., 22., 19., 19., 18., 42., 20., 18., 19., 18., 18., 18., 19., 18., 18., 19., 19., 18., 19., 19., 18., 18., 19., 19., 18., 18., 18., 19., 18., 18., 18., 18., 19., 18., 18., 18., 19., 18., 18., 18., 19., 18., 18., 18., 19., 18., 18., 18., 19., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",369,369,0,50,"encoder/6/1/attention/1/value/Net","encoder/6/1/attention/1/value/Net","encoder/6/1/attention/1/value/Net","Linear","Linear","Linear",21.,24.200000000000003,48.,"{48., 33., 24., 21., 21., 21., 23., 21., 22., 22., 28., 22., 21., 21., 22., 21., 34., 26., 24., 24., 25., 24., 25., 25., 24., 24., 25., 24., 24., 24., 24., 25., 25., 32., 32., 25., 25., 24., 24., 24., 24., 32., 32., 25., 24., 24., 25., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",370,370,0,50,"encoder/6/1/attention/1/attention/ScoringNet/1","encoder/6/1/attention/1/attention/ScoringNet/1","encoder/6/1/attention/1/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3667,46.,"{46., 23., 20., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",371,371,0,50,"encoder/6/1/attention/2/key/Net","encoder/6/1/attention/2/key/Net","encoder/6/1/attention/2/key/Net","Linear","Linear","Linear",23.,24.400000000000002,59.,"{59., 35., 34., 34., 32., 24., 32., 32., 32., 32., 26., 33., 32., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 23., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",372,372,0,50,"encoder/6/1/attention/2/query/Net","encoder/6/1/attention/2/query/Net","encoder/6/1/attention/2/query/Net","Linear","Linear","Linear",21.,23.,53.,"{47., 33., 23., 21., 21., 22., 21., 21., 21., 22., 21., 22., 21., 21., 21., 21., 22., 21., 22., 21., 21., 21., 48., 31., 22., 22., 21., 34., 24., 24., 24., 24., 25., 50., 28., 24., 24., 24., 24., 24., 24., 24., 24., 53., 34., 26., 24., 24., 24., 23.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",373,373,0,50,"encoder/6/1/attention/2/elem","encoder/6/1/attention/2/elem","encoder/6/1/attention/2/elem","Elementwise","Elementwise","Elementwise",18.,18.,40.,"{40., 22., 19., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 19., 18., 19., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",374,374,0,50,"encoder/6/1/attention/2/value/Net","encoder/6/1/attention/2/value/Net","encoder/6/1/attention/2/value/Net","Linear","Linear","Linear",21.,23.5667,60.,"{58., 32., 23., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 22., 21., 21., 21., 21., 22., 60., 42., 34., 33., 27., 24., 24., 24., 23., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 51., 33., 27., 24., 24., 24., 24., 25., 25., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",375,375,0,50,"encoder/6/1/attention/2/attention/ScoringNet/1","encoder/6/1/attention/2/attention/ScoringNet/1","encoder/6/1/attention/2/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2333,52.,"{47., 33., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 20., 19., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 20., 52., 22., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",376,376,0,50,"encoder/6/1/attention/3/key/Net","encoder/6/1/attention/3/key/Net","encoder/6/1/attention/3/key/Net","Linear","Linear","Linear",21.,23.200000000000003,59.,"{59., 33., 24., 45., 25., 24., 24., 25., 24., 24., 24., 24., 25., 24., 25., 33., 25., 24., 24., 25., 24., 25., 24., 26., 23., 32., 21., 29., 23., 21., 22., 21., 21., 22., 22., 21., 22., 22., 21., 22., 21., 21., 22., 22., 21., 21., 22., 21., 21., 22.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",377,377,0,50,"encoder/6/1/attention/3/query/Net","encoder/6/1/attention/3/query/Net","encoder/6/1/attention/3/query/Net","Linear","Linear","Linear",21.,24.3333,59.,"{59., 32., 30., 36., 25., 24., 24., 26., 25., 24., 25., 24., 24., 25., 24., 25., 24., 24., 49., 35., 33., 26., 24., 25., 24., 24., 24., 25., 24., 24., 24., 25., 25., 24., 24., 24., 25., 24., 24., 32., 22., 22., 21., 21., 22., 22., 22., 21., 22., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",378,378,0,50,"encoder/6/1/attention/3/elem","encoder/6/1/attention/3/elem","encoder/6/1/attention/3/elem","Elementwise","Elementwise","Elementwise",18.,18.2667,40.,"{40., 21., 19., 18., 18., 19., 19., 18., 19., 19., 19., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 19., 19., 19., 19., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",379,379,0,50,"encoder/6/1/attention/3/value/Net","encoder/6/1/attention/3/value/Net","encoder/6/1/attention/3/value/Net","Linear","Linear","Linear",21.,23.5667,59.,"{59., 32., 29., 22., 22., 22., 22., 22., 22., 21., 21., 21., 22., 22., 21., 21., 22., 22., 22., 21., 22., 22., 21., 34., 25., 24., 24., 25., 24., 24., 25., 24., 24., 25., 52., 33., 32., 32., 33., 25., 24., 25., 24., 24., 25., 24., 24., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",380,380,0,50,"encoder/6/1/attention/3/attention/ScoringNet/1","encoder/6/1/attention/3/attention/ScoringNet/1","encoder/6/1/attention/3/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2667,46.,"{46., 23., 20., 19., 20., 20., 19., 19., 20., 19., 20., 19., 19., 19., 19., 44., 20., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 19., 19., 19., 19., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",381,381,0,50,"encoder/6/1/attention/4/key/Net","encoder/6/1/attention/4/key/Net","encoder/6/1/attention/4/key/Net","Linear","Linear","Linear",21.,24.1,60.,"{60., 32., 23., 22., 21., 33., 24., 24., 25., 24., 24., 24., 24., 24., 25., 23., 24., 24., 25., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 25., 23., 24., 24., 24., 51., 27., 24., 24., 33., 32., 34., 25., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",382,382,0,50,"encoder/6/1/attention/4/query/Net","encoder/6/1/attention/4/query/Net","encoder/6/1/attention/4/query/Net","Linear","Linear","Linear",21.,24.166700000000002,60.,"{60., 32., 23., 22., 22., 22., 22., 21., 21., 21., 22., 21., 21., 34., 24., 25., 24., 25., 24., 25., 24., 24., 24., 24., 25., 24., 25., 25., 24., 24., 25., 24., 25., 24., 24., 25., 24., 24., 24., 24., 24., 25., 24., 24., 25., 24., 24., 25., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",383,383,0,50,"encoder/6/1/attention/4/elem","encoder/6/1/attention/4/elem","encoder/6/1/attention/4/elem","Elementwise","Elementwise","Elementwise",18.,18.,41.,"{41., 21., 19., 18., 18., 18., 19., 19., 18., 19., 19., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",384,384,0,50,"encoder/6/1/attention/4/value/Net","encoder/6/1/attention/4/value/Net","encoder/6/1/attention/4/value/Net","Linear","Linear","Linear",21.,22.2667,58.,"{58., 32., 30., 29., 28., 23., 22., 22., 21., 22., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 22., 21., 21., 22., 21., 21., 22., 21., 21., 33., 24., 24., 24., 24., 24., 24., 24., 50., 34., 34., 26., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",385,385,0,50,"encoder/6/1/attention/4/attention/ScoringNet/1","encoder/6/1/attention/4/attention/ScoringNet/1","encoder/6/1/attention/4/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.166700000000002,47.,"{47., 22., 20., 20., 20., 19., 20., 20., 19., 19., 20., 20., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20., 20., 19., 20., 19., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",386,386,0,50,"encoder/6/1/attention/5/key/Net","encoder/6/1/attention/5/key/Net","encoder/6/1/attention/5/key/Net","Linear","Linear","Linear",24.,24.4667,62.,"{62., 32., 41., 33., 26., 25., 24., 25., 25., 25., 24., 24., 24., 25., 24., 24., 24., 53., 25., 25., 24., 24., 24., 25., 24., 24., 24., 26., 49., 27., 25., 25., 25., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 36., 27., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",387,387,0,50,"encoder/6/1/attention/5/query/Net","encoder/6/1/attention/5/query/Net","encoder/6/1/attention/5/query/Net","Linear","Linear","Linear",23.,25.5667,58.,"{58., 31., 38., 25., 32., 26., 31., 25., 24., 24., 23., 31., 26., 32., 34., 33., 26., 24., 24., 31., 32., 25., 31., 26., 32., 33., 24., 24., 24., 31., 25., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 23., 23., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",388,388,0,50,"encoder/6/1/attention/5/elem","encoder/6/1/attention/5/elem","encoder/6/1/attention/5/elem","Elementwise","Elementwise","Elementwise",17.,18.1,40.,"{40., 21., 20., 18., 18., 18., 19., 18., 19., 18., 17., 19., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 19., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 40., 20., 19., 18., 18., 18., 18., 18., 18., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",389,389,0,50,"encoder/6/1/attention/5/value/Net","encoder/6/1/attention/5/value/Net","encoder/6/1/attention/5/value/Net","Linear","Linear","Linear",22.,24.133300000000002,60.,"{60., 31., 23., 22., 22., 22., 23., 29., 30., 28., 22., 44., 31., 24., 22., 33., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",390,390,0,50,"encoder/6/1/attention/5/attention/ScoringNet/1","encoder/6/1/attention/5/attention/ScoringNet/1","encoder/6/1/attention/5/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2333,46.,"{46., 23., 20., 20., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 20., 20., 19., 19., 19., 20., 20., 19., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",391,391,0,50,"encoder/6/1/attention/6/key/Net","encoder/6/1/attention/6/key/Net","encoder/6/1/attention/6/key/Net","Linear","Linear","Linear",22.,24.2667,59.,"{59., 31., 24., 22., 33., 24., 24., 25., 24., 24., 25., 33., 33., 32., 33., 25., 25., 24., 24., 25., 25., 24., 24., 24., 24., 25., 24., 24., 24., 24., 25., 24., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",392,392,0,50,"encoder/6/1/attention/6/query/Net","encoder/6/1/attention/6/query/Net","encoder/6/1/attention/6/query/Net","Linear","Linear","Linear",21.,24.6,61.,"{61., 32., 23., 29., 30., 29., 29., 22., 28., 29., 22., 22., 22., 34., 24., 33., 27., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24., 36., 32., 21., 21., 21., 21., 21., 21., 22., 33., 25., 25., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",393,393,0,50,"encoder/6/1/attention/6/elem","encoder/6/1/attention/6/elem","encoder/6/1/attention/6/elem","Elementwise","Elementwise","Elementwise",18.,18.166700000000002,46.,"{46., 21., 20., 19., 18., 19., 18., 18., 19., 19., 18., 18., 18., 18., 18., 19., 19., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 43., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 29., 19., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",394,394,0,50,"encoder/6/1/attention/6/value/Net","encoder/6/1/attention/6/value/Net","encoder/6/1/attention/6/value/Net","Linear","Linear","Linear",21.,23.8333,62.,"{62., 32., 23., 22., 22., 22., 22., 22., 22., 21., 22., 22., 21., 21., 34., 24., 25., 24., 24., 24., 24., 24., 34., 32., 25., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 25., 24., 24., 24., 25., 24., 24., 24., 37., 22., 33., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",395,395,0,50,"encoder/6/1/attention/6/attention/ScoringNet/1","encoder/6/1/attention/6/attention/ScoringNet/1","encoder/6/1/attention/6/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.7,65.,"{47., 23., 20., 20., 20., 20., 19., 20., 20., 19., 20., 20., 19., 20., 19., 65., 21., 20., 20., 19., 20., 19., 20., 19., 20., 20., 19., 20., 19., 19., 20., 33., 21., 19., 20., 20., 19., 20., 19., 20., 19., 19., 20., 20., 19., 20., 19., 20., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",396,396,0,50,"encoder/6/1/attention/7/key/Net","encoder/6/1/attention/7/key/Net","encoder/6/1/attention/7/key/Net","Linear","Linear","Linear",21.,24.0667,63.,"{63., 32., 23., 22., 21., 21., 22., 34., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 25., 25., 24., 24., 24., 33., 27., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 32., 25., 24., 24., 24., 24., 24., 24., 32., 22., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",397,397,0,50,"encoder/6/1/attention/7/query/Net","encoder/6/1/attention/7/query/Net","encoder/6/1/attention/7/query/Net","Linear","Linear","Linear",24.,24.2667,63.,"{51., 36., 34., 26., 25., 25., 25., 24., 24., 25., 24., 25., 24., 24., 24., 25., 24., 25., 24., 24., 63., 33., 26., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",398,398,0,50,"encoder/6/1/attention/7/elem","encoder/6/1/attention/7/elem","encoder/6/1/attention/7/elem","Elementwise","Elementwise","Elementwise",17.,18.0333,64.,"{43., 23., 31., 19., 19., 18., 18., 18., 18., 18., 18., 64., 21., 21., 20., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 19., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",399,399,0,50,"encoder/6/1/attention/7/value/Net","encoder/6/1/attention/7/value/Net","encoder/6/1/attention/7/value/Net","Linear","Linear","Linear",24.,24.,61.,"{61., 32., 44., 25., 25., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",400,400,0,50,"encoder/6/1/attention/7/attention/ScoringNet/1","encoder/6/1/attention/7/attention/ScoringNet/1","encoder/6/1/attention/7/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.433300000000003,51.,"{47., 23., 20., 51., 21., 20., 19., 19., 20., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 20., 19., 19., 19., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 20., 19., 20., 19., 19., 19., 48., 21., 19., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",401,401,0,50,"encoder/6/1/attention/8/key/Net","encoder/6/1/attention/8/key/Net","encoder/6/1/attention/8/key/Net","Linear","Linear","Linear",21.,24.,62.,"{61., 31., 29., 29., 28., 24., 22., 21., 22., 21., 34., 24., 24., 24., 24., 24., 24., 24., 24., 62., 34., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",402,402,0,50,"encoder/6/1/attention/8/query/Net","encoder/6/1/attention/8/query/Net","encoder/6/1/attention/8/query/Net","Linear","Linear","Linear",21.,24.,60.,"{60., 32., 31., 23., 22., 21., 21., 33., 25., 24., 24., 25., 24., 24., 24., 24., 25., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",403,403,0,50,"encoder/6/1/attention/8/elem","encoder/6/1/attention/8/elem","encoder/6/1/attention/8/elem","Elementwise","Elementwise","Elementwise",17.,18.,42.,"{42., 21., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 41., 19., 19., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",404,404,0,50,"encoder/6/1/attention/8/value/Net","encoder/6/1/attention/8/value/Net","encoder/6/1/attention/8/value/Net","Linear","Linear","Linear",21.,24.0667,52.,"{50., 32., 24., 34., 24., 24., 25., 24., 24., 52., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 25., 24., 26., 23., 32., 22., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",405,405,0,50,"encoder/6/1/attention/8/attention/ScoringNet/1","encoder/6/1/attention/8/attention/ScoringNet/1","encoder/6/1/attention/8/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.433300000000003,47.,"{47., 23., 20., 20., 19., 20., 19., 20., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",406,406,0,50,"encoder/6/1/attention/9/key/Net","encoder/6/1/attention/9/key/Net","encoder/6/1/attention/9/key/Net","Linear","Linear","Linear",24.,24.1,62.,"{62., 32., 29., 28., 42., 32., 26., 32., 33., 26., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",407,407,0,50,"encoder/6/1/attention/9/query/Net","encoder/6/1/attention/9/query/Net","encoder/6/1/attention/9/query/Net","Linear","Linear","Linear",21.,24.133300000000002,70.,"{70., 32., 24., 21., 21., 22., 33., 24., 32., 26., 25., 24., 24., 24., 24., 24., 24., 25., 24., 25., 32., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 25., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",408,408,0,50,"encoder/6/1/attention/9/elem","encoder/6/1/attention/9/elem","encoder/6/1/attention/9/elem","Elementwise","Elementwise","Elementwise",17.,18.,42.,"{42., 21., 21., 19., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",409,409,0,50,"encoder/6/1/attention/9/value/Net","encoder/6/1/attention/9/value/Net","encoder/6/1/attention/9/value/Net","Linear","Linear","Linear",21.,24.8667,59.,"{59., 32., 30., 30., 29., 28., 28., 23., 22., 22., 21., 21., 22., 21., 22., 21., 21., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 33., 32., 25., 24., 24., 32., 33., 26., 25., 24., 32., 32., 26., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",410,410,0,50,"encoder/6/1/attention/9/attention/ScoringNet/1","encoder/6/1/attention/9/attention/ScoringNet/1","encoder/6/1/attention/9/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.433300000000003,45.,"{45., 34., 21., 20., 19., 20., 20., 20., 19., 20., 19., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 20., 20., 19., 19., 20., 19., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",411,411,0,50,"encoder/6/1/attention/10/key/Net","encoder/6/1/attention/10/key/Net","encoder/6/1/attention/10/key/Net","Linear","Linear","Linear",21.,23.8667,61.,"{61., 32., 29., 24., 21., 21., 22., 21., 21., 21., 22., 23., 21., 22., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 23.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",412,412,0,50,"encoder/6/1/attention/10/query/Net","encoder/6/1/attention/10/query/Net","encoder/6/1/attention/10/query/Net","Linear","Linear","Linear",21.,24.700000000000003,64.,"{59., 32., 29., 29., 24., 28., 22., 28., 21., 64., 38., 25., 23., 24., 25., 38., 32., 59., 34., 32., 25., 24., 24., 33., 24., 24., 24., 24., 23., 24., 23., 24., 24., 23., 24., 24., 24., 23., 24., 24., 24., 23., 24., 24., 23., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",413,413,0,50,"encoder/6/1/attention/10/elem","encoder/6/1/attention/10/elem","encoder/6/1/attention/10/elem","Elementwise","Elementwise","Elementwise",17.,18.,41.,"{41., 21., 18., 19., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 19., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",414,414,0,50,"encoder/6/1/attention/10/value/Net","encoder/6/1/attention/10/value/Net","encoder/6/1/attention/10/value/Net","Linear","Linear","Linear",23.,24.0667,60.,"{60., 33., 36., 25., 24., 24., 24., 24., 24., 32., 32., 33., 32., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 25., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",415,415,0,50,"encoder/6/1/attention/10/attention/ScoringNet/1","encoder/6/1/attention/10/attention/ScoringNet/1","encoder/6/1/attention/10/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.4667,46.,"{46., 23., 20., 20., 20., 42., 21., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 20., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 19., 19., 19., 19., 19., 20., 19., 20., 19., 20., 19., 19., 19., 20., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",416,416,0,50,"encoder/6/1/attention/11/key/Net","encoder/6/1/attention/11/key/Net","encoder/6/1/attention/11/key/Net","Linear","Linear","Linear",21.,25.0333,62.,"{62., 32., 44., 27., 25., 25., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 25., 24., 24., 61., 34., 33., 32., 33., 33., 25., 24., 25., 24., 25., 23., 33., 21., 22., 22., 21., 29., 29., 29., 22., 21., 22., 22., 21., 22., 21., 32.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",417,417,0,50,"encoder/6/1/attention/11/query/Net","encoder/6/1/attention/11/query/Net","encoder/6/1/attention/11/query/Net","Linear","Linear","Linear",21.,26.3,64.,"{49., 33., 24., 22., 22., 22., 22., 21., 34., 24., 32., 26., 24., 24., 25., 24., 32., 26., 32., 33., 32., 33., 32., 26., 25., 24., 24., 24., 24., 24., 24., 25., 24., 24., 64., 35., 32., 53., 34., 33., 36., 25., 24., 24., 24., 24., 25., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",418,418,0,50,"encoder/6/1/attention/11/elem","encoder/6/1/attention/11/elem","encoder/6/1/attention/11/elem","Elementwise","Elementwise","Elementwise",18.,18.2333,43.,"{43., 22., 19., 19., 19., 18., 18., 18., 18., 18., 19., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 42., 21., 19., 19., 19., 19., 19., 18., 19., 19., 18., 19., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",419,419,0,50,"encoder/6/1/attention/11/value/Net","encoder/6/1/attention/11/value/Net","encoder/6/1/attention/11/value/Net","Linear","Linear","Linear",23.,24.,89.,"{61., 89., 38., 55., 35., 26., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 26., 24., 24., 24., 23., 24., 24., 24., 24., 23., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",420,420,0,50,"encoder/6/1/attention/11/attention/ScoringNet/1","encoder/6/1/attention/11/attention/ScoringNet/1","encoder/6/1/attention/11/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.900000000000002,46.,"{46., 24., 21., 20., 19., 20., 20., 20., 20., 20., 20., 20., 19., 20., 20., 19., 20., 20., 19., 20., 19., 20., 20., 20., 20., 19., 20., 20., 19., 20., 19., 20., 19., 20., 20., 19., 20., 20., 19., 21., 20., 20., 20., 19., 20., 20., 19., 20., 20., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",421,421,0,50,"encoder/6/1/attention/12/key/Net","encoder/6/1/attention/12/key/Net","encoder/6/1/attention/12/key/Net","Linear","Linear","Linear",21.,24.,60.,"{60., 32., 30., 23., 21., 21., 21., 32., 24., 24., 25., 23., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 33., 26., 24., 23., 26., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",422,422,0,50,"encoder/6/1/attention/12/query/Net","encoder/6/1/attention/12/query/Net","encoder/6/1/attention/12/query/Net","Linear","Linear","Linear",21.,24.,47.,"{47., 31., 24., 22., 21., 21., 22., 21., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 26., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",423,423,0,50,"encoder/6/1/attention/12/elem","encoder/6/1/attention/12/elem","encoder/6/1/attention/12/elem","Elementwise","Elementwise","Elementwise",18.,18.0667,42.,"{42., 21., 18., 19., 18., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 19., 18., 18., 19., 19., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",424,424,0,50,"encoder/6/1/attention/12/value/Net","encoder/6/1/attention/12/value/Net","encoder/6/1/attention/12/value/Net","Linear","Linear","Linear",22.,24.3,69.,"{59., 31., 29., 29., 22., 42., 25., 25., 24., 24., 24., 32., 25., 25., 25., 24., 24., 24., 24., 23., 25., 24., 24., 24., 24., 24., 24., 24., 25., 33., 25., 69., 44., 33., 24., 25., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",425,425,0,50,"encoder/6/1/attention/12/attention/ScoringNet/1","encoder/6/1/attention/12/attention/ScoringNet/1","encoder/6/1/attention/12/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.4667,46.,"{46., 23., 20., 19., 20., 19., 20., 19., 20., 20., 19., 19., 20., 19., 20., 20., 19., 20., 19., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 43., 21., 20., 19., 20., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",426,426,0,50,"encoder/6/1/attention/13","encoder/6/1/attention/13","encoder/6/1/attention/13","Catenate","Catenate","Catenate",55.,56.066700000000004,78.,"{78., 59., 57., 57., 56., 57., 56., 56., 56., 57., 57., 56., 57., 56., 56., 56., 56., 56., 56., 56., 57., 56., 56., 56., 56., 56., 57., 56., 56., 56., 56., 56., 56., 56., 57., 56., 56., 56., 56., 56., 56., 56., 56., 57., 56., 55., 56., 56., 56., 55.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",427,427,0,50,"encoder/6/1/attention/14/Net","encoder/6/1/attention/14/Net","encoder/6/1/attention/14/Net","Linear","Linear","Linear",138.,138.4,261.,"{261., 191., 143., 139., 138., 140., 138., 138., 139., 138., 138., 138., 138., 138., 138., 139., 138., 138., 138., 138., 138., 139., 139., 138., 139., 138., 185., 141., 139., 139., 139., 138., 139., 139., 139., 138., 139., 138., 139., 138., 138., 138., 139., 138., 138., 138., 138., 139., 138., 138.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",428,428,0,50,"encoder/6/1/dropout","encoder/6/1/dropout","encoder/6/1/dropout","Dropout","Dropout","Dropout",17.,18.,49.,"{37., 21., 18., 19., 18., 18., 17., 18., 18., 18., 19., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 49., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",429,430,1,50,"encoder/6/1/add","encoder/6/1/norm","encoder/6/1/add-encoder/6/1/norm","Threading","Normalization","Threading-Normalization",161.,162.3667,256.,"{256., 172., 163., 161., 162., 163., 163., 162., 186., 164., 162., 163., 162., 161., 161., 162., 163., 163., 162., 162., 163., 162., 161., 161., 162., 163., 162., 163., 162., 162., 162., 162., 179., 163., 163., 162., 162., 163., 162., 163., 161., 163., 162., 191., 163., 162., 162., 161., 161., 161.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",431,431,0,50,"encoder/6/2/linear1/Net","encoder/6/2/linear1/Net","encoder/6/2/linear1/Net","Linear","Linear","Linear",439.,444.90000000000003,761.,"{761., 720., 508., 483., 449., 442., 442., 442., 449., 488., 443., 475., 443., 439., 443., 441., 463., 442., 440., 442., 466., 441., 440., 442., 439., 442., 440., 441., 441., 477., 442., 489., 447., 446., 446., 445., 448., 448., 465., 441., 441., 440., 441., 441., 441., 442., 468., 443., 443., 443.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",432,432,0,50,"encoder/6/2/gelu","encoder/6/2/gelu","encoder/6/2/gelu","Elementwise","Elementwise","Elementwise",105.,105.53330000000001,147.,"{137., 109., 107., 106., 129., 108., 106., 105., 106., 105., 105., 105., 105., 105., 105., 105., 105., 105., 105., 106., 105., 105., 105., 105., 106., 105., 105., 106., 105., 105., 105., 106., 106., 105., 105., 106., 105., 106., 106., 106., 123., 106., 115., 106., 106., 105., 106., 106., 147., 110.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",433,433,0,50,"encoder/6/2/linear2/Net","encoder/6/2/linear2/Net","encoder/6/2/linear2/Net","Linear","Linear","Linear",431.,433.36670000000004,530.,"{530., 497., 505., 441., 433., 433., 432., 442., 432., 475., 433., 467., 435., 431., 434., 433., 432., 432., 432., 433., 458., 434., 433., 432., 433., 432., 432., 432., 433., 468., 434., 457., 434., 433., 432., 432., 432., 432., 458., 432., 432., 432., 433., 432., 432., 431., 432., 459., 433., 432.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",434,434,0,50,"encoder/6/2/dropout","encoder/6/2/dropout","encoder/6/2/dropout","Dropout","Dropout","Dropout",20.,20.400000000000002,43.,"{43., 23., 21., 21., 21., 20., 20., 21., 20., 21., 21., 20., 20., 21., 20., 20., 21., 20., 20., 21., 20., 20., 21., 21., 20., 20., 21., 20., 20., 21., 21., 20., 21., 21., 20., 20., 21., 20., 20., 20., 20., 20., 21., 20., 21., 20., 20., 21., 20., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",435,436,1,50,"encoder/6/2/add","encoder/6/2/norm","encoder/6/2/add-encoder/6/2/norm","Threading","Normalization","Threading-Normalization",161.,162.4333,218.,"{218., 167., 163., 162., 173., 166., 162., 162., 162., 164., 162., 162., 163., 162., 163., 168., 162., 163., 162., 162., 163., 161., 162., 162., 162., 162., 162., 161., 162., 161., 162., 163., 163., 177., 164., 163., 163., 163., 181., 163., 162., 162., 163., 162., 162., 162., 162., 163., 163., 162.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",437,437,0,50,"encoder/7/1/attention/1/key/Net","encoder/7/1/attention/1/key/Net","encoder/7/1/attention/1/key/Net","Linear","Linear","Linear",23.,24.4667,68.,"{68., 32., 24., 33., 25., 25., 24., 24., 24., 24., 24., 33., 33., 32., 32., 25., 31., 25., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 33., 37., 36., 26., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",438,438,0,50,"encoder/7/1/attention/1/query/Net","encoder/7/1/attention/1/query/Net","encoder/7/1/attention/1/query/Net","Linear","Linear","Linear",21.,24.166700000000002,59.,"{59., 31., 30., 29., 29., 22., 29., 22., 21., 22., 22., 21., 21., 22., 33., 24., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 25., 24., 24., 24., 24., 25., 25., 23., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",439,439,0,50,"encoder/7/1/attention/1/elem","encoder/7/1/attention/1/elem","encoder/7/1/attention/1/elem","Elementwise","Elementwise","Elementwise",17.,18.1,43.,"{43., 21., 19., 19., 18., 18., 19., 19., 19., 19., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",440,440,0,50,"encoder/7/1/attention/1/value/Net","encoder/7/1/attention/1/value/Net","encoder/7/1/attention/1/value/Net","Linear","Linear","Linear",21.,25.8333,59.,"{59., 32., 30., 23., 21., 21., 29., 22., 22., 21., 34., 25., 24., 24., 24., 24., 24., 32., 32., 33., 32., 32., 25., 24., 24., 25., 24., 24., 24., 25., 32., 33., 25., 25., 24., 32., 32., 32., 32., 25., 25., 24., 25., 25., 24., 24., 25., 24., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",441,441,0,50,"encoder/7/1/attention/1/attention/ScoringNet/1","encoder/7/1/attention/1/attention/ScoringNet/1","encoder/7/1/attention/1/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2667,45.,"{45., 33., 21., 20., 20., 19., 19., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 19., 20., 19., 19., 20., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 19., 19., 20., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",442,442,0,50,"encoder/7/1/attention/2/key/Net","encoder/7/1/attention/2/key/Net","encoder/7/1/attention/2/key/Net","Linear","Linear","Linear",22.,24.2333,59.,"{59., 32., 23., 22., 32., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 32., 32., 25., 32., 33., 32., 26., 25., 24., 24., 24., 24., 24., 24., 24., 24., 25., 26., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",443,443,0,50,"encoder/7/1/attention/2/query/Net","encoder/7/1/attention/2/query/Net","encoder/7/1/attention/2/query/Net","Linear","Linear","Linear",21.,24.166700000000002,59.,"{59., 32., 22., 21., 21., 22., 22., 57., 38., 32., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 50., 25., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 26., 35., 31., 21., 21., 33., 24., 24., 24., 24., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",444,444,0,50,"encoder/7/1/attention/2/elem","encoder/7/1/attention/2/elem","encoder/7/1/attention/2/elem","Elementwise","Elementwise","Elementwise",18.,18.,39.,"{39., 20., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 19., 18., 19., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",445,445,0,50,"encoder/7/1/attention/2/value/Net","encoder/7/1/attention/2/value/Net","encoder/7/1/attention/2/value/Net","Linear","Linear","Linear",24.,37.6667,64.,"{64., 38., 39., 37., 38., 38., 38., 38., 38., 38., 38., 38., 38., 38., 38., 38., 38., 38., 38., 38., 37., 37., 37., 37., 38., 37., 37., 38., 37., 38., 37., 37., 38., 38., 38., 38., 38., 37., 38., 38., 37., 50., 26., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",446,446,0,50,"encoder/7/1/attention/2/attention/ScoringNet/1","encoder/7/1/attention/2/attention/ScoringNet/1","encoder/7/1/attention/2/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.7333,45.,"{45., 23., 20., 20., 20., 20., 20., 19., 19., 20., 19., 19., 20., 20., 19., 20., 20., 19., 20., 19., 20., 20., 19., 20., 20., 19., 20., 19., 20., 19., 20., 19., 20., 20., 19., 20., 19., 20., 20., 19., 20., 20., 20., 20., 19., 20., 19., 20., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",447,447,0,50,"encoder/7/1/attention/3/key/Net","encoder/7/1/attention/3/key/Net","encoder/7/1/attention/3/key/Net","Linear","Linear","Linear",21.,34.9333,48.,"{48., 31., 31., 30., 23., 21., 34., 25., 39., 36., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 34., 34., 35., 35., 35., 35., 34., 35., 34., 35., 35., 35., 34., 35.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",448,448,0,50,"encoder/7/1/attention/3/query/Net","encoder/7/1/attention/3/query/Net","encoder/7/1/attention/3/query/Net","Linear","Linear","Linear",22.,24.8333,73.,"{47., 32., 24., 22., 73., 38., 33., 33., 25., 25., 26., 25., 24., 25., 24., 24., 24., 25., 24., 26., 25., 32., 33., 32., 33., 33., 25., 24., 25., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 25., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",449,449,0,50,"encoder/7/1/attention/3/elem","encoder/7/1/attention/3/elem","encoder/7/1/attention/3/elem","Elementwise","Elementwise","Elementwise",18.,18.3667,43.,"{43., 23., 21., 20., 21., 21., 39., 20., 19., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 19., 19., 18., 18., 18., 19., 18., 18., 18., 19., 19., 19., 19., 19., 19., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",450,450,0,50,"encoder/7/1/attention/3/value/Net","encoder/7/1/attention/3/value/Net","encoder/7/1/attention/3/value/Net","Linear","Linear","Linear",21.,23.166700000000002,48.,"{48., 32., 34., 24., 24., 25., 24., 24., 25., 24., 24., 24., 25., 24., 24., 24., 25., 25., 24., 24., 24., 25., 25., 24., 36., 23., 32., 22., 21., 22., 21., 22., 21., 22., 21., 22., 21., 22., 21., 22., 22., 21., 21., 22., 22., 21., 22., 21., 22., 22.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",451,451,0,50,"encoder/7/1/attention/3/attention/ScoringNet/1","encoder/7/1/attention/3/attention/ScoringNet/1","encoder/7/1/attention/3/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3,45.,"{45., 23., 20., 20., 20., 20., 20., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",452,452,0,50,"encoder/7/1/attention/4/key/Net","encoder/7/1/attention/4/key/Net","encoder/7/1/attention/4/key/Net","Linear","Linear","Linear",21.,23.1,59.,"{59., 32., 30., 23., 28., 22., 22., 22., 22., 21., 22., 21., 21., 22., 21., 22., 21., 22., 21., 22., 21., 22., 21., 21., 22., 33., 24., 24., 32., 24., 24., 24., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 36., 22., 21., 22.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",453,453,0,50,"encoder/7/1/attention/4/query/Net","encoder/7/1/attention/4/query/Net","encoder/7/1/attention/4/query/Net","Linear","Linear","Linear",21.,21.3,58.,"{58., 32., 23., 22., 22., 21., 22., 22., 21., 21., 22., 21., 21., 21., 22., 21., 22., 21., 22., 21., 21., 22., 21., 24., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21., 21., 22., 22., 21., 21., 21., 21., 21., 21., 22., 21., 22., 21., 22.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",454,454,0,50,"encoder/7/1/attention/4/elem","encoder/7/1/attention/4/elem","encoder/7/1/attention/4/elem","Elementwise","Elementwise","Elementwise",18.,18.,38.,"{38., 22., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",455,455,0,50,"encoder/7/1/attention/4/value/Net","encoder/7/1/attention/4/value/Net","encoder/7/1/attention/4/value/Net","Linear","Linear","Linear",21.,25.900000000000002,60.,"{58., 31., 24., 21., 28., 22., 22., 21., 21., 28., 30., 30., 30., 30., 29., 29., 29., 30., 22., 21., 22., 21., 22., 28., 22., 21., 21., 34., 32., 25., 60., 36., 34., 32., 25., 25., 26., 24., 24., 24., 25., 24., 24., 24., 24., 31., 24., 24., 24., 32.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",456,456,0,50,"encoder/7/1/attention/4/attention/ScoringNet/1","encoder/7/1/attention/4/attention/ScoringNet/1","encoder/7/1/attention/4/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.5,45.,"{45., 34., 21., 20., 20., 19., 19., 20., 19., 19., 20., 19., 20., 20., 19., 20., 19., 19., 20., 19., 20., 19., 20., 20., 19., 20., 19., 20., 19., 19., 19., 19., 20., 20., 19., 20., 20., 19., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",457,457,0,50,"encoder/7/1/attention/5/key/Net","encoder/7/1/attention/5/key/Net","encoder/7/1/attention/5/key/Net","Linear","Linear","Linear",21.,23.0667,59.,"{59., 31., 30., 22., 34., 24., 25., 25., 24., 24., 24., 24., 25., 24., 25., 24., 24., 25., 24., 24., 25., 25., 24., 24., 24., 36., 23., 32., 21., 21., 21., 21., 22., 21., 21., 22., 22., 21., 21., 21., 23., 21., 21., 22., 21., 21., 22., 21., 21., 22.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",458,458,0,50,"encoder/7/1/attention/5/query/Net","encoder/7/1/attention/5/query/Net","encoder/7/1/attention/5/query/Net","Linear","Linear","Linear",21.,23.8,61.,"{58., 31., 24., 22., 22., 21., 22., 21., 21., 22., 21., 22., 21., 32., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 61., 33., 32., 32., 32., 33., 26., 24., 24., 24., 24., 25., 24., 37., 33., 22., 21., 21., 21., 21., 22., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",459,459,0,50,"encoder/7/1/attention/5/elem","encoder/7/1/attention/5/elem","encoder/7/1/attention/5/elem","Elementwise","Elementwise","Elementwise",17.,18.,40.,"{40., 21., 19., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 17.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",460,460,0,50,"encoder/7/1/attention/5/value/Net","encoder/7/1/attention/5/value/Net","encoder/7/1/attention/5/value/Net","Linear","Linear","Linear",21.,23.2333,59.,"{59., 33., 30., 30., 33., 25., 24., 24., 25., 24., 34., 25., 24., 25., 24., 23., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 23., 36., 33., 22., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21., 22., 21., 22., 21., 21., 22., 22., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",461,461,0,50,"encoder/7/1/attention/5/attention/ScoringNet/1","encoder/7/1/attention/5/attention/ScoringNet/1","encoder/7/1/attention/5/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3333,44.,"{44., 34., 20., 20., 20., 19., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 42., 22., 20., 19., 20., 19., 19., 20., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",462,462,0,50,"encoder/7/1/attention/6/key/Net","encoder/7/1/attention/6/key/Net","encoder/7/1/attention/6/key/Net","Linear","Linear","Linear",21.,24.1,58.,"{58., 32., 30., 23., 22., 21., 21., 21., 21., 21., 21., 34., 24., 24., 24., 25., 25., 25., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 32., 24., 25., 24., 24., 24., 24., 24., 24., 24., 36., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",463,463,0,50,"encoder/7/1/attention/6/query/Net","encoder/7/1/attention/6/query/Net","encoder/7/1/attention/6/query/Net","Linear","Linear","Linear",23.,24.1,58.,"{58., 56., 33., 29., 29., 28., 29., 31., 36., 27., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 25., 23., 24., 24., 24., 24., 25., 24., 25., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",464,464,0,50,"encoder/7/1/attention/6/elem","encoder/7/1/attention/6/elem","encoder/7/1/attention/6/elem","Elementwise","Elementwise","Elementwise",18.,18.,39.,"{39., 20., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",465,465,0,50,"encoder/7/1/attention/6/value/Net","encoder/7/1/attention/6/value/Net","encoder/7/1/attention/6/value/Net","Linear","Linear","Linear",23.,27.3667,56.,"{48., 32., 34., 32., 32., 32., 32., 26., 24., 32., 32., 32., 26., 24., 24., 24., 24., 24., 24., 24., 24., 25., 23., 25., 24., 25., 24., 24., 24., 24., 24., 24., 32., 33., 33., 32., 25., 56., 34., 32., 33., 25., 25., 26., 32., 33., 24., 32., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",466,466,0,50,"encoder/7/1/attention/6/attention/ScoringNet/1","encoder/7/1/attention/6/attention/ScoringNet/1","encoder/7/1/attention/6/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2,44.,"{44., 34., 21., 20., 19., 20., 19., 19., 19., 20., 19., 19., 19., 20., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 20., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",467,467,0,50,"encoder/7/1/attention/7/key/Net","encoder/7/1/attention/7/key/Net","encoder/7/1/attention/7/key/Net","Linear","Linear","Linear",20.,23.633300000000002,62.,"{59., 32., 24., 21., 23., 21., 21., 21., 21., 22., 31., 22., 21., 22., 21., 21., 21., 21., 34., 24., 24., 24., 25., 24., 23., 24., 62., 37., 32., 32., 33., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 32., 20., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",468,468,0,50,"encoder/7/1/attention/7/query/Net","encoder/7/1/attention/7/query/Net","encoder/7/1/attention/7/query/Net","Linear","Linear","Linear",21.,24.633300000000002,57.,"{57., 32., 44., 33., 32., 25., 32., 32., 33., 26., 32., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 33., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 22., 21., 33., 24., 24., 24., 24., 24., 24., 24., 32., 32., 24., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",469,469,0,50,"encoder/7/1/attention/7/elem","encoder/7/1/attention/7/elem","encoder/7/1/attention/7/elem","Elementwise","Elementwise","Elementwise",17.,18.166700000000002,43.,"{40., 21., 18., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 43., 18., 19., 19., 18., 19., 19., 18., 18., 19., 18., 19., 18., 18., 19., 19., 18., 18., 18., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",470,470,0,50,"encoder/7/1/attention/7/value/Net","encoder/7/1/attention/7/value/Net","encoder/7/1/attention/7/value/Net","Linear","Linear","Linear",21.,23.433300000000003,63.,"{63., 33., 23., 22., 22., 22., 21., 21., 21., 21., 22., 33., 25., 24., 25., 25., 24., 24., 24., 32., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 37., 22., 22., 22., 21., 22., 21., 22., 21., 22., 21., 28., 22., 23., 33., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",471,471,0,50,"encoder/7/1/attention/7/attention/ScoringNet/1","encoder/7/1/attention/7/attention/ScoringNet/1","encoder/7/1/attention/7/attention/ScoringNet/1","Dot","Dot","Dot",21.,21.5,46.,"{46., 34., 23., 22., 21., 21., 21., 22., 21., 22., 22., 22., 21., 21., 22., 22., 23., 21., 22., 21., 21., 21., 22., 22., 21., 22., 21., 21., 22., 22., 21., 21., 22., 21., 21., 22., 21., 21., 22., 22., 21., 21., 22., 21., 21., 22., 22., 21., 22., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",472,472,0,50,"encoder/7/1/attention/8/key/Net","encoder/7/1/attention/8/key/Net","encoder/7/1/attention/8/key/Net","Linear","Linear","Linear",21.,24.5,59.,"{59., 32., 29., 29., 29., 29., 24., 22., 21., 21., 22., 22., 34., 25., 24., 25., 25., 24., 25., 25., 24., 24., 25., 25., 24., 25., 24., 24., 25., 24., 24., 25., 25., 24., 24., 25., 25., 24., 24., 25., 25., 24., 24., 24., 25., 25., 25., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",473,473,0,50,"encoder/7/1/attention/8/query/Net","encoder/7/1/attention/8/query/Net","encoder/7/1/attention/8/query/Net","Linear","Linear","Linear",21.,23.933300000000003,46.,"{46., 32., 29., 23., 21., 22., 21., 22., 21., 21., 33., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 23., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 23., 24., 24., 24., 24., 23., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",474,474,0,50,"encoder/7/1/attention/8/elem","encoder/7/1/attention/8/elem","encoder/7/1/attention/8/elem","Elementwise","Elementwise","Elementwise",18.,18.2,42.,"{39., 22., 19., 18., 19., 18., 19., 19., 18., 18., 20., 42., 20., 18., 19., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 20., 18., 18., 18., 18., 18., 18., 19., 18., 19., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",475,475,0,50,"encoder/7/1/attention/8/value/Net","encoder/7/1/attention/8/value/Net","encoder/7/1/attention/8/value/Net","Linear","Linear","Linear",23.,24.133300000000002,58.,"{58., 32., 42., 33., 25., 25., 32., 33., 25., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 23., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 23., 24., 24., 24., 31.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",476,476,0,50,"encoder/7/1/attention/8/attention/ScoringNet/1","encoder/7/1/attention/8/attention/ScoringNet/1","encoder/7/1/attention/8/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3333,48.,"{48., 39., 21., 19., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 20., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 39., 21., 19., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",477,477,0,50,"encoder/7/1/attention/9/key/Net","encoder/7/1/attention/9/key/Net","encoder/7/1/attention/9/key/Net","Linear","Linear","Linear",21.,23.900000000000002,59.,"{59., 32., 30., 23., 21., 22., 44., 32., 33., 27., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 23., 24., 24., 32., 21., 21., 21., 21., 21., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",478,478,0,50,"encoder/7/1/attention/9/query/Net","encoder/7/1/attention/9/query/Net","encoder/7/1/attention/9/query/Net","Linear","Linear","Linear",21.,23.8,62.,"{58., 32., 23., 22., 21., 21., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 62., 34., 33., 25., 24., 24., 24., 24., 24., 25., 25., 24., 23., 24., 24., 24., 24., 24., 25., 35., 32., 22., 21., 21., 21., 22., 21., 21., 21., 21., 22.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",479,479,0,50,"encoder/7/1/attention/9/elem","encoder/7/1/attention/9/elem","encoder/7/1/attention/9/elem","Elementwise","Elementwise","Elementwise",17.,18.,39.,"{39., 21., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 17., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 17., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",480,480,0,50,"encoder/7/1/attention/9/value/Net","encoder/7/1/attention/9/value/Net","encoder/7/1/attention/9/value/Net","Linear","Linear","Linear",21.,22.8333,58.,"{58., 32., 23., 22., 21., 34., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 23., 32., 21., 21., 21., 22., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21., 22., 21., 21., 22., 21., 22.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",481,481,0,50,"encoder/7/1/attention/9/attention/ScoringNet/1","encoder/7/1/attention/9/attention/ScoringNet/1","encoder/7/1/attention/9/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.0667,43.,"{43., 22., 20., 19., 20., 19., 19., 19., 20., 19., 19., 19., 41., 21., 19., 19., 20., 19., 19., 19., 19., 20., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",482,482,0,50,"encoder/7/1/attention/10/key/Net","encoder/7/1/attention/10/key/Net","encoder/7/1/attention/10/key/Net","Linear","Linear","Linear",23.,24.200000000000003,58.,"{58., 31., 44., 34., 33., 25., 32., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 45., 34., 27., 25., 23., 24., 32., 25., 24., 24., 24., 24., 25., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",483,483,0,50,"encoder/7/1/attention/10/query/Net","encoder/7/1/attention/10/query/Net","encoder/7/1/attention/10/query/Net","Linear","Linear","Linear",22.,24.1,59.,"{59., 32., 29., 29., 29., 22., 22., 22., 22., 31., 25., 24., 24., 24., 24., 24., 25., 25., 25., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",484,484,0,50,"encoder/7/1/attention/10/elem","encoder/7/1/attention/10/elem","encoder/7/1/attention/10/elem","Elementwise","Elementwise","Elementwise",17.,18.,39.,"{39., 22., 19., 19., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",485,485,0,50,"encoder/7/1/attention/10/value/Net","encoder/7/1/attention/10/value/Net","encoder/7/1/attention/10/value/Net","Linear","Linear","Linear",21.,24.5667,59.,"{59., 32., 29., 33., 25., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 36., 32., 45., 30., 29., 23., 22., 21., 21., 21., 22., 33., 24., 24., 24., 24., 32., 25., 24., 24., 25., 24., 25., 32., 25., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",486,486,0,50,"encoder/7/1/attention/10/attention/ScoringNet/1","encoder/7/1/attention/10/attention/ScoringNet/1","encoder/7/1/attention/10/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.133300000000002,44.,"{44., 34., 20., 20., 20., 19., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 20., 20., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",487,487,0,50,"encoder/7/1/attention/11/key/Net","encoder/7/1/attention/11/key/Net","encoder/7/1/attention/11/key/Net","Linear","Linear","Linear",21.,24.200000000000003,60.,"{60., 32., 30., 23., 29., 29., 29., 23., 21., 22., 22., 21., 22., 32., 24., 32., 26., 24., 24., 24., 24., 24., 25., 24., 24., 54., 33., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 25., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",488,488,0,50,"encoder/7/1/attention/11/query/Net","encoder/7/1/attention/11/query/Net","encoder/7/1/attention/11/query/Net","Linear","Linear","Linear",23.,25.433300000000003,59.,"{59., 33., 23., 34., 25., 25., 26., 33., 33., 27., 25., 24., 32., 25., 33., 33., 27., 24., 33., 27., 32., 32., 26., 33., 25., 25., 25., 25., 24., 24., 24., 24., 25., 24., 25., 24., 24., 24., 24., 25., 24., 25., 24., 24., 24., 25., 24., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",489,489,0,50,"encoder/7/1/attention/11/elem","encoder/7/1/attention/11/elem","encoder/7/1/attention/11/elem","Elementwise","Elementwise","Elementwise",18.,18.3333,39.,"{39., 21., 19., 19., 19., 18., 18., 18., 19., 18., 18., 19., 20., 19., 18., 18., 18., 18., 19., 19., 27., 19., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 19., 18., 19., 18., 19., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",490,490,0,50,"encoder/7/1/attention/11/value/Net","encoder/7/1/attention/11/value/Net","encoder/7/1/attention/11/value/Net","Linear","Linear","Linear",21.,24.,47.,"{47., 33., 25., 22., 22., 21., 21., 21., 21., 22., 21., 21., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 25., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",491,491,0,50,"encoder/7/1/attention/11/attention/ScoringNet/1","encoder/7/1/attention/11/attention/ScoringNet/1","encoder/7/1/attention/11/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.7,43.,"{43., 23., 21., 20., 20., 20., 27., 20., 20., 20., 19., 20., 19., 20., 19., 20., 20., 20., 19., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 20., 19., 20., 20., 19., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",492,492,0,50,"encoder/7/1/attention/12/key/Net","encoder/7/1/attention/12/key/Net","encoder/7/1/attention/12/key/Net","Linear","Linear","Linear",21.,24.8333,60.,"{60., 32., 29., 42., 32., 32., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 25., 24., 32., 32., 33., 26., 24., 24., 24., 24., 24., 24., 31., 32., 32., 25., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 23., 32., 21., 21., 21., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",493,493,0,50,"encoder/7/1/attention/12/query/Net","encoder/7/1/attention/12/query/Net","encoder/7/1/attention/12/query/Net","Linear","Linear","Linear",23.,24.166700000000002,92.,"{57., 32., 92., 37., 25., 24., 24., 24., 24., 24., 24., 23., 25., 23., 25., 24., 24., 24., 24., 24., 24., 74., 28., 24., 25., 31., 25., 24., 24., 24., 23., 24., 24., 57., 32., 26., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",494,494,0,50,"encoder/7/1/attention/12/elem","encoder/7/1/attention/12/elem","encoder/7/1/attention/12/elem","Elementwise","Elementwise","Elementwise",18.,18.4333,39.,"{39., 20., 19., 18., 19., 18., 19., 19., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 19., 18., 18., 19., 18., 18., 19., 18., 18., 19., 18., 19., 18., 19., 18., 18., 19., 18., 18., 18., 19., 18., 18., 19., 19., 18., 18., 19., 19., 27., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",495,495,0,50,"encoder/7/1/attention/12/value/Net","encoder/7/1/attention/12/value/Net","encoder/7/1/attention/12/value/Net","Linear","Linear","Linear",21.,23.133300000000002,58.,"{58., 26., 22., 29., 23., 21., 22., 21., 21., 22., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21., 41., 25., 24., 24., 24., 24., 24., 23., 23., 25., 23., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 23., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",496,496,0,50,"encoder/7/1/attention/12/attention/ScoringNet/1","encoder/7/1/attention/12/attention/ScoringNet/1","encoder/7/1/attention/12/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.400000000000002,55.,"{45., 22., 20., 20., 19., 19., 20., 19., 19., 19., 20., 19., 20., 19., 20., 19., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 55., 20., 20., 19., 20., 19., 20., 26., 20., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",497,497,0,50,"encoder/7/1/attention/13","encoder/7/1/attention/13","encoder/7/1/attention/13","Catenate","Catenate","Catenate",55.,56.033300000000004,80.,"{80., 58., 57., 56., 56., 56., 57., 56., 56., 55., 56., 57., 56., 56., 56., 56., 56., 57., 56., 56., 56., 56., 56., 56., 56., 56., 57., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 57., 56., 56., 56., 56., 56., 56., 76., 58., 57., 56., 56.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",498,498,0,50,"encoder/7/1/attention/14/Net","encoder/7/1/attention/14/Net","encoder/7/1/attention/14/Net","Linear","Linear","Linear",138.,139.20000000000002,239.,"{239., 210., 148., 139., 139., 138., 139., 140., 139., 139., 140., 139., 139., 139., 139., 138., 139., 140., 139., 138., 139., 168., 150., 141., 139., 139., 138., 139., 142., 140., 139., 138., 138., 140., 138., 138., 140., 139., 138., 140., 139., 139., 138., 139., 138., 140., 139., 187., 143., 139.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",499,499,0,50,"encoder/7/1/dropout","encoder/7/1/dropout","encoder/7/1/dropout","Dropout","Dropout","Dropout",17.,18.,38.,"{38., 21., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",500,501,1,50,"encoder/7/1/add","encoder/7/1/norm","encoder/7/1/add-encoder/7/1/norm","Threading","Normalization","Threading-Normalization",161.,162.76670000000001,215.,"{215., 167., 188., 165., 163., 162., 163., 163., 163., 163., 162., 162., 162., 164., 161., 162., 161., 162., 163., 165., 163., 161., 162., 161., 163., 162., 184., 174., 164., 163., 163., 163., 163., 161., 162., 162., 163., 162., 163., 163., 163., 163., 163., 162., 163., 163., 163., 163., 163., 215.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",502,502,0,50,"encoder/7/2/linear1/Net","encoder/7/2/linear1/Net","encoder/7/2/linear1/Net","Linear","Linear","Linear",439.,444.66670000000005,772.,"{772., 756., 510., 461., 449., 486., 445., 441., 441., 466., 442., 441., 441., 441., 439., 460., 442., 443., 474., 443., 443., 440., 442., 441., 442., 442., 465., 466., 443., 441., 440., 441., 440., 441., 441., 466., 441., 441., 442., 440., 452., 441., 441., 442., 467., 446., 443., 443., 443., 463.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",503,503,0,50,"encoder/7/2/gelu","encoder/7/2/gelu","encoder/7/2/gelu","Elementwise","Elementwise","Elementwise",104.,106.2,137.,"{137., 108., 106., 106., 106., 105., 105., 106., 105., 105., 105., 105., 106., 105., 104., 105., 105., 105., 105., 106., 105., 106., 106., 105., 105., 106., 105., 106., 105., 105., 105., 137., 110., 131., 113., 108., 108., 107., 107., 108., 108., 130., 110., 107., 107., 108., 108., 107., 107., 107.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",504,504,0,50,"encoder/7/2/linear2/Net","encoder/7/2/linear2/Net","encoder/7/2/linear2/Net","Linear","Linear","Linear",434.,438.40000000000003,555.,"{555., 497., 451., 441., 436., 453., 438., 437., 460., 437., 436., 436., 436., 436., 436., 435., 435., 460., 447., 438., 437., 437., 439., 436., 437., 436., 460., 454., 437., 436., 436., 437., 436., 436., 435., 462., 437., 444., 436., 434., 449., 437., 436., 435., 462., 436., 439., 437., 436., 474.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",505,505,0,50,"encoder/7/2/dropout","encoder/7/2/dropout","encoder/7/2/dropout","Dropout","Dropout","Dropout",20.,21.3,51.,"{44., 25., 24., 22., 21., 21., 22., 22., 22., 21., 21., 22., 21., 21., 21., 21., 22., 21., 21., 21., 21., 22., 22., 22., 22., 22., 22., 51., 22., 21., 21., 21., 30., 21., 29., 21., 21., 20., 21., 21., 21., 21., 20., 21., 21., 20., 20., 21., 21., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",506,507,1,50,"encoder/7/2/add","encoder/7/2/norm","encoder/7/2/add-encoder/7/2/norm","Threading","Normalization","Threading-Normalization",161.,164.4333,219.,"{219., 166., 163., 162., 201., 172., 165., 165., 165., 164., 164., 164., 164., 166., 165., 165., 171., 166., 166., 165., 164., 165., 165., 165., 165., 165., 165., 184., 165., 163., 161., 163., 164., 162., 163., 163., 162., 163., 162., 162., 162., 163., 163., 186., 169., 165., 164., 165., 164., 165.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",508,508,0,50,"encoder/8/1/attention/1/key/Net","encoder/8/1/attention/1/key/Net","encoder/8/1/attention/1/key/Net","Linear","Linear","Linear",22.,24.3333,72.,"{72., 31., 22., 33., 25., 24., 25., 25., 24., 24., 24., 25., 25., 24., 25., 24., 24., 24., 24., 24., 25., 24., 24., 25., 24., 24., 24., 24., 24., 24., 61., 35., 27., 24., 25., 24., 24., 25., 24., 24., 25., 24., 25., 24., 25., 24., 24., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",509,509,0,50,"encoder/8/1/attention/1/query/Net","encoder/8/1/attention/1/query/Net","encoder/8/1/attention/1/query/Net","Linear","Linear","Linear",21.,23.633300000000002,61.,"{61., 31., 30., 28., 29., 29., 35., 24., 24., 25., 24., 25., 25., 24., 24., 24., 25., 25., 25., 25., 25., 24., 24., 24., 24., 24., 24., 24., 25., 24., 26., 23., 33., 21., 21., 22., 21., 22., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",510,510,0,50,"encoder/8/1/attention/1/elem","encoder/8/1/attention/1/elem","encoder/8/1/attention/1/elem","Elementwise","Elementwise","Elementwise",17.,18.,45.,"{45., 43., 20., 19., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",511,511,0,50,"encoder/8/1/attention/1/value/Net","encoder/8/1/attention/1/value/Net","encoder/8/1/attention/1/value/Net","Linear","Linear","Linear",21.,24.1,61.,"{47., 26., 22., 21., 21., 21., 21., 22., 22., 22., 33., 24., 25., 23., 24., 24., 61., 35., 25., 25., 25., 25., 31., 25., 33., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 37., 34., 21., 21., 22., 21., 33., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",512,512,0,50,"encoder/8/1/attention/1/attention/ScoringNet/1","encoder/8/1/attention/1/attention/ScoringNet/1","encoder/8/1/attention/1/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3,47.,"{47., 23., 20., 20., 19., 20., 19., 20., 20., 20., 20., 19., 19., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 20., 20., 19., 19., 19., 19., 19., 20., 20., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",513,513,0,50,"encoder/8/1/attention/2/key/Net","encoder/8/1/attention/2/key/Net","encoder/8/1/attention/2/key/Net","Linear","Linear","Linear",21.,22.1,61.,"{61., 31., 29., 30., 29., 28., 30., 23., 22., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 22., 21., 21., 21., 21., 21., 22., 21., 21., 30., 23., 28., 22., 22., 21., 21., 21., 21., 21., 21., 21., 22., 32., 24., 24., 24., 24., 23., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",514,514,0,50,"encoder/8/1/attention/2/query/Net","encoder/8/1/attention/2/query/Net","encoder/8/1/attention/2/query/Net","Linear","Linear","Linear",21.,23.3333,57.,"{57., 31., 29., 22., 22., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 33., 24., 24., 23., 24., 24., 23., 25., 24., 24., 24., 24., 23., 24., 24., 24., 23., 26., 24., 24., 24., 24., 24., 32., 21., 21., 21., 21., 33., 24., 24., 24., 24., 23., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",515,515,0,50,"encoder/8/1/attention/2/elem","encoder/8/1/attention/2/elem","encoder/8/1/attention/2/elem","Elementwise","Elementwise","Elementwise",17.,18.0333,46.,"{41., 22., 19., 18., 18., 19., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 46., 20., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",516,516,0,50,"encoder/8/1/attention/2/value/Net","encoder/8/1/attention/2/value/Net","encoder/8/1/attention/2/value/Net","Linear","Linear","Linear",21.,23.200000000000003,59.,"{59., 32., 29., 30., 24., 21., 33., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 25., 22., 31., 21., 21., 21., 21., 22., 21., 22., 21., 21., 30., 28., 22., 21., 30., 22., 21., 21., 21., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",517,517,0,50,"encoder/8/1/attention/2/attention/ScoringNet/1","encoder/8/1/attention/2/attention/ScoringNet/1","encoder/8/1/attention/2/attention/ScoringNet/1","Dot","Dot","Dot",18.,19.2667,57.,"{46., 33., 20., 20., 19., 20., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 18., 20., 19., 19., 57., 23., 19., 20., 19., 20., 20., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 20., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",518,518,0,50,"encoder/8/1/attention/3/key/Net","encoder/8/1/attention/3/key/Net","encoder/8/1/attention/3/key/Net","Linear","Linear","Linear",22.,24.4667,50.,"{50., 27., 22., 22., 34., 24., 25., 24., 25., 25., 24., 32., 32., 26., 24., 25., 24., 25., 24., 25., 24., 24., 26., 24., 24., 24., 24., 24., 24., 24., 24., 24., 32., 24., 25., 26., 24., 32., 33., 26., 24., 24., 24., 24., 25., 24., 32., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",519,519,0,50,"encoder/8/1/attention/3/query/Net","encoder/8/1/attention/3/query/Net","encoder/8/1/attention/3/query/Net","Linear","Linear","Linear",21.,26.3333,59.,"{59., 32., 26., 24., 24., 25., 24., 24., 26., 24., 24., 32., 26., 24., 58., 36., 33., 27., 24., 25., 26., 23., 32., 22., 21., 21., 22., 22., 21., 33., 25., 24., 24., 24., 24., 25., 24., 24., 24., 25., 24., 26., 40., 36., 35., 34., 34., 35., 35., 34.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",520,520,0,50,"encoder/8/1/attention/3/elem","encoder/8/1/attention/3/elem","encoder/8/1/attention/3/elem","Elementwise","Elementwise","Elementwise",18.,18.3333,40.,"{40., 21., 19., 19., 18., 19., 18., 19., 18., 18., 18., 18., 19., 19., 19., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 19., 19., 19., 19., 19., 19., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",521,521,0,50,"encoder/8/1/attention/3/value/Net","encoder/8/1/attention/3/value/Net","encoder/8/1/attention/3/value/Net","Linear","Linear","Linear",22.,26.3,61.,"{47., 32., 45., 33., 32., 26., 25., 24., 24., 25., 24., 24., 24., 25., 32., 32., 25., 24., 24., 24., 32., 32., 32., 25., 25., 24., 32., 32., 32., 25., 24., 25., 24., 31., 24., 24., 24., 24., 24., 24., 24., 61., 27., 24., 24., 25., 55., 22., 22., 33.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",522,522,0,50,"encoder/8/1/attention/3/attention/ScoringNet/1","encoder/8/1/attention/3/attention/ScoringNet/1","encoder/8/1/attention/3/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.5667,52.,"{45., 34., 21., 20., 19., 19., 20., 20., 19., 20., 20., 20., 19., 20., 19., 20., 19., 19., 20., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 52., 22., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",523,523,0,50,"encoder/8/1/attention/4/key/Net","encoder/8/1/attention/4/key/Net","encoder/8/1/attention/4/key/Net","Linear","Linear","Linear",21.,24.,59.,"{59., 31., 23., 51., 31., 31., 30., 29., 22., 22., 21., 21., 22., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",524,524,0,50,"encoder/8/1/attention/4/query/Net","encoder/8/1/attention/4/query/Net","encoder/8/1/attention/4/query/Net","Linear","Linear","Linear",21.,24.1,59.,"{59., 31., 23., 21., 22., 22., 21., 21., 22., 21., 21., 22., 21., 32., 25., 24., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 25., 24., 24., 26., 24., 24., 24., 24., 24., 25., 24., 25., 25., 24., 24., 25., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",525,525,0,50,"encoder/8/1/attention/4/elem","encoder/8/1/attention/4/elem","encoder/8/1/attention/4/elem","Elementwise","Elementwise","Elementwise",17.,18.133300000000002,43.,"{43., 21., 19., 19., 19., 19., 18., 19., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 41., 20., 18., 18., 19., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",526,526,0,50,"encoder/8/1/attention/4/value/Net","encoder/8/1/attention/4/value/Net","encoder/8/1/attention/4/value/Net","Linear","Linear","Linear",21.,26.0333,60.,"{60., 31., 29., 22., 22., 21., 22., 28., 29., 22., 22., 28., 28., 23., 21., 22., 21., 22., 21., 21., 34., 31., 32., 32., 32., 32., 25., 24., 24., 23., 24., 24., 24., 31., 34., 31., 24., 24., 24., 31., 32., 32., 33., 32., 25., 24., 24., 25., 23., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",527,527,0,50,"encoder/8/1/attention/4/attention/ScoringNet/1","encoder/8/1/attention/4/attention/ScoringNet/1","encoder/8/1/attention/4/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.133300000000002,45.,"{45., 23., 21., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 19., 19., 19., 19., 20., 20., 20., 19., 19., 19., 20., 20., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",528,528,0,50,"encoder/8/1/attention/5/key/Net","encoder/8/1/attention/5/key/Net","encoder/8/1/attention/5/key/Net","Linear","Linear","Linear",21.,23.6,49.,"{49., 31., 31., 29., 22., 21., 22., 22., 21., 22., 21., 21., 22., 21., 22., 21., 22., 21., 22., 21., 33., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",529,529,0,50,"encoder/8/1/attention/5/query/Net","encoder/8/1/attention/5/query/Net","encoder/8/1/attention/5/query/Net","Linear","Linear","Linear",21.,26.5667,58.,"{57., 32., 29., 29., 29., 28., 28., 29., 28., 28., 28., 24., 21., 28., 28., 22., 29., 30., 24., 21., 21., 21., 21., 21., 34., 31., 32., 34., 58., 36., 33., 32., 32., 32., 26., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",530,530,0,50,"encoder/8/1/attention/5/elem","encoder/8/1/attention/5/elem","encoder/8/1/attention/5/elem","Elementwise","Elementwise","Elementwise",17.,18.,40.,"{40., 21., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",531,531,0,50,"encoder/8/1/attention/5/value/Net","encoder/8/1/attention/5/value/Net","encoder/8/1/attention/5/value/Net","Linear","Linear","Linear",21.,24.1,59.,"{59., 31., 31., 29., 30., 23., 21., 21., 21., 22., 21., 21., 22., 21., 22., 21., 22., 28., 28., 28., 29., 22., 21., 22., 21., 22., 21., 21., 22., 28., 29., 29., 36., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 32., 32., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",532,532,0,50,"encoder/8/1/attention/5/attention/ScoringNet/1","encoder/8/1/attention/5/attention/ScoringNet/1","encoder/8/1/attention/5/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.900000000000002,47.,"{47., 23., 20., 20., 44., 22., 20., 20., 20., 20., 20., 20., 20., 19., 20., 20., 20., 19., 20., 20., 20., 19., 20., 20., 19., 20., 19., 20., 20., 19., 20., 20., 19., 20., 20., 19., 20., 20., 19., 20., 20., 19., 20., 20., 20., 19., 20., 20., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",533,533,0,50,"encoder/8/1/attention/6/key/Net","encoder/8/1/attention/6/key/Net","encoder/8/1/attention/6/key/Net","Linear","Linear","Linear",21.,24.133300000000002,61.,"{61., 31., 23., 28., 23., 22., 22., 22., 22., 22., 22., 21., 21., 22., 22., 22., 33., 24., 25., 24., 56., 35., 33., 32., 32., 25., 25., 24., 25., 25., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 25., 24., 25., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",534,534,0,50,"encoder/8/1/attention/6/query/Net","encoder/8/1/attention/6/query/Net","encoder/8/1/attention/6/query/Net","Linear","Linear","Linear",21.,23.400000000000002,58.,"{58., 31., 30., 23., 28., 24., 22., 21., 28., 22., 21., 21., 21., 22., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 22., 33., 24., 24., 23., 24., 24., 24., 32., 26., 24., 24., 24., 24., 24., 24., 23., 24., 32., 32., 33., 26., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",535,535,0,50,"encoder/8/1/attention/6/elem","encoder/8/1/attention/6/elem","encoder/8/1/attention/6/elem","Elementwise","Elementwise","Elementwise",18.,18.2667,41.,"{41., 22., 20., 18., 19., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 19., 19., 19., 19., 18., 18., 39., 20., 18., 19., 19., 19., 18., 18., 18., 19., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",536,536,0,50,"encoder/8/1/attention/6/value/Net","encoder/8/1/attention/6/value/Net","encoder/8/1/attention/6/value/Net","Linear","Linear","Linear",21.,24.400000000000002,73.,"{59., 32., 61., 34., 33., 33., 33., 32., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 73., 24., 32., 22., 21., 21., 22., 22., 33., 24., 24., 24., 23., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",537,537,0,50,"encoder/8/1/attention/6/attention/ScoringNet/1","encoder/8/1/attention/6/attention/ScoringNet/1","encoder/8/1/attention/6/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.400000000000002,45.,"{45., 34., 21., 20., 20., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 20., 19., 19., 19., 19., 20., 19., 19., 20., 19., 20., 19., 20., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",538,538,0,50,"encoder/8/1/attention/7/key/Net","encoder/8/1/attention/7/key/Net","encoder/8/1/attention/7/key/Net","Linear","Linear","Linear",21.,23.8,59.,"{59., 32., 30., 23., 22., 22., 21., 21., 21., 21., 21., 21., 22., 21., 22., 21., 35., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 25., 24., 23., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",539,539,0,50,"encoder/8/1/attention/7/query/Net","encoder/8/1/attention/7/query/Net","encoder/8/1/attention/7/query/Net","Linear","Linear","Linear",21.,24.1,57.,"{57., 31., 35., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 31., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 23., 24., 24., 24., 37., 22., 32., 29., 29., 50., 25., 22., 21., 21., 34., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",540,540,0,50,"encoder/8/1/attention/7/elem","encoder/8/1/attention/7/elem","encoder/8/1/attention/7/elem","Elementwise","Elementwise","Elementwise",17.,18.,41.,"{41., 21., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",541,541,0,50,"encoder/8/1/attention/7/value/Net","encoder/8/1/attention/7/value/Net","encoder/8/1/attention/7/value/Net","Linear","Linear","Linear",21.,24.,58.,"{58., 32., 23., 22., 22., 21., 21., 21., 34., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 23., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 32., 32., 32., 24., 32.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",542,542,0,50,"encoder/8/1/attention/7/attention/ScoringNet/1","encoder/8/1/attention/7/attention/ScoringNet/1","encoder/8/1/attention/7/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3667,46.,"{45., 22., 20., 19., 20., 20., 19., 19., 20., 19., 20., 19., 20., 19., 20., 20., 19., 20., 19., 19., 20., 19., 19., 20., 46., 21., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",543,543,0,50,"encoder/8/1/attention/8/key/Net","encoder/8/1/attention/8/key/Net","encoder/8/1/attention/8/key/Net","Linear","Linear","Linear",22.,25.,60.,"{60., 31., 29., 28., 29., 23., 22., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 49., 35., 32., 32., 33., 32., 32., 32., 32., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",544,544,0,50,"encoder/8/1/attention/8/query/Net","encoder/8/1/attention/8/query/Net","encoder/8/1/attention/8/query/Net","Linear","Linear","Linear",21.,23.666700000000002,97.,"{60., 32., 29., 29., 30., 29., 29., 22., 22., 22., 22., 21., 21., 21., 21., 22., 21., 21., 33., 25., 24., 24., 24., 24., 25., 24., 25., 24., 24., 25., 24., 24., 24., 25., 25., 24., 24., 24., 24., 25., 23., 33., 22., 21., 22., 21., 22., 21., 22., 97.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",545,545,0,50,"encoder/8/1/attention/8/elem","encoder/8/1/attention/8/elem","encoder/8/1/attention/8/elem","Elementwise","Elementwise","Elementwise",18.,18.,40.,"{40., 21., 19., 19., 18., 18., 18., 18., 18., 18., 19., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",546,546,0,50,"encoder/8/1/attention/8/value/Net","encoder/8/1/attention/8/value/Net","encoder/8/1/attention/8/value/Net","Linear","Linear","Linear",21.,24.0333,60.,"{48., 31., 29., 23., 29., 23., 21., 23., 33., 24., 31., 25., 24., 24., 24., 24., 24., 24., 60., 34., 26., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",547,547,0,50,"encoder/8/1/attention/8/attention/ScoringNet/1","encoder/8/1/attention/8/attention/ScoringNet/1","encoder/8/1/attention/8/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3333,47.,"{47., 23., 21., 20., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19., 20., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",548,548,0,50,"encoder/8/1/attention/9/key/Net","encoder/8/1/attention/9/key/Net","encoder/8/1/attention/9/key/Net","Linear","Linear","Linear",23.,24.,59.,"{59., 31., 46., 27., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 23., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",549,549,0,50,"encoder/8/1/attention/9/query/Net","encoder/8/1/attention/9/query/Net","encoder/8/1/attention/9/query/Net","Linear","Linear","Linear",23.,24.200000000000003,70.,"{58., 32., 30., 29., 29., 70., 28., 25., 24., 25., 24., 24., 24., 24., 25., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 23., 25., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",550,550,0,50,"encoder/8/1/attention/9/elem","encoder/8/1/attention/9/elem","encoder/8/1/attention/9/elem","Elementwise","Elementwise","Elementwise",17.,18.133300000000002,40.,"{40., 20., 19., 19., 18., 19., 18., 18., 18., 18., 18., 19., 18., 18., 19., 19., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 19., 18., 19., 17., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",551,551,0,50,"encoder/8/1/attention/9/value/Net","encoder/8/1/attention/9/value/Net","encoder/8/1/attention/9/value/Net","Linear","Linear","Linear",21.,24.2667,58.,"{58., 33., 43., 26., 25., 24., 25., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 41., 23., 22., 21., 21., 34., 24., 25., 24., 24., 25., 24., 24., 24., 25., 25., 24., 25., 25., 24., 24., 24., 25., 24., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",552,552,0,50,"encoder/8/1/attention/9/attention/ScoringNet/1","encoder/8/1/attention/9/attention/ScoringNet/1","encoder/8/1/attention/9/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3667,45.,"{45., 22., 20., 20., 20., 19., 20., 19., 19., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 20., 20., 45., 20., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 20., 19., 19., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",553,553,0,50,"encoder/8/1/attention/10/key/Net","encoder/8/1/attention/10/key/Net","encoder/8/1/attention/10/key/Net","Linear","Linear","Linear",21.,23.666700000000002,60.,"{59., 31., 29., 23., 21., 21., 21., 21., 21., 21., 22., 21., 21., 21., 22., 21., 21., 33., 23., 25., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 60., 33., 33., 26.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",554,554,0,50,"encoder/8/1/attention/10/query/Net","encoder/8/1/attention/10/query/Net","encoder/8/1/attention/10/query/Net","Linear","Linear","Linear",22.,24.166700000000002,59.,"{58., 31., 29., 29., 22., 33., 24., 24., 25., 24., 24., 24., 24., 24., 26., 59., 34., 32., 26., 24., 25., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 27., 24., 24., 24., 23., 24., 24., 23., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",555,555,0,50,"encoder/8/1/attention/10/elem","encoder/8/1/attention/10/elem","encoder/8/1/attention/10/elem","Elementwise","Elementwise","Elementwise",17.,18.,41.,"{41., 22., 19., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 19., 19., 19., 18., 18., 18., 18., 17.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",556,556,0,50,"encoder/8/1/attention/10/value/Net","encoder/8/1/attention/10/value/Net","encoder/8/1/attention/10/value/Net","Linear","Linear","Linear",24.,24.8667,60.,"{59., 32., 29., 30., 29., 29., 29., 28., 33., 25., 25., 32., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 60., 34., 32., 32., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",557,557,0,50,"encoder/8/1/attention/10/attention/ScoringNet/1","encoder/8/1/attention/10/attention/ScoringNet/1","encoder/8/1/attention/10/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.400000000000002,45.,"{45., 23., 21., 19., 19., 19., 20., 20., 19., 20., 19., 20., 20., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 20., 19., 20., 20., 19., 20., 19., 19., 19., 19., 19., 19., 20., 20., 19., 20., 19., 20., 19., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",558,558,0,50,"encoder/8/1/attention/11/key/Net","encoder/8/1/attention/11/key/Net","encoder/8/1/attention/11/key/Net","Linear","Linear","Linear",21.,23.666700000000002,49.,"{49., 31., 31., 22., 22., 22., 21., 21., 21., 33., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 25., 24., 24., 24., 24., 26., 23., 32., 21., 21., 22., 21., 21., 21., 22., 22., 21., 21., 33., 24., 25., 24., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",559,559,0,50,"encoder/8/1/attention/11/query/Net","encoder/8/1/attention/11/query/Net","encoder/8/1/attention/11/query/Net","Linear","Linear","Linear",24.,25.0333,58.,"{58., 32., 29., 29., 29., 36., 24., 24., 24., 25., 24., 24., 25., 24., 25., 24., 24., 32., 32., 25., 34., 57., 26., 26., 24., 25., 24., 24., 24., 24., 25., 24., 24., 25., 24., 24., 25., 24., 53., 36., 26., 24., 24., 24., 25., 24., 24., 24., 25., 35.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",560,560,0,50,"encoder/8/1/attention/11/elem","encoder/8/1/attention/11/elem","encoder/8/1/attention/11/elem","Elementwise","Elementwise","Elementwise",18.,18.3667,41.,"{41., 22., 19., 18., 19., 18., 19., 18., 18., 18., 19., 18., 18., 18., 19., 18., 18., 19., 18., 18., 18., 18., 19., 18., 19., 18., 19., 18., 19., 19., 18., 19., 18., 19., 19., 18., 19., 18., 18., 19., 18., 19., 18., 19., 18., 18., 19., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",561,561,0,50,"encoder/8/1/attention/11/value/Net","encoder/8/1/attention/11/value/Net","encoder/8/1/attention/11/value/Net","Linear","Linear","Linear",21.,24.0333,59.,"{59., 31., 24., 22., 22., 22., 21., 21., 23., 29., 29., 29., 29., 29., 29., 29., 22., 29., 22., 29., 22., 21., 21., 22., 21., 22., 21., 34., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 23., 25., 24., 23., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",562,562,0,50,"encoder/8/1/attention/11/attention/ScoringNet/1","encoder/8/1/attention/11/attention/ScoringNet/1","encoder/8/1/attention/11/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.9667,46.,"{46., 34., 20., 20., 19., 19., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 19., 20., 20., 20., 20., 20., 20., 19., 20., 20., 20., 19., 20., 19., 20., 20., 19., 20., 20., 43., 22., 20., 20., 19., 20., 19., 20., 20., 20., 20., 19., 19., 20., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",563,563,0,50,"encoder/8/1/attention/12/key/Net","encoder/8/1/attention/12/key/Net","encoder/8/1/attention/12/key/Net","Linear","Linear","Linear",21.,23.2667,48.,"{48., 32., 24., 22., 21., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 22., 21., 21., 21., 22., 32., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",564,564,0,50,"encoder/8/1/attention/12/query/Net","encoder/8/1/attention/12/query/Net","encoder/8/1/attention/12/query/Net","Linear","Linear","Linear",23.,24.400000000000002,68.,"{59., 32., 44., 36., 24., 25., 33., 26., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 32., 32., 68., 34., 25., 25., 32., 25., 24., 23., 25., 24., 25., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",565,565,0,50,"encoder/8/1/attention/12/elem","encoder/8/1/attention/12/elem","encoder/8/1/attention/12/elem","Elementwise","Elementwise","Elementwise",18.,18.,40.,"{40., 21., 19., 19., 18., 19., 19., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",566,566,0,50,"encoder/8/1/attention/12/value/Net","encoder/8/1/attention/12/value/Net","encoder/8/1/attention/12/value/Net","Linear","Linear","Linear",23.,24.3,68.,"{57., 32., 30., 68., 28., 25., 24., 25., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 47., 35., 33., 32., 33., 32., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",567,567,0,50,"encoder/8/1/attention/12/attention/ScoringNet/1","encoder/8/1/attention/12/attention/ScoringNet/1","encoder/8/1/attention/12/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.0667,44.,"{44., 34., 20., 19., 20., 19., 19., 19., 20., 20., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 20., 20., 19., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",568,568,0,50,"encoder/8/1/attention/13","encoder/8/1/attention/13","encoder/8/1/attention/13","Catenate","Catenate","Catenate",55.,56.,79.,"{79., 59., 58., 56., 56., 56., 56., 55., 56., 57., 56., 56., 56., 56., 56., 56., 56., 56., 57., 56., 56., 56., 56., 79., 58., 56., 56., 56., 57., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 56., 57., 56., 56., 57., 56., 56.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",569,569,0,50,"encoder/8/1/attention/14/Net","encoder/8/1/attention/14/Net","encoder/8/1/attention/14/Net","Linear","Linear","Linear",136.,137.70000000000002,241.,"{241., 190., 145., 139., 139., 138., 137., 138., 139., 137., 137., 137., 142., 138., 138., 138., 137., 137., 138., 138., 138., 137., 137., 137., 137., 137., 138., 138., 138., 137., 138., 137., 138., 137., 137., 137., 137., 136., 138., 164., 139., 138., 138., 138., 137., 138., 137., 140., 155., 138.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",570,570,0,50,"encoder/8/1/dropout","encoder/8/1/dropout","encoder/8/1/dropout","Dropout","Dropout","Dropout",18.,18.,38.,"{38., 21., 19., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 19., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",571,572,1,50,"encoder/8/1/add","encoder/8/1/norm","encoder/8/1/add-encoder/8/1/norm","Threading","Normalization","Threading-Normalization",161.,162.26670000000001,213.,"{213., 166., 163., 162., 162., 163., 162., 170., 164., 162., 162., 162., 162., 162., 163., 162., 162., 162., 186., 165., 163., 163., 162., 162., 162., 161., 162., 163., 162., 162., 163., 162., 163., 162., 162., 163., 162., 162., 162., 162., 162., 163., 187., 164., 162., 161., 162., 161., 161., 162.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",573,573,0,50,"encoder/8/2/linear1/Net","encoder/8/2/linear1/Net","encoder/8/2/linear1/Net","Linear","Linear","Linear",439.,444.16670000000005,765.,"{765., 710., 522., 470., 448., 492., 470., 443., 441., 443., 441., 448., 442., 442., 441., 442., 440., 440., 440., 440., 439., 442., 442., 467., 442., 442., 440., 480., 442., 441., 442., 460., 487., 443., 442., 442., 442., 459., 441., 441., 441., 478., 441., 441., 441., 441., 441., 441., 441., 492.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",574,574,0,50,"encoder/8/2/gelu","encoder/8/2/gelu","encoder/8/2/gelu","Elementwise","Elementwise","Elementwise",105.,105.4,136.,"{136., 109., 107., 106., 106., 106., 105., 105., 105., 105., 105., 106., 105., 106., 105., 106., 131., 107., 105., 105., 106., 106., 105., 106., 106., 105., 105., 105., 106., 105., 105., 105., 128., 111., 106., 105., 105., 105., 105., 106., 105., 105., 106., 105., 105., 105., 106., 105., 105., 105.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",575,575,0,50,"encoder/8/2/linear2/Net","encoder/8/2/linear2/Net","encoder/8/2/linear2/Net","Linear","Linear","Linear",434.,437.40000000000003,506.,"{506., 482., 450., 440., 439., 484., 439., 436., 435., 435., 446., 436., 436., 437., 462., 436., 436., 434., 435., 435., 435., 436., 435., 461., 449., 437., 436., 451., 437., 437., 436., 436., 469., 437., 436., 437., 436., 437., 435., 436., 435., 461., 436., 435., 436., 437., 437., 436., 436., 472.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",576,576,0,50,"encoder/8/2/dropout","encoder/8/2/dropout","encoder/8/2/dropout","Dropout","Dropout","Dropout",18.,18.2667,39.,"{39., 21., 19., 19., 19., 19., 19., 18., 18., 19., 19., 18., 18., 18., 19., 19., 19., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 19., 18., 18., 19., 18., 18., 18., 18., 18., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",577,578,1,50,"encoder/8/2/add","encoder/8/2/norm","encoder/8/2/add-encoder/8/2/norm","Threading","Normalization","Threading-Normalization",161.,162.26670000000001,218.,"{218., 166., 163., 162., 161., 163., 163., 162., 162., 163., 162., 162., 162., 163., 162., 163., 162., 161., 161., 162., 187., 164., 161., 163., 162., 162., 162., 162., 162., 162., 162., 163., 162., 161., 162., 161., 161., 161., 162., 161., 162., 161., 162., 178., 195., 168., 164., 162., 163., 163.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",579,579,0,50,"encoder/9/1/attention/1/key/Net","encoder/9/1/attention/1/key/Net","encoder/9/1/attention/1/key/Net","Linear","Linear","Linear",21.,24.3,69.,"{69., 32., 44., 26., 25., 24., 24., 25., 25., 24., 24., 26., 24., 25., 25., 25., 25., 24., 24., 32., 34., 25., 32., 22., 21., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 26., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",580,580,0,50,"encoder/9/1/attention/1/query/Net","encoder/9/1/attention/1/query/Net","encoder/9/1/attention/1/query/Net","Linear","Linear","Linear",21.,23.3,61.,"{61., 31., 29., 29., 29., 29., 23., 28., 28., 22., 21., 21., 21., 21., 33., 23., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 23., 35., 33., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",581,581,0,50,"encoder/9/1/attention/1/elem","encoder/9/1/attention/1/elem","encoder/9/1/attention/1/elem","Elementwise","Elementwise","Elementwise",17.,18.0333,44.,"{44., 21., 21., 22., 19., 19., 34., 20., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",582,582,0,50,"encoder/9/1/attention/1/value/Net","encoder/9/1/attention/1/value/Net","encoder/9/1/attention/1/value/Net","Linear","Linear","Linear",22.,24.3,61.,"{61., 33., 29., 29., 29., 29., 22., 22., 33., 35., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 32., 33., 33.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",583,583,0,50,"encoder/9/1/attention/1/attention/ScoringNet/1","encoder/9/1/attention/1/attention/ScoringNet/1","encoder/9/1/attention/1/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.433300000000003,53.,"{47., 23., 20., 19., 20., 20., 19., 19., 19., 20., 19., 19., 20., 20., 19., 20., 19., 19., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 53., 20., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 41., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",584,584,0,50,"encoder/9/1/attention/2/key/Net","encoder/9/1/attention/2/key/Net","encoder/9/1/attention/2/key/Net","Linear","Linear","Linear",21.,23.633300000000002,60.,"{60., 32., 24., 22., 24., 22., 22., 21., 22., 22., 21., 22., 21., 21., 21., 21., 21., 21., 22., 33., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 23., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",585,585,0,50,"encoder/9/1/attention/2/query/Net","encoder/9/1/attention/2/query/Net","encoder/9/1/attention/2/query/Net","Linear","Linear","Linear",21.,24.5,59.,"{59., 32., 31., 29., 29., 29., 29., 23., 29., 55., 30., 23., 22., 22., 21., 21., 34., 24., 25., 25., 24., 24., 24., 24., 24., 24., 25., 25., 24., 25., 24., 24., 24., 24., 25., 25., 25., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",586,586,0,50,"encoder/9/1/attention/2/elem","encoder/9/1/attention/2/elem","encoder/9/1/attention/2/elem","Elementwise","Elementwise","Elementwise",18.,18.0667,50.,"{40., 22., 18., 18., 18., 18., 18., 18., 19., 18., 18., 19., 18., 18., 18., 18., 19., 18., 18., 18., 21., 23., 18., 18., 18., 50., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",587,587,0,50,"encoder/9/1/attention/2/value/Net","encoder/9/1/attention/2/value/Net","encoder/9/1/attention/2/value/Net","Linear","Linear","Linear",23.,24.2333,50.,"{48., 33., 36., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 23., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 50., 35., 34., 33., 32., 26., 25., 25., 25., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",588,588,0,50,"encoder/9/1/attention/2/attention/ScoringNet/1","encoder/9/1/attention/2/attention/ScoringNet/1","encoder/9/1/attention/2/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.6,49.,"{49., 22., 21., 20., 19., 19., 20., 19., 20., 19., 20., 20., 19., 20., 19., 20., 20., 20., 19., 20., 19., 20., 19., 20., 19., 19., 20., 20., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",589,589,0,50,"encoder/9/1/attention/3/key/Net","encoder/9/1/attention/3/key/Net","encoder/9/1/attention/3/key/Net","Linear","Linear","Linear",21.,24.2333,82.,"{82., 36., 30., 29., 24., 22., 22., 21., 22., 34., 24., 25., 25., 24., 24., 25., 25., 24., 24., 24., 24., 25., 25., 25., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 25., 25., 25., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",590,590,0,50,"encoder/9/1/attention/3/query/Net","encoder/9/1/attention/3/query/Net","encoder/9/1/attention/3/query/Net","Linear","Linear","Linear",21.,24.0333,58.,"{58., 32., 44., 25., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 23., 24., 24., 23., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 32., 21., 21., 21., 30., 28., 29., 28., 28., 28., 22., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",591,591,0,50,"encoder/9/1/attention/3/elem","encoder/9/1/attention/3/elem","encoder/9/1/attention/3/elem","Elementwise","Elementwise","Elementwise",18.,18.3,50.,"{41., 21., 19., 18., 18., 19., 18., 19., 18., 18., 18., 18., 43., 19., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 19., 19., 19., 19., 19., 33., 19., 19., 18., 18., 18., 50., 19., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",592,592,0,50,"encoder/9/1/attention/3/value/Net","encoder/9/1/attention/3/value/Net","encoder/9/1/attention/3/value/Net","Linear","Linear","Linear",21.,24.2667,59.,"{59., 31., 30., 30., 22., 22., 28., 29., 22., 21., 22., 21., 22., 22., 21., 21., 34., 24., 24., 24., 24., 24., 32., 33., 25., 24., 24., 25., 24., 24., 24., 25., 32., 25., 32., 25., 24., 24., 24., 24., 24., 24., 37., 22., 33., 21., 21., 21., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",593,593,0,50,"encoder/9/1/attention/3/attention/ScoringNet/1","encoder/9/1/attention/3/attention/ScoringNet/1","encoder/9/1/attention/3/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2,54.,"{44., 34., 20., 19., 19., 20., 19., 20., 19., 20., 19., 19., 45., 21., 19., 19., 19., 19., 54., 21., 19., 19., 19., 20., 20., 19., 19., 20., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",594,594,0,50,"encoder/9/1/attention/4/key/Net","encoder/9/1/attention/4/key/Net","encoder/9/1/attention/4/key/Net","Linear","Linear","Linear",21.,26.5,60.,"{60., 32., 29., 29., 22., 22., 22., 21., 28., 28., 28., 22., 22., 28., 22., 28., 28., 28., 22., 21., 21., 21., 33., 24., 24., 23., 32., 25., 24., 25., 24., 24., 24., 24., 24., 24., 32., 33., 26., 31., 32., 32., 36., 33., 21., 28., 29., 31., 31., 33.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",595,595,0,50,"encoder/9/1/attention/4/query/Net","encoder/9/1/attention/4/query/Net","encoder/9/1/attention/4/query/Net","Linear","Linear","Linear",21.,23.0667,57.,"{47., 32., 24., 22., 22., 22., 22., 22., 22., 22., 21., 21., 21., 22., 32., 29., 29., 30., 23., 21., 21., 23., 22., 22., 21., 21., 21., 22., 21., 21., 22., 21., 21., 33., 24., 25., 24., 57., 34., 25., 25., 25., 24., 24., 24., 24., 24., 24., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",596,596,0,50,"encoder/9/1/attention/4/elem","encoder/9/1/attention/4/elem","encoder/9/1/attention/4/elem","Elementwise","Elementwise","Elementwise",18.,18.0667,52.,"{40., 21., 19., 18., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 19., 18., 18., 18., 18., 18., 18., 21., 21., 19., 19., 18., 18., 18., 18., 52.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",597,597,0,50,"encoder/9/1/attention/4/value/Net","encoder/9/1/attention/4/value/Net","encoder/9/1/attention/4/value/Net","Linear","Linear","Linear",21.,23.2667,59.,"{48., 32., 30., 23., 22., 21., 21., 22., 21., 21., 22., 21., 22., 22., 21., 21., 21., 22., 22., 21., 22., 21., 21., 21., 32., 24., 24., 24., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 59., 34., 33., 25., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",598,598,0,50,"encoder/9/1/attention/4/attention/ScoringNet/1","encoder/9/1/attention/4/attention/ScoringNet/1","encoder/9/1/attention/4/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.666700000000002,45.,"{45., 35., 20., 20., 19., 19., 20., 20., 20., 19., 19., 20., 19., 20., 20., 19., 20., 44., 21., 19., 19., 19., 20., 19., 22., 32., 21., 19., 20., 20., 20., 19., 20., 19., 20., 20., 19., 20., 20., 19., 20., 19., 20., 20., 19., 19., 20., 19., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",599,599,0,50,"encoder/9/1/attention/5/key/Net","encoder/9/1/attention/5/key/Net","encoder/9/1/attention/5/key/Net","Linear","Linear","Linear",21.,24.2333,60.,"{60., 32., 54., 31., 23., 22., 21., 22., 22., 21., 21., 21., 21., 22., 34., 24., 25., 24., 24., 24., 25., 25., 24., 24., 25., 24., 25., 24., 24., 25., 24., 24., 25., 24., 25., 24., 24., 25., 24., 24., 24., 25., 24., 24., 25., 24., 24., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",600,600,0,50,"encoder/9/1/attention/5/query/Net","encoder/9/1/attention/5/query/Net","encoder/9/1/attention/5/query/Net","Linear","Linear","Linear",21.,24.,46.,"{46., 32., 24., 22., 22., 21., 21., 22., 21., 21., 21., 33., 24., 24., 24., 24., 24., 24., 23., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",601,601,0,50,"encoder/9/1/attention/5/elem","encoder/9/1/attention/5/elem","encoder/9/1/attention/5/elem","Elementwise","Elementwise","Elementwise",17.,18.,42.,"{40., 21., 19., 19., 19., 18., 18., 19., 18., 18., 18., 18., 19., 42., 20., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",602,602,0,50,"encoder/9/1/attention/5/value/Net","encoder/9/1/attention/5/value/Net","encoder/9/1/attention/5/value/Net","Linear","Linear","Linear",21.,23.633300000000002,47.,"{47., 32., 24., 21., 21., 22., 21., 21., 22., 21., 22., 21., 21., 22., 21., 22., 21., 21., 34., 24., 24., 24., 24., 24., 23., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 33., 32., 24., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",603,603,0,50,"encoder/9/1/attention/5/attention/ScoringNet/1","encoder/9/1/attention/5/attention/ScoringNet/1","encoder/9/1/attention/5/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.7667,46.,"{46., 23., 21., 21., 19., 20., 20., 20., 20., 19., 20., 19., 20., 20., 20., 19., 19., 20., 19., 19., 20., 20., 19., 20., 20., 20., 19., 19., 20., 19., 19., 20., 20., 44., 21., 20., 20., 20., 19., 20., 20., 19., 46., 22., 20., 19., 20., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",604,604,0,50,"encoder/9/1/attention/6/key/Net","encoder/9/1/attention/6/key/Net","encoder/9/1/attention/6/key/Net","Linear","Linear","Linear",23.,25.8667,58.,"{58., 31., 30., 29., 29., 23., 34., 25., 24., 32., 26., 24., 24., 25., 31., 32., 26., 24., 32., 26., 24., 26., 24., 25., 25., 24., 24., 24., 32., 25., 32., 26., 24., 24., 31., 32., 25., 25., 24., 24., 24., 24., 32., 25., 24., 23., 25., 24., 24., 32.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",605,605,0,50,"encoder/9/1/attention/6/query/Net","encoder/9/1/attention/6/query/Net","encoder/9/1/attention/6/query/Net","Linear","Linear","Linear",23.,24.,58.,"{58., 31., 36., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 35., 27., 24., 24., 24., 24., 24., 24., 25., 23., 24., 24., 25., 24., 25., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",606,606,0,50,"encoder/9/1/attention/6/elem","encoder/9/1/attention/6/elem","encoder/9/1/attention/6/elem","Elementwise","Elementwise","Elementwise",17.,18.0333,39.,"{39., 21., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 19., 18., 18., 18., 18., 18., 18., 18., 19., 19., 19., 18., 18., 18., 18., 18., 18., 19., 19., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",607,607,0,50,"encoder/9/1/attention/6/value/Net","encoder/9/1/attention/6/value/Net","encoder/9/1/attention/6/value/Net","Linear","Linear","Linear",21.,24.6,47.,"{47., 32., 23., 28., 28., 22., 22., 21., 28., 29., 28., 22., 22., 21., 22., 21., 21., 21., 21., 33., 24., 24., 32., 24., 25., 32., 33., 32., 25., 24., 24., 24., 24., 32., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 35., 26., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",608,608,0,50,"encoder/9/1/attention/6/attention/ScoringNet/1","encoder/9/1/attention/6/attention/ScoringNet/1","encoder/9/1/attention/6/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.166700000000002,44.,"{44., 34., 20., 19., 19., 20., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 26., 20., 19., 19., 19., 19., 19., 20., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",609,609,0,50,"encoder/9/1/attention/7/key/Net","encoder/9/1/attention/7/key/Net","encoder/9/1/attention/7/key/Net","Linear","Linear","Linear",21.,24.2333,58.,"{58., 31., 29., 30., 29., 22., 23., 21., 22., 54., 35., 25., 24., 24., 25., 25., 24., 25., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 25., 25., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",610,610,0,50,"encoder/9/1/attention/7/query/Net","encoder/9/1/attention/7/query/Net","encoder/9/1/attention/7/query/Net","Linear","Linear","Linear",23.,24.,58.,"{58., 32., 43., 32., 32., 27., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 23., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 25., 23., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",611,611,0,50,"encoder/9/1/attention/7/elem","encoder/9/1/attention/7/elem","encoder/9/1/attention/7/elem","Elementwise","Elementwise","Elementwise",17.,18.,43.,"{39., 21., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 43., 18., 18., 18., 17., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 19., 17., 18., 18., 18., 19., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",612,612,0,50,"encoder/9/1/attention/7/value/Net","encoder/9/1/attention/7/value/Net","encoder/9/1/attention/7/value/Net","Linear","Linear","Linear",21.,27.3,58.,"{58., 32., 29., 29., 42., 32., 32., 33., 32., 32., 32., 32., 33., 32., 32., 32., 31., 33., 32., 32., 33., 23., 21., 33., 24., 24., 24., 24., 24., 24., 24., 33., 26., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",613,613,0,50,"encoder/9/1/attention/7/attention/ScoringNet/1","encoder/9/1/attention/7/attention/ScoringNet/1","encoder/9/1/attention/7/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2667,44.,"{44., 23., 20., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 20., 20., 19., 43., 21., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",614,614,0,50,"encoder/9/1/attention/8/key/Net","encoder/9/1/attention/8/key/Net","encoder/9/1/attention/8/key/Net","Linear","Linear","Linear",21.,23.633300000000002,59.,"{59., 32., 24., 22., 22., 22., 21., 34., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 25., 23., 25., 25., 24., 24., 24., 24., 24., 24., 24., 26., 23., 32., 22., 23., 21., 22., 22., 21., 22., 21., 21., 22., 21., 21., 33., 25., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",615,615,0,50,"encoder/9/1/attention/8/query/Net","encoder/9/1/attention/8/query/Net","encoder/9/1/attention/8/query/Net","Linear","Linear","Linear",21.,24.1,58.,"{58., 26., 24., 22., 21., 21., 22., 21., 21., 22., 21., 34., 24., 24., 24., 24., 25., 24., 24., 25., 25., 48., 35., 26., 25., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",616,616,0,50,"encoder/9/1/attention/8/elem","encoder/9/1/attention/8/elem","encoder/9/1/attention/8/elem","Elementwise","Elementwise","Elementwise",17.,18.,39.,"{39., 21., 19., 18., 18., 18., 18., 18., 18., 18., 19., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",617,617,0,50,"encoder/9/1/attention/8/value/Net","encoder/9/1/attention/8/value/Net","encoder/9/1/attention/8/value/Net","Linear","Linear","Linear",22.,28.,58.,"{58., 32., 24., 28., 29., 24., 29., 29., 29., 23., 22., 22., 33., 24., 25., 24., 24., 24., 24., 24., 32., 25., 33., 32., 32., 33., 32., 32., 32., 33., 25., 24., 32., 34., 33., 26., 32., 32., 32., 25., 25., 24., 24., 24., 24., 24., 57., 36., 33., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",618,618,0,50,"encoder/9/1/attention/8/attention/ScoringNet/1","encoder/9/1/attention/8/attention/ScoringNet/1","encoder/9/1/attention/8/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.1,44.,"{44., 34., 20., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 21., 29., 20., 20., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",619,619,0,50,"encoder/9/1/attention/9/key/Net","encoder/9/1/attention/9/key/Net","encoder/9/1/attention/9/key/Net","Linear","Linear","Linear",21.,23.633300000000002,47.,"{47., 31., 24., 21., 22., 21., 22., 31., 29., 23., 21., 22., 21., 22., 21., 22., 21., 21., 22., 21., 32., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",620,620,0,50,"encoder/9/1/attention/9/query/Net","encoder/9/1/attention/9/query/Net","encoder/9/1/attention/9/query/Net","Linear","Linear","Linear",21.,24.,58.,"{58., 32., 28., 22., 21., 33., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 32., 33., 24., 24., 24., 25., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",621,621,0,50,"encoder/9/1/attention/9/elem","encoder/9/1/attention/9/elem","encoder/9/1/attention/9/elem","Elementwise","Elementwise","Elementwise",17.,18.0667,39.,"{39., 21., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 39., 20., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 19., 18., 18., 17., 19., 18., 18., 18., 18., 19., 18., 19., 19., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",622,622,0,50,"encoder/9/1/attention/9/value/Net","encoder/9/1/attention/9/value/Net","encoder/9/1/attention/9/value/Net","Linear","Linear","Linear",21.,24.0333,59.,"{59., 32., 30., 29., 28., 22., 21., 22., 33., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 26., 35., 32., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",623,623,0,50,"encoder/9/1/attention/9/attention/ScoringNet/1","encoder/9/1/attention/9/attention/ScoringNet/1","encoder/9/1/attention/9/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2333,45.,"{45., 23., 20., 20., 20., 19., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",624,624,0,50,"encoder/9/1/attention/10/key/Net","encoder/9/1/attention/10/key/Net","encoder/9/1/attention/10/key/Net","Linear","Linear","Linear",21.,24.133300000000002,59.,"{59., 32., 26., 32., 33., 27., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 22., 32., 21., 21., 21., 22., 21., 21., 21., 22., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",625,625,0,50,"encoder/9/1/attention/10/query/Net","encoder/9/1/attention/10/query/Net","encoder/9/1/attention/10/query/Net","Linear","Linear","Linear",21.,23.9667,60.,"{58., 32., 31., 29., 23., 22., 21., 22., 22., 21., 22., 21., 22., 21., 22., 21., 22., 33., 23., 24., 25., 25., 25., 24., 60., 35., 26., 25., 24., 24., 24., 25., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",626,626,0,50,"encoder/9/1/attention/10/elem","encoder/9/1/attention/10/elem","encoder/9/1/attention/10/elem","Elementwise","Elementwise","Elementwise",18.,18.,39.,"{39., 21., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",627,627,0,50,"encoder/9/1/attention/10/value/Net","encoder/9/1/attention/10/value/Net","encoder/9/1/attention/10/value/Net","Linear","Linear","Linear",24.,24.8,59.,"{59., 32., 30., 29., 28., 42., 33., 33., 32., 32., 33., 33., 27., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 25., 25., 25., 25., 24., 25., 25., 25., 25., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",628,628,0,50,"encoder/9/1/attention/10/attention/ScoringNet/1","encoder/9/1/attention/10/attention/ScoringNet/1","encoder/9/1/attention/10/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.5667,45.,"{45., 23., 20., 20., 20., 20., 20., 20., 19., 20., 20., 19., 20., 19., 20., 19., 19., 19., 20., 19., 20., 20., 19., 19., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 20., 19., 20., 19., 20., 19., 19., 20., 20., 19., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",629,629,0,50,"encoder/9/1/attention/11/key/Net","encoder/9/1/attention/11/key/Net","encoder/9/1/attention/11/key/Net","Linear","Linear","Linear",21.,26.8667,53.,"{47., 32., 29., 29., 24., 22., 21., 21., 21., 22., 53., 31., 29., 28., 29., 30., 29., 29., 29., 29., 32., 32., 32., 32., 33., 32., 33., 26., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 49., 32., 34., 26., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",630,630,0,50,"encoder/9/1/attention/11/query/Net","encoder/9/1/attention/11/query/Net","encoder/9/1/attention/11/query/Net","Linear","Linear","Linear",21.,24.0333,47.,"{47., 32., 29., 23., 21., 22., 21., 21., 22., 33., 25., 25., 24., 24., 24., 24., 24., 24., 32., 26., 24., 24., 24., 24., 26., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",631,631,0,50,"encoder/9/1/attention/11/elem","encoder/9/1/attention/11/elem","encoder/9/1/attention/11/elem","Elementwise","Elementwise","Elementwise",17.,18.,39.,"{39., 20., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 22., 19., 18., 19., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",632,632,0,50,"encoder/9/1/attention/11/value/Net","encoder/9/1/attention/11/value/Net","encoder/9/1/attention/11/value/Net","Linear","Linear","Linear",21.,24.2333,46.,"{46., 31., 29., 25., 24., 24., 24., 23., 24., 24., 24., 24., 23., 23., 24., 24., 24., 24., 24., 24., 24., 23., 25., 24., 35., 39., 30., 29., 28., 22., 21., 29., 23., 28., 22., 21., 22., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",633,633,0,50,"encoder/9/1/attention/11/attention/ScoringNet/1","encoder/9/1/attention/11/attention/ScoringNet/1","encoder/9/1/attention/11/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.5667,45.,"{45., 32., 20., 20., 19., 19., 20., 20., 19., 20., 19., 20., 20., 19., 19., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 20., 19., 20., 19., 19., 20., 20., 19., 20., 19., 20., 19., 27., 20., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",634,634,0,50,"encoder/9/1/attention/12/key/Net","encoder/9/1/attention/12/key/Net","encoder/9/1/attention/12/key/Net","Linear","Linear","Linear",23.,24.,48.,"{48., 31., 30., 30., 26., 24., 24., 24., 32., 32., 33., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 23., 24., 24., 24., 24., 23., 24., 24., 23., 23., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",635,635,0,50,"encoder/9/1/attention/12/query/Net","encoder/9/1/attention/12/query/Net","encoder/9/1/attention/12/query/Net","Linear","Linear","Linear",21.,24.7333,59.,"{58., 31., 29., 28., 36., 25., 31., 25., 32., 33., 32., 32., 25., 24., 31., 59., 27., 24., 24., 24., 24., 32., 26., 24., 24., 24., 24., 24., 24., 24., 24., 25., 35., 31., 21., 21., 21., 21., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",636,636,0,50,"encoder/9/1/attention/12/elem","encoder/9/1/attention/12/elem","encoder/9/1/attention/12/elem","Elementwise","Elementwise","Elementwise",18.,18.2667,39.,"{39., 21., 19., 18., 19., 19., 18., 18., 18., 19., 19., 19., 18., 18., 19., 18., 18., 19., 18., 18., 18., 18., 19., 19., 19., 18., 18., 18., 18., 18., 18., 19., 19., 18., 19., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",637,637,0,50,"encoder/9/1/attention/12/value/Net","encoder/9/1/attention/12/value/Net","encoder/9/1/attention/12/value/Net","Linear","Linear","Linear",21.,24.5,266.,"{47., 31., 23., 33., 26., 32., 32., 24., 25., 31., 24., 24., 24., 24., 23., 24., 24., 24., 24., 23., 23., 23., 24., 32., 25., 24., 24., 24., 24., 24., 24., 24., 32., 24., 24., 24., 25., 23., 24., 36., 21., 266., 39., 25., 24., 24., 24., 26., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",638,638,0,50,"encoder/9/1/attention/12/attention/ScoringNet/1","encoder/9/1/attention/12/attention/ScoringNet/1","encoder/9/1/attention/12/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.5,44.,"{44., 34., 20., 20., 20., 20., 20., 20., 20., 20., 20., 19., 19., 19., 20., 19., 19., 20., 20., 19., 20., 20., 20., 19., 20., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 20., 19., 20., 20., 19., 19., 20., 19., 19., 21., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",639,639,0,50,"encoder/9/1/attention/13","encoder/9/1/attention/13","encoder/9/1/attention/13","Catenate","Catenate","Catenate",55.,56.300000000000004,80.,"{79., 59., 57., 57., 56., 56., 56., 56., 56., 56., 56., 56., 57., 56., 56., 56., 56., 56., 56., 56., 56., 55., 55., 80., 57., 57., 64., 57., 56., 56., 56., 72., 59., 57., 56., 56., 57., 56., 57., 56., 58., 63., 57., 56., 56., 55., 56., 56., 57., 56.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",640,640,0,50,"encoder/9/1/attention/14/Net","encoder/9/1/attention/14/Net","encoder/9/1/attention/14/Net","Linear","Linear","Linear",137.,138.66670000000002,239.,"{239., 193., 142., 139., 139., 139., 138., 138., 138., 139., 138., 169., 140., 138., 138., 138., 139., 138., 137., 137., 138., 139., 138., 138., 139., 168., 141., 138., 147., 141., 138., 138., 163., 143., 138., 139., 138., 165., 140., 138., 138., 139., 138., 139., 139., 139., 138., 139., 138., 138.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",641,641,0,50,"encoder/9/1/dropout","encoder/9/1/dropout","encoder/9/1/dropout","Dropout","Dropout","Dropout",18.,18.,37.,"{37., 21., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",642,643,1,50,"encoder/9/1/add","encoder/9/1/norm","encoder/9/1/add-encoder/9/1/norm","Threading","Normalization","Threading-Normalization",161.,162.9,210.,"{210., 167., 163., 164., 163., 162., 162., 163., 162., 163., 162., 163., 162., 168., 163., 164., 186., 165., 163., 161., 163., 162., 163., 163., 162., 161., 163., 162., 163., 171., 164., 163., 178., 164., 162., 162., 179., 166., 163., 181., 166., 162., 161., 162., 163., 163., 161., 162., 161., 161.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",644,644,0,50,"encoder/9/2/linear1/Net","encoder/9/2/linear1/Net","encoder/9/2/linear1/Net","Linear","Linear","Linear",440.,448.,773.,"{773., 721., 525., 486., 470., 442., 442., 441., 441., 441., 441., 440., 456., 478., 443., 441., 441., 441., 453., 456., 444., 458., 471., 446., 444., 445., 445., 445., 445., 443., 446., 472., 447., 446., 446., 445., 446., 447., 448., 477., 459., 451., 444., 458., 447., 446., 446., 445., 471., 450.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",645,645,0,50,"encoder/9/2/gelu","encoder/9/2/gelu","encoder/9/2/gelu","Elementwise","Elementwise","Elementwise",105.,107.6667,167.,"{167., 116., 134., 108., 106., 106., 106., 106., 106., 106., 106., 106., 106., 106., 106., 127., 112., 109., 109., 109., 109., 109., 109., 109., 109., 109., 109., 109., 109., 109., 109., 109., 109., 109., 109., 109., 109., 109., 106., 106., 105., 105., 105., 105., 105., 106., 105., 106., 106., 105.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",646,646,0,50,"encoder/9/2/linear2/Net","encoder/9/2/linear2/Net","encoder/9/2/linear2/Net","Linear","Linear","Linear",431.,436.66670000000005,675.,"{675., 623., 484., 445., 437., 433., 432., 472., 435., 433., 434., 434., 445., 435., 451., 433., 480., 435., 433., 433., 433., 433., 432., 433., 434., 462., 435., 433., 433., 433., 519., 438., 434., 431., 475., 437., 442., 437., 449., 437., 437., 436., 461., 439., 435., 436., 436., 436., 435., 435.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",647,647,0,50,"encoder/9/2/dropout","encoder/9/2/dropout","encoder/9/2/dropout","Dropout","Dropout","Dropout",21.,21.,44.,"{44., 32., 24., 21., 21., 21., 21., 21., 21., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 29., 30., 22.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",648,649,1,50,"encoder/9/2/add","encoder/9/2/norm","encoder/9/2/add-encoder/9/2/norm","Threading","Normalization","Threading-Normalization",161.,164.9333,221.,"{221., 167., 182., 170., 167., 166., 166., 181., 170., 168., 166., 166., 166., 166., 167., 167., 165., 187., 165., 162., 163., 162., 161., 162., 163., 164., 163., 162., 162., 163., 162., 162., 163., 163., 162., 163., 162., 163., 163., 162., 163., 185., 168., 167., 166., 166., 167., 166., 166., 167.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",650,650,0,50,"encoder/10/1/attention/1/key/Net","encoder/10/1/attention/1/key/Net","encoder/10/1/attention/1/key/Net","Linear","Linear","Linear",22.,24.,71.,"{71., 32., 30., 29., 22., 22., 33., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 23., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",651,651,0,50,"encoder/10/1/attention/1/query/Net","encoder/10/1/attention/1/query/Net","encoder/10/1/attention/1/query/Net","Linear","Linear","Linear",21.,24.0333,62.,"{62., 32., 24., 22., 21., 21., 22., 21., 22., 28., 29., 22., 22., 22., 21., 28., 21., 21., 33., 23., 24., 24., 24., 24., 23., 24., 24., 23., 34., 33., 26., 48., 34., 33., 26., 25., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",652,652,0,50,"encoder/10/1/attention/1/elem","encoder/10/1/attention/1/elem","encoder/10/1/attention/1/elem","Elementwise","Elementwise","Elementwise",17.,18.,45.,"{45., 21., 19., 18., 18., 19., 19., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 29., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 17., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",653,653,0,50,"encoder/10/1/attention/1/value/Net","encoder/10/1/attention/1/value/Net","encoder/10/1/attention/1/value/Net","Linear","Linear","Linear",21.,23.400000000000002,61.,"{61., 31., 30., 22., 22., 21., 21., 22., 22., 21., 21., 21., 21., 21., 21., 21., 22., 21., 21., 21., 32., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 33., 33., 32., 25., 24., 23., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",654,654,0,50,"encoder/10/1/attention/1/attention/ScoringNet/1","encoder/10/1/attention/1/attention/ScoringNet/1","encoder/10/1/attention/1/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3333,52.,"{48., 23., 21., 52., 21., 19., 20., 20., 19., 20., 19., 20., 19., 19., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 20., 20., 19., 19., 19., 20., 19., 20., 19., 19., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",655,655,0,50,"encoder/10/1/attention/2/key/Net","encoder/10/1/attention/2/key/Net","encoder/10/1/attention/2/key/Net","Linear","Linear","Linear",24.,24.3333,61.,"{61., 32., 44., 33., 57., 34., 33., 25., 24., 25., 24., 25., 24., 25., 24., 24., 24., 24., 32., 32., 25., 25., 25., 24., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 26., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",656,656,0,50,"encoder/10/1/attention/2/query/Net","encoder/10/1/attention/2/query/Net","encoder/10/1/attention/2/query/Net","Linear","Linear","Linear",21.,23.0333,58.,"{58., 31., 29., 23., 22., 22., 21., 21., 21., 21., 22., 21., 21., 21., 32., 24., 24., 24., 24., 24., 24., 24., 23., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 26., 36., 31., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 33., 32.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",657,657,0,50,"encoder/10/1/attention/2/elem","encoder/10/1/attention/2/elem","encoder/10/1/attention/2/elem","Elementwise","Elementwise","Elementwise",17.,18.1,41.,"{41., 22., 21., 18., 19., 18., 18., 18., 18., 18., 26., 19., 18., 18., 18., 18., 19., 19., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 17., 19., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",658,658,0,50,"encoder/10/1/attention/2/value/Net","encoder/10/1/attention/2/value/Net","encoder/10/1/attention/2/value/Net","Linear","Linear","Linear",21.,24.200000000000003,59.,"{59., 33., 43., 34., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 32., 32., 25., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 25., 24., 47., 21., 22., 21., 21., 22., 21., 21., 22., 32., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",659,659,0,50,"encoder/10/1/attention/2/attention/ScoringNet/1","encoder/10/1/attention/2/attention/ScoringNet/1","encoder/10/1/attention/2/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.400000000000002,49.,"{46., 23., 20., 20., 20., 20., 19., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 19., 19., 20., 19., 20., 19., 32., 20., 19., 49., 21., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",660,660,0,50,"encoder/10/1/attention/3/key/Net","encoder/10/1/attention/3/key/Net","encoder/10/1/attention/3/key/Net","Linear","Linear","Linear",22.,24.1,56.,"{49., 32., 24., 22., 33., 25., 25., 24., 24., 24., 25., 24., 25., 24., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 56., 26., 24., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",661,661,0,50,"encoder/10/1/attention/3/query/Net","encoder/10/1/attention/3/query/Net","encoder/10/1/attention/3/query/Net","Linear","Linear","Linear",21.,24.400000000000002,59.,"{59., 32., 23., 22., 21., 33., 25., 26., 24., 26., 25., 24., 24., 25., 32., 34., 24., 24., 25., 24., 25., 24., 24., 24., 24., 26., 23., 32., 22., 33., 33., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 23., 24., 24., 24., 24., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",662,662,0,50,"encoder/10/1/attention/3/elem","encoder/10/1/attention/3/elem","encoder/10/1/attention/3/elem","Elementwise","Elementwise","Elementwise",18.,18.,41.,"{41., 21., 18., 19., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 19., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",663,663,0,50,"encoder/10/1/attention/3/value/Net","encoder/10/1/attention/3/value/Net","encoder/10/1/attention/3/value/Net","Linear","Linear","Linear",21.,24.0333,59.,"{59., 32., 24., 22., 22., 22., 21., 22., 22., 46., 23., 21., 22., 34., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24., 25., 25., 25., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",664,664,0,50,"encoder/10/1/attention/3/attention/ScoringNet/1","encoder/10/1/attention/3/attention/ScoringNet/1","encoder/10/1/attention/3/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2333,46.,"{46., 34., 20., 19., 19., 19., 19., 20., 20., 20., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 20., 24., 20., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",665,665,0,50,"encoder/10/1/attention/4/key/Net","encoder/10/1/attention/4/key/Net","encoder/10/1/attention/4/key/Net","Linear","Linear","Linear",21.,22.3667,59.,"{59., 32., 29., 29., 24., 22., 21., 22., 22., 21., 22., 21., 22., 23., 21., 22., 21., 22., 21., 21., 21., 21., 21., 22., 21., 22., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21., 29., 29., 28., 30., 29., 38., 29., 29., 29., 22., 21., 22., 21., 22.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",666,666,0,50,"encoder/10/1/attention/4/query/Net","encoder/10/1/attention/4/query/Net","encoder/10/1/attention/4/query/Net","Linear","Linear","Linear",22.,24.,61.,"{48., 32., 30., 30., 23., 22., 34., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 25., 25., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 61., 35.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",667,667,0,50,"encoder/10/1/attention/4/elem","encoder/10/1/attention/4/elem","encoder/10/1/attention/4/elem","Elementwise","Elementwise","Elementwise",18.,18.2,40.,"{40., 21., 20., 18., 19., 18., 19., 18., 19., 18., 19., 18., 18., 19., 18., 19., 18., 18., 18., 19., 18., 19., 18., 18., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",668,668,0,50,"encoder/10/1/attention/4/value/Net","encoder/10/1/attention/4/value/Net","encoder/10/1/attention/4/value/Net","Linear","Linear","Linear",21.,24.166700000000002,48.,"{48., 31., 30., 29., 24., 42., 33., 24., 25., 24., 23., 24., 24., 32., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 34., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 36., 23., 33., 21., 21., 21., 22.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",669,669,0,50,"encoder/10/1/attention/4/attention/ScoringNet/1","encoder/10/1/attention/4/attention/ScoringNet/1","encoder/10/1/attention/4/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2667,45.,"{45., 34., 21., 20., 19., 20., 19., 20., 19., 19., 19., 19., 21., 19., 20., 19., 19., 20., 19., 19., 20., 20., 33., 20., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",670,670,0,50,"encoder/10/1/attention/5/key/Net","encoder/10/1/attention/5/key/Net","encoder/10/1/attention/5/key/Net","Linear","Linear","Linear",21.,24.0333,60.,"{58., 31., 24., 21., 21., 21., 21., 29., 23., 22., 21., 22., 21., 21., 21., 21., 22., 21., 21., 32., 33., 32., 25., 24., 24., 24., 24., 24., 60., 34., 32., 25., 24., 33., 25., 24., 24., 24., 32., 22., 21., 22., 21., 22., 44., 36., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",671,671,0,50,"encoder/10/1/attention/5/query/Net","encoder/10/1/attention/5/query/Net","encoder/10/1/attention/5/query/Net","Linear","Linear","Linear",21.,24.0667,59.,"{59., 33., 27., 24., 24., 32., 26., 24., 25., 24., 24., 24., 25., 24., 24., 24., 23., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 23., 32., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",672,672,0,50,"encoder/10/1/attention/5/elem","encoder/10/1/attention/5/elem","encoder/10/1/attention/5/elem","Elementwise","Elementwise","Elementwise",17.,18.0667,43.,"{40., 21., 19., 19., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 17., 18., 17., 18., 18., 18., 18., 18., 18., 43., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 21., 21., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",673,673,0,50,"encoder/10/1/attention/5/value/Net","encoder/10/1/attention/5/value/Net","encoder/10/1/attention/5/value/Net","Linear","Linear","Linear",21.,24.,59.,"{59., 32., 23., 21., 21., 22., 22., 33., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",674,674,0,50,"encoder/10/1/attention/5/attention/ScoringNet/1","encoder/10/1/attention/5/attention/ScoringNet/1","encoder/10/1/attention/5/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.5,45.,"{45., 22., 21., 20., 20., 19., 20., 20., 19., 20., 19., 20., 20., 19., 20., 31., 21., 19., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 20., 20., 19., 19., 20., 19., 20., 19., 19., 19., 19., 19., 20., 19., 20., 19., 20., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",675,675,0,50,"encoder/10/1/attention/6/key/Net","encoder/10/1/attention/6/key/Net","encoder/10/1/attention/6/key/Net","Linear","Linear","Linear",21.,23.666700000000002,48.,"{48., 32., 23., 22., 21., 21., 21., 22., 21., 22., 21., 21., 21., 21., 21., 21., 21., 22., 21., 34., 26., 24., 26., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 33., 34., 24., 25., 24., 31., 32., 32., 25., 24., 24., 24., 24., 25., 24., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",676,676,0,50,"encoder/10/1/attention/6/query/Net","encoder/10/1/attention/6/query/Net","encoder/10/1/attention/6/query/Net","Linear","Linear","Linear",21.,23.7667,60.,"{48., 31., 29., 22., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 33., 24., 24., 24., 23., 24., 24., 60., 34., 26., 24., 25., 32., 26., 23., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 26.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",677,677,0,50,"encoder/10/1/attention/6/elem","encoder/10/1/attention/6/elem","encoder/10/1/attention/6/elem","Elementwise","Elementwise","Elementwise",17.,18.,43.,"{41., 21., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 17., 18., 17., 18., 19., 18., 18., 18., 18., 17., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 43., 20., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",678,678,0,50,"encoder/10/1/attention/6/value/Net","encoder/10/1/attention/6/value/Net","encoder/10/1/attention/6/value/Net","Linear","Linear","Linear",21.,24.3333,60.,"{60., 32., 37., 25., 24., 24., 24., 24., 24., 24., 24., 32., 32., 24., 24., 24., 24., 24., 31., 32., 31., 25., 31., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 33., 24., 24., 50., 34., 33., 32., 26., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",679,679,0,50,"encoder/10/1/attention/6/attention/ScoringNet/1","encoder/10/1/attention/6/attention/ScoringNet/1","encoder/10/1/attention/6/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.0667,47.,"{47., 44., 21., 19., 19., 19., 20., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",680,680,0,50,"encoder/10/1/attention/7/key/Net","encoder/10/1/attention/7/key/Net","encoder/10/1/attention/7/key/Net","Linear","Linear","Linear",21.,23.2667,60.,"{60., 41., 30., 43., 27., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 32., 21., 21., 21., 22., 21., 21., 22., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21., 29.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",681,681,0,50,"encoder/10/1/attention/7/query/Net","encoder/10/1/attention/7/query/Net","encoder/10/1/attention/7/query/Net","Linear","Linear","Linear",21.,23.933300000000003,60.,"{60., 31., 24., 22., 22., 33., 24., 24., 23., 24., 24., 23., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 25., 24., 24., 24., 24., 24., 24., 31., 21., 21., 33., 24., 23., 24., 23., 24., 24., 24., 24., 23., 24., 23., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",682,682,0,50,"encoder/10/1/attention/7/elem","encoder/10/1/attention/7/elem","encoder/10/1/attention/7/elem","Elementwise","Elementwise","Elementwise",17.,18.,42.,"{42., 21., 18., 18., 19., 18., 18., 18., 19., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 32., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 17., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",683,683,0,50,"encoder/10/1/attention/7/value/Net","encoder/10/1/attention/7/value/Net","encoder/10/1/attention/7/value/Net","Linear","Linear","Linear",21.,24.3333,59.,"{59., 32., 23., 22., 22., 21., 29., 30., 43., 32., 25., 24., 24., 24., 32., 25., 26., 24., 24., 32., 25., 24., 24., 25., 24., 25., 25., 24., 24., 24., 24., 24., 25., 24., 32., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 26., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",684,684,0,50,"encoder/10/1/attention/7/attention/ScoringNet/1","encoder/10/1/attention/7/attention/ScoringNet/1","encoder/10/1/attention/7/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.5,49.,"{45., 23., 20., 19., 20., 20., 19., 20., 19., 20., 20., 19., 20., 20., 19., 20., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 20., 42., 21., 20., 19., 19., 20., 49., 21., 20., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",685,685,0,50,"encoder/10/1/attention/8/key/Net","encoder/10/1/attention/8/key/Net","encoder/10/1/attention/8/key/Net","Linear","Linear","Linear",24.,24.400000000000002,59.,"{59., 32., 27., 25., 25., 24., 25., 25., 24., 24., 24., 24., 24., 25., 25., 24., 24., 25., 24., 24., 24., 25., 24., 32., 34., 24., 24., 24., 24., 24., 25., 24., 24., 25., 25., 25., 24., 25., 25., 24., 24., 24., 24., 50., 26., 24., 24., 24., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",686,686,0,50,"encoder/10/1/attention/8/query/Net","encoder/10/1/attention/8/query/Net","encoder/10/1/attention/8/query/Net","Linear","Linear","Linear",21.,23.2667,60.,"{60., 32., 22., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 28., 22., 21., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 23., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 23., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",687,687,0,50,"encoder/10/1/attention/8/elem","encoder/10/1/attention/8/elem","encoder/10/1/attention/8/elem","Elementwise","Elementwise","Elementwise",17.,18.,41.,"{41., 22., 18., 19., 18., 18., 18., 18., 18., 19., 18., 40., 19., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",688,688,0,50,"encoder/10/1/attention/8/value/Net","encoder/10/1/attention/8/value/Net","encoder/10/1/attention/8/value/Net","Linear","Linear","Linear",21.,23.7667,57.,"{49., 31., 30., 28., 23., 22., 21., 22., 57., 35., 26., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 26., 25., 24., 24., 24., 37., 33., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 33., 24., 24., 23., 24., 24., 24., 23., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",689,689,0,50,"encoder/10/1/attention/8/attention/ScoringNet/1","encoder/10/1/attention/8/attention/ScoringNet/1","encoder/10/1/attention/8/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3667,60.,"{47., 23., 21., 20., 20., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 20., 20., 19., 20., 20., 19., 60., 21., 19., 19., 19., 19., 20., 20., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",690,690,0,50,"encoder/10/1/attention/9/key/Net","encoder/10/1/attention/9/key/Net","encoder/10/1/attention/9/key/Net","Linear","Linear","Linear",21.,24.,60.,"{60., 34., 23., 24., 21., 23., 28., 43., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",691,691,0,50,"encoder/10/1/attention/9/query/Net","encoder/10/1/attention/9/query/Net","encoder/10/1/attention/9/query/Net","Linear","Linear","Linear",21.,24.,59.,"{58., 32., 23., 22., 21., 21., 22., 21., 33., 24., 24., 25., 23., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 59., 34., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",692,692,0,50,"encoder/10/1/attention/9/elem","encoder/10/1/attention/9/elem","encoder/10/1/attention/9/elem","Elementwise","Elementwise","Elementwise",18.,18.3667,40.,"{40., 22., 19., 18., 18., 18., 18., 18., 19., 19., 18., 19., 19., 18., 18., 18., 19., 19., 19., 18., 19., 19., 19., 19., 19., 18., 18., 18., 18., 18., 18., 18., 19., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",693,693,0,50,"encoder/10/1/attention/9/value/Net","encoder/10/1/attention/9/value/Net","encoder/10/1/attention/9/value/Net","Linear","Linear","Linear",23.,24.0333,59.,"{59., 32., 30., 29., 42., 32., 27., 24., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 23., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",694,694,0,50,"encoder/10/1/attention/9/attention/ScoringNet/1","encoder/10/1/attention/9/attention/ScoringNet/1","encoder/10/1/attention/9/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3333,53.,"{47., 23., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 53., 23., 20., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 20., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",695,695,0,50,"encoder/10/1/attention/10/key/Net","encoder/10/1/attention/10/key/Net","encoder/10/1/attention/10/key/Net","Linear","Linear","Linear",26.,32.566700000000004,61.,"{61., 31., 29., 55., 30., 29., 29., 29., 29., 43., 32., 33., 33., 33., 33., 26., 33., 33., 33., 33., 33., 32., 32., 32., 33., 33., 33., 33., 32., 32., 33., 32., 32., 32., 33., 33., 33., 32., 44., 33., 32., 32., 33., 33., 33., 34., 32., 32., 32., 33.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",696,696,0,50,"encoder/10/1/attention/10/query/Net","encoder/10/1/attention/10/query/Net","encoder/10/1/attention/10/query/Net","Linear","Linear","Linear",21.,24.1,59.,"{59., 32., 29., 23., 21., 21., 28., 28., 42., 26., 25., 25., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 23., 24., 24., 24., 24., 32., 26., 24., 24., 24., 24., 24., 33.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",697,697,0,50,"encoder/10/1/attention/10/elem","encoder/10/1/attention/10/elem","encoder/10/1/attention/10/elem","Elementwise","Elementwise","Elementwise",18.,18.,41.,"{41., 21., 18., 19., 18., 18., 19., 19., 18., 18., 18., 18., 18., 20., 36., 20., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",698,698,0,50,"encoder/10/1/attention/10/value/Net","encoder/10/1/attention/10/value/Net","encoder/10/1/attention/10/value/Net","Linear","Linear","Linear",21.,23.900000000000002,60.,"{60., 33., 29., 23., 22., 21., 21., 28., 21., 21., 21., 22., 21., 22., 21., 33., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 34., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",699,699,0,50,"encoder/10/1/attention/10/attention/ScoringNet/1","encoder/10/1/attention/10/attention/ScoringNet/1","encoder/10/1/attention/10/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2333,51.,"{45., 34., 20., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 51., 21., 20., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20., 19., 20., 19., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",700,700,0,50,"encoder/10/1/attention/11/key/Net","encoder/10/1/attention/11/key/Net","encoder/10/1/attention/11/key/Net","Linear","Linear","Linear",21.,24.,59.,"{59., 32., 22., 21., 21., 22., 21., 22., 21., 34., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 40., 33., 33., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 37., 27., 24., 24., 24., 24., 23., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",701,701,0,50,"encoder/10/1/attention/11/query/Net","encoder/10/1/attention/11/query/Net","encoder/10/1/attention/11/query/Net","Linear","Linear","Linear",21.,23.5333,58.,"{58., 32., 24., 21., 22., 21., 22., 21., 21., 22., 21., 21., 22., 22., 22., 21., 21., 22., 21., 21., 33., 24., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",702,702,0,50,"encoder/10/1/attention/11/elem","encoder/10/1/attention/11/elem","encoder/10/1/attention/11/elem","Elementwise","Elementwise","Elementwise",18.,18.166700000000002,43.,"{41., 21., 19., 19., 19., 18., 19., 18., 43., 20., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 41., 19., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",703,703,0,50,"encoder/10/1/attention/11/value/Net","encoder/10/1/attention/11/value/Net","encoder/10/1/attention/11/value/Net","Linear","Linear","Linear",23.,25.966700000000003,60.,"{59., 32., 30., 29., 29., 54., 28., 24., 25., 24., 24., 43., 32., 33., 26., 25., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 23., 36., 60., 33., 33., 32., 32., 32., 32., 26., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 23.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",704,704,0,50,"encoder/10/1/attention/11/attention/ScoringNet/1","encoder/10/1/attention/11/attention/ScoringNet/1","encoder/10/1/attention/11/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.4667,46.,"{46., 23., 20., 20., 20., 19., 19., 19., 20., 20., 20., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 20., 19., 19., 20., 19., 19., 19., 20., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",705,705,0,50,"encoder/10/1/attention/12/key/Net","encoder/10/1/attention/12/key/Net","encoder/10/1/attention/12/key/Net","Linear","Linear","Linear",21.,24.0333,61.,"{61., 32., 30., 23., 24., 23., 21., 22., 21., 21., 22., 49., 35., 32., 33., 25., 25., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 25., 23., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",706,706,0,50,"encoder/10/1/attention/12/query/Net","encoder/10/1/attention/12/query/Net","encoder/10/1/attention/12/query/Net","Linear","Linear","Linear",21.,24.133300000000002,60.,"{60., 31., 29., 23., 21., 22., 33., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 35., 25., 24., 24., 24., 24., 24., 50., 35., 25., 25., 25., 24., 34., 25., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",707,707,0,50,"encoder/10/1/attention/12/elem","encoder/10/1/attention/12/elem","encoder/10/1/attention/12/elem","Elementwise","Elementwise","Elementwise",17.,18.,42.,"{42., 20., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 17., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",708,708,0,50,"encoder/10/1/attention/12/value/Net","encoder/10/1/attention/12/value/Net","encoder/10/1/attention/12/value/Net","Linear","Linear","Linear",22.,24.2667,61.,"{61., 32., 43., 25., 25., 24., 26., 24., 24., 25., 24., 24., 24., 24., 34., 33., 25., 24., 26., 24., 24., 24., 36., 22., 33., 24., 24., 24., 24., 23., 24., 24., 24., 23., 24., 24., 24., 24., 59., 27., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",709,709,0,50,"encoder/10/1/attention/12/attention/ScoringNet/1","encoder/10/1/attention/12/attention/ScoringNet/1","encoder/10/1/attention/12/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.166700000000002,48.,"{48., 34., 21., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 20., 20., 19., 19., 19., 19., 19., 19., 20., 19., 20., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",710,710,0,50,"encoder/10/1/attention/13","encoder/10/1/attention/13","encoder/10/1/attention/13","Catenate","Catenate","Catenate",55.,56.2667,80.,"{80., 60., 57., 58., 57., 56., 56., 56., 57., 56., 57., 56., 57., 57., 56., 57., 56., 57., 55., 56., 79., 57., 57., 56., 57., 56., 56., 56., 56., 56., 57., 56., 56., 56., 56., 56., 56., 56., 57., 56., 56., 56., 56., 56., 56., 56., 56., 56., 57., 56.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",711,711,0,50,"encoder/10/1/attention/14/Net","encoder/10/1/attention/14/Net","encoder/10/1/attention/14/Net","Linear","Linear","Linear",137.,138.63330000000002,235.,"{235., 182., 141., 139., 139., 139., 154., 139., 174., 140., 139., 179., 144., 139., 138., 137., 139., 137., 139., 137., 138., 138., 139., 137., 138., 138., 138., 138., 139., 137., 138., 138., 137., 139., 139., 164., 152., 139., 139., 138., 138., 139., 139., 138., 138., 138., 139., 138., 140., 138.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",712,712,0,50,"encoder/10/1/dropout","encoder/10/1/dropout","encoder/10/1/dropout","Dropout","Dropout","Dropout",17.,18.0333,39.,"{38., 21., 19., 18., 18., 19., 18., 18., 19., 19., 18., 19., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 39., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",713,714,1,50,"encoder/10/1/add","encoder/10/1/norm","encoder/10/1/add-encoder/10/1/norm","Threading","Normalization","Threading-Normalization",161.,162.16670000000002,221.,"{221., 166., 163., 163., 162., 161., 186., 191., 165., 162., 163., 162., 164., 162., 161., 161., 163., 162., 162., 162., 162., 162., 162., 162., 162., 162., 161., 162., 163., 162., 161., 180., 176., 164., 162., 162., 161., 162., 162., 163., 161., 161., 162., 161., 163., 162., 163., 161., 161., 161.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",715,715,0,50,"encoder/10/2/linear1/Net","encoder/10/2/linear1/Net","encoder/10/2/linear1/Net","Linear","Linear","Linear",442.,448.8333,796.,"{796., 666., 507., 469., 469., 450., 448., 494., 450., 442., 444., 445., 502., 446., 444., 447., 484., 447., 463., 444., 445., 443., 443., 445., 445., 482., 448., 446., 447., 461., 449., 446., 448., 475., 446., 448., 446., 445., 454., 446., 447., 447., 473., 445., 444., 443., 444., 451., 444., 445.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",716,716,0,50,"encoder/10/2/gelu","encoder/10/2/gelu","encoder/10/2/gelu","Elementwise","Elementwise","Elementwise",104.,105.2667,139.,"{139., 109., 106., 105., 106., 105., 106., 106., 105., 105., 105., 105., 105., 105., 109., 106., 106., 105., 117., 127., 108., 105., 105., 105., 105., 105., 105., 105., 104., 105., 105., 105., 105., 127., 109., 105., 105., 106., 105., 105., 104., 105., 105., 105., 106., 105., 106., 105., 105., 126.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",717,717,0,50,"encoder/10/2/linear2/Net","encoder/10/2/linear2/Net","encoder/10/2/linear2/Net","Linear","Linear","Linear",433.,441.43330000000003,613.,"{613., 550., 482., 500., 449., 444., 444., 445., 441., 442., 442., 478., 452., 441., 438., 438., 439., 438., 438., 439., 471., 439., 458., 438., 437., 450., 440., 438., 437., 470., 437., 436., 436., 437., 448., 438., 442., 438., 465., 436., 436., 434., 433., 433., 451., 436., 436., 440., 453., 440.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",718,718,0,50,"encoder/10/2/dropout","encoder/10/2/dropout","encoder/10/2/dropout","Dropout","Dropout","Dropout",18.,19.166700000000002,55.,"{42., 21., 19., 18., 19., 18., 18., 19., 19., 18., 18., 19., 18., 18., 18., 19., 19., 18., 18., 19., 18., 18., 18., 19., 18., 18., 18., 18., 19., 19., 19., 18., 18., 19., 19., 55., 24., 21., 22., 22., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",719,720,1,50,"encoder/10/2/add","encoder/10/2/norm","encoder/10/2/add-encoder/10/2/norm","Threading","Normalization","Threading-Normalization",161.,162.4333,222.,"{222., 168., 189., 165., 164., 163., 163., 162., 162., 162., 163., 163., 162., 163., 163., 163., 161., 161., 162., 164., 168., 163., 163., 162., 161., 162., 181., 163., 162., 161., 183., 167., 162., 163., 162., 162., 162., 162., 162., 162., 161., 162., 162., 162., 162., 161., 162., 161., 162., 181.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",721,721,0,50,"encoder/11/1/attention/1/key/Net","encoder/11/1/attention/1/key/Net","encoder/11/1/attention/1/key/Net","Linear","Linear","Linear",21.,23.700000000000003,75.,"{75., 32., 29., 29., 22., 28., 23., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 33., 24., 24., 24., 24., 31., 25., 24., 23., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 32., 32., 32., 32., 32.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",722,722,0,50,"encoder/11/1/attention/1/query/Net","encoder/11/1/attention/1/query/Net","encoder/11/1/attention/1/query/Net","Linear","Linear","Linear",21.,24.,63.,"{63., 32., 29., 22., 21., 33., 24., 24., 25., 25., 24., 24., 24., 23., 24., 24., 24., 24., 23., 25., 23., 24., 24., 24., 24., 24., 24., 24., 50., 36., 25., 24., 24., 23., 24., 24., 23., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",723,723,0,50,"encoder/11/1/attention/1/elem","encoder/11/1/attention/1/elem","encoder/11/1/attention/1/elem","Elementwise","Elementwise","Elementwise",18.,18.3,44.,"{44., 21., 19., 18., 18., 19., 18., 18., 18., 18., 18., 19., 20., 19., 31., 20., 19., 18., 18., 18., 18., 18., 18., 18., 19., 18., 19., 19., 18., 19., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",724,724,0,50,"encoder/11/1/attention/1/value/Net","encoder/11/1/attention/1/value/Net","encoder/11/1/attention/1/value/Net","Linear","Linear","Linear",24.,24.433300000000003,58.,"{52., 33., 29., 35., 32., 25., 24., 25., 24., 24., 24., 24., 25., 24., 24., 24., 26., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 32., 32., 26., 24., 25., 24., 24., 24., 58., 34., 25., 25., 24., 25., 24., 24., 25., 24., 25., 24., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",725,725,0,50,"encoder/11/1/attention/1/attention/ScoringNet/1","encoder/11/1/attention/1/attention/ScoringNet/1","encoder/11/1/attention/1/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.5667,69.,"{69., 26., 20., 20., 20., 19., 19., 20., 20., 19., 20., 19., 20., 20., 19., 19., 20., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 20., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 19., 20., 19., 20., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",726,726,0,50,"encoder/11/1/attention/2/key/Net","encoder/11/1/attention/2/key/Net","encoder/11/1/attention/2/key/Net","Linear","Linear","Linear",24.,24.1,69.,"{60., 31., 30., 37., 24., 24., 24., 25., 24., 24., 69., 34., 26., 24., 24., 33., 25., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",727,727,0,50,"encoder/11/1/attention/2/query/Net","encoder/11/1/attention/2/query/Net","encoder/11/1/attention/2/query/Net","Linear","Linear","Linear",23.,24.0333,59.,"{59., 31., 23., 33., 24., 24., 25., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 23., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 55., 36., 27.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",728,728,0,50,"encoder/11/1/attention/2/elem","encoder/11/1/attention/2/elem","encoder/11/1/attention/2/elem","Elementwise","Elementwise","Elementwise",18.,18.5,41.,"{41., 40., 21., 19., 19., 18., 19., 18., 18., 19., 18., 18., 18., 19., 18., 18., 19., 19., 18., 18., 19., 19., 18., 18., 19., 19., 19., 18., 19., 18., 19., 19., 18., 19., 18., 19., 18., 18., 19., 19., 18., 19., 18., 18., 19., 18., 18., 19., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",729,729,0,50,"encoder/11/1/attention/2/value/Net","encoder/11/1/attention/2/value/Net","encoder/11/1/attention/2/value/Net","Linear","Linear","Linear",21.,24.2667,68.,"{59., 26., 43., 26., 24., 24., 24., 25., 24., 68., 35., 25., 24., 24., 24., 25., 24., 24., 25., 24., 24., 25., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 25., 37., 23., 32., 22., 21., 22., 21., 33., 24., 24., 25., 23., 24., 25., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",730,730,0,50,"encoder/11/1/attention/2/attention/ScoringNet/1","encoder/11/1/attention/2/attention/ScoringNet/1","encoder/11/1/attention/2/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3333,50.,"{46., 23., 21., 20., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 20., 19., 19., 20., 19., 50., 21., 19., 20., 19., 19., 20., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",731,731,0,50,"encoder/11/1/attention/3/key/Net","encoder/11/1/attention/3/key/Net","encoder/11/1/attention/3/key/Net","Linear","Linear","Linear",23.,26.0667,62.,"{62., 31., 29., 42., 25., 24., 24., 24., 24., 23., 24., 24., 24., 24., 23., 24., 24., 24., 24., 62., 33., 32., 32., 32., 32., 32., 32., 32., 32., 32., 26., 24., 24., 25., 25., 25., 23., 26., 24., 24., 61., 34., 26., 24., 24., 24., 24., 24., 23., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",732,732,0,50,"encoder/11/1/attention/3/query/Net","encoder/11/1/attention/3/query/Net","encoder/11/1/attention/3/query/Net","Linear","Linear","Linear",21.,24.7333,50.,"{47., 32., 29., 30., 22., 21., 22., 33., 24., 25., 24., 24., 25., 24., 24., 32., 32., 26., 24., 25., 25., 25., 24., 25., 24., 24., 24., 25., 26., 50., 34., 34., 33., 27., 24., 24., 24., 25., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",733,733,0,50,"encoder/11/1/attention/3/elem","encoder/11/1/attention/3/elem","encoder/11/1/attention/3/elem","Elementwise","Elementwise","Elementwise",17.,18.3667,44.,"{40., 21., 19., 19., 18., 19., 18., 18., 18., 18., 18., 19., 18., 19., 19., 18., 19., 18., 18., 19., 18., 19., 19., 19., 19., 19., 18., 18., 19., 18., 18., 18., 19., 18., 19., 17., 18., 18., 18., 44., 19., 18., 18., 18., 18., 19., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",734,734,0,50,"encoder/11/1/attention/3/value/Net","encoder/11/1/attention/3/value/Net","encoder/11/1/attention/3/value/Net","Linear","Linear","Linear",22.,25.,61.,"{61., 32., 29., 29., 24., 29., 29., 28., 28., 29., 28., 22., 28., 22., 29., 28., 42., 34., 32., 32., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",735,735,0,50,"encoder/11/1/attention/3/attention/ScoringNet/1","encoder/11/1/attention/3/attention/ScoringNet/1","encoder/11/1/attention/3/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3667,45.,"{45., 23., 21., 20., 20., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 20., 19., 20., 20., 19., 20., 19., 19., 19., 19., 20., 20., 19., 19., 19., 19., 19., 20., 19., 20., 19., 19., 19., 20., 20., 19., 20., 19., 19., 20., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",736,736,0,50,"encoder/11/1/attention/4/key/Net","encoder/11/1/attention/4/key/Net","encoder/11/1/attention/4/key/Net","Linear","Linear","Linear",21.,24.0667,49.,"{49., 32., 34., 24., 33., 25., 32., 34., 26., 24., 32., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 35., 21., 21., 33., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",737,737,0,50,"encoder/11/1/attention/4/query/Net","encoder/11/1/attention/4/query/Net","encoder/11/1/attention/4/query/Net","Linear","Linear","Linear",21.,24.,59.,"{59., 32., 29., 23., 21., 21., 22., 23., 41., 35., 24., 24., 24., 24., 24., 24., 47., 25., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",738,738,0,50,"encoder/11/1/attention/4/elem","encoder/11/1/attention/4/elem","encoder/11/1/attention/4/elem","Elementwise","Elementwise","Elementwise",18.,18.,41.,"{41., 21., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 19., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 19., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",739,739,0,50,"encoder/11/1/attention/4/value/Net","encoder/11/1/attention/4/value/Net","encoder/11/1/attention/4/value/Net","Linear","Linear","Linear",21.,25.5,105.,"{60., 33., 30., 23., 34., 32., 32., 25., 24., 25., 25., 25., 24., 24., 25., 32., 25., 24., 32., 33., 25., 24., 24., 24., 24., 24., 25., 24., 25., 35., 32., 21., 22., 105., 36., 26., 24., 34., 25., 24., 24., 25., 24., 24., 25., 24., 24., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",740,740,0,50,"encoder/11/1/attention/4/attention/ScoringNet/1","encoder/11/1/attention/4/attention/ScoringNet/1","encoder/11/1/attention/4/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.5,45.,"{45., 23., 20., 20., 20., 19., 20., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 20., 20., 41., 20., 20., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",741,741,0,50,"encoder/11/1/attention/5/key/Net","encoder/11/1/attention/5/key/Net","encoder/11/1/attention/5/key/Net","Linear","Linear","Linear",22.,26.466700000000003,48.,"{48., 32., 24., 22., 34., 34., 27., 24., 25., 32., 32., 33., 26., 25., 24., 25., 24., 32., 32., 33., 33., 25., 25., 25., 25., 25., 24., 32., 32., 26., 24., 24., 25., 24., 24., 31., 32., 32., 33., 26., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",742,742,0,50,"encoder/11/1/attention/5/query/Net","encoder/11/1/attention/5/query/Net","encoder/11/1/attention/5/query/Net","Linear","Linear","Linear",21.,23.5333,58.,"{58., 32., 30., 29., 29., 24., 22., 34., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 23., 23., 24., 24., 24., 25., 23., 32., 21., 21., 21., 21., 21., 22., 21., 21., 21., 21., 21., 22., 21., 32., 24., 24., 23., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",743,743,0,50,"encoder/11/1/attention/5/elem","encoder/11/1/attention/5/elem","encoder/11/1/attention/5/elem","Elementwise","Elementwise","Elementwise",17.,18.,41.,"{41., 21., 19., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 19., 17., 18., 18., 18., 38., 19., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",744,744,0,50,"encoder/11/1/attention/5/value/Net","encoder/11/1/attention/5/value/Net","encoder/11/1/attention/5/value/Net","Linear","Linear","Linear",21.,24.0333,59.,"{59., 32., 31., 29., 22., 29., 22., 22., 21., 33., 22., 34., 24., 24., 24., 23., 34., 33., 32., 25., 23., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 23., 24., 23., 24., 24., 24., 24., 23., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",745,745,0,50,"encoder/11/1/attention/5/attention/ScoringNet/1","encoder/11/1/attention/5/attention/ScoringNet/1","encoder/11/1/attention/5/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2667,45.,"{45., 22., 43., 21., 34., 20., 19., 19., 20., 19., 20., 19., 19., 19., 20., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",746,746,0,50,"encoder/11/1/attention/6/key/Net","encoder/11/1/attention/6/key/Net","encoder/11/1/attention/6/key/Net","Linear","Linear","Linear",21.,24.1,61.,"{61., 32., 30., 24., 22., 22., 21., 21., 21., 22., 22., 22., 21., 31., 29., 24., 29., 29., 22., 21., 34., 25., 25., 24., 24., 24., 24., 25., 24., 24., 24., 25., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",747,747,0,50,"encoder/11/1/attention/6/query/Net","encoder/11/1/attention/6/query/Net","encoder/11/1/attention/6/query/Net","Linear","Linear","Linear",21.,23.9667,60.,"{60., 32., 29., 23., 22., 21., 22., 21., 22., 21., 21., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 33., 26., 24., 34., 25., 24., 25., 23., 33., 21., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",748,748,0,50,"encoder/11/1/attention/6/elem","encoder/11/1/attention/6/elem","encoder/11/1/attention/6/elem","Elementwise","Elementwise","Elementwise",17.,18.,42.,"{42., 22., 19., 18., 18., 18., 42., 20., 18., 18., 18., 18., 18., 19., 30., 19., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 19., 18., 18., 19., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",749,749,0,50,"encoder/11/1/attention/6/value/Net","encoder/11/1/attention/6/value/Net","encoder/11/1/attention/6/value/Net","Linear","Linear","Linear",21.,23.700000000000003,62.,"{62., 26., 22., 21., 21., 22., 21., 23., 28., 22., 21., 22., 21., 22., 21., 21., 22., 32., 24., 24., 25., 25., 25., 24., 24., 24., 24., 24., 23., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",750,750,0,50,"encoder/11/1/attention/6/attention/ScoringNet/1","encoder/11/1/attention/6/attention/ScoringNet/1","encoder/11/1/attention/6/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.400000000000002,48.,"{48., 23., 21., 20., 20., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 20., 19., 19., 20., 19., 20., 20., 19., 19., 19., 19., 46., 20., 19., 20., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",751,751,0,50,"encoder/11/1/attention/7/key/Net","encoder/11/1/attention/7/key/Net","encoder/11/1/attention/7/key/Net","Linear","Linear","Linear",21.,24.0667,53.,"{53., 32., 30., 22., 23., 22., 22., 22., 21., 21., 21., 22., 22., 22., 22., 21., 21., 22., 34., 25., 24., 25., 24., 24., 24., 24., 24., 33., 26., 24., 24., 24., 24., 24., 25., 32., 25., 24., 32., 25., 24., 25., 25., 24., 24., 49., 35., 33., 25., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",752,752,0,50,"encoder/11/1/attention/7/query/Net","encoder/11/1/attention/7/query/Net","encoder/11/1/attention/7/query/Net","Linear","Linear","Linear",21.,21.633300000000002,61.,"{61., 32., 23., 22., 21., 21., 22., 22., 21., 21., 22., 22., 21., 21., 21., 22., 22., 21., 21., 22., 22., 21., 21., 22., 21., 22., 21., 28., 23., 22., 21., 23., 28., 29., 23., 22., 21., 22., 22., 21., 21., 22., 21., 22., 21., 21., 22., 21., 22., 33.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",753,753,0,50,"encoder/11/1/attention/7/elem","encoder/11/1/attention/7/elem","encoder/11/1/attention/7/elem","Elementwise","Elementwise","Elementwise",18.,18.,43.,"{42., 21., 19., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 43.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",754,754,0,50,"encoder/11/1/attention/7/value/Net","encoder/11/1/attention/7/value/Net","encoder/11/1/attention/7/value/Net","Linear","Linear","Linear",21.,23.6,60.,"{59., 33., 60., 28., 25., 23., 24., 32., 32., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 23., 25., 25., 23., 33., 22., 21., 21., 21., 21., 21., 21., 22., 21., 21., 21., 22., 21., 21., 21., 34., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",755,755,0,50,"encoder/11/1/attention/7/attention/ScoringNet/1","encoder/11/1/attention/7/attention/ScoringNet/1","encoder/11/1/attention/7/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.400000000000002,59.,"{47., 23., 20., 20., 19., 20., 19., 20., 20., 19., 20., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 20., 59., 21., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 19., 20., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",756,756,0,50,"encoder/11/1/attention/8/key/Net","encoder/11/1/attention/8/key/Net","encoder/11/1/attention/8/key/Net","Linear","Linear","Linear",21.,24.633300000000002,50.,"{50., 43., 30., 22., 28., 28., 29., 24., 28., 29., 28., 22., 21., 21., 22., 32., 32., 26., 24., 24., 24., 24., 24., 24., 39., 27., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 32., 26., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",757,757,0,50,"encoder/11/1/attention/8/query/Net","encoder/11/1/attention/8/query/Net","encoder/11/1/attention/8/query/Net","Linear","Linear","Linear",21.,24.9667,61.,"{46., 32., 31., 23., 21., 22., 22., 33., 25., 24., 33., 26., 24., 25., 61., 27., 24., 24., 25., 24., 24., 24., 24., 24., 24., 23., 32., 26., 24., 24., 26., 24., 24., 24., 24., 24., 31., 32., 32., 25., 24., 31., 25., 24., 24., 24., 24., 32., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",758,758,0,50,"encoder/11/1/attention/8/elem","encoder/11/1/attention/8/elem","encoder/11/1/attention/8/elem","Elementwise","Elementwise","Elementwise",18.,18.0667,40.,"{40., 22., 19., 18., 19., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 19., 18., 18., 18., 18., 21., 34., 20., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",759,759,0,50,"encoder/11/1/attention/8/value/Net","encoder/11/1/attention/8/value/Net","encoder/11/1/attention/8/value/Net","Linear","Linear","Linear",21.,24.,60.,"{60., 32., 24., 22., 22., 22., 21., 22., 34., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 25., 25., 24., 24., 24., 24., 24., 25., 48., 26., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",760,760,0,50,"encoder/11/1/attention/8/attention/ScoringNet/1","encoder/11/1/attention/8/attention/ScoringNet/1","encoder/11/1/attention/8/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.5333,47.,"{47., 23., 20., 19., 19., 20., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 20., 19., 20., 19., 20., 19., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 27., 20., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",761,761,0,50,"encoder/11/1/attention/9/key/Net","encoder/11/1/attention/9/key/Net","encoder/11/1/attention/9/key/Net","Linear","Linear","Linear",21.,24.3,48.,"{48., 32., 24., 48., 33., 33., 27., 25., 24., 24., 24., 24., 25., 24., 24., 25., 24., 24., 25., 25., 24., 24., 24., 24., 25., 23., 34., 21., 22., 21., 22., 33., 24., 24., 24., 25., 24., 24., 24., 24., 24., 25., 24., 25., 25., 24., 24., 25., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",762,762,0,50,"encoder/11/1/attention/9/query/Net","encoder/11/1/attention/9/query/Net","encoder/11/1/attention/9/query/Net","Linear","Linear","Linear",21.,23.400000000000002,59.,"{59., 31., 29., 29., 23., 22., 22., 22., 21., 21., 21., 22., 21., 21., 22., 21., 22., 21., 22., 21., 21., 21., 21., 32., 24., 25., 24., 24., 25., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",763,763,0,50,"encoder/11/1/attention/9/elem","encoder/11/1/attention/9/elem","encoder/11/1/attention/9/elem","Elementwise","Elementwise","Elementwise",18.,18.4333,47.,"{40., 21., 19., 19., 18., 18., 18., 18., 19., 47., 20., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 19., 18., 19., 18., 18., 18., 19., 19., 19., 18., 18., 18., 18., 19., 19., 19., 18., 19., 18., 19., 19., 19., 19., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",764,764,0,50,"encoder/11/1/attention/9/value/Net","encoder/11/1/attention/9/value/Net","encoder/11/1/attention/9/value/Net","Linear","Linear","Linear",21.,23.900000000000002,59.,"{59., 33., 43., 26., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 23., 24., 25., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 23., 33., 21., 21., 22., 21., 21., 21., 21., 21., 22., 21., 33., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",765,765,0,50,"encoder/11/1/attention/9/attention/ScoringNet/1","encoder/11/1/attention/9/attention/ScoringNet/1","encoder/11/1/attention/9/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.1,45.,"{45., 34., 20., 20., 19., 20., 22., 19., 19., 19., 19., 19., 20., 19., 20., 19., 20., 20., 19., 20., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",766,766,0,50,"encoder/11/1/attention/10/key/Net","encoder/11/1/attention/10/key/Net","encoder/11/1/attention/10/key/Net","Linear","Linear","Linear",21.,23.9667,60.,"{60., 32., 30., 29., 23., 22., 21., 22., 21., 22., 21., 22., 21., 21., 22., 21., 33., 24., 49., 35., 27., 34., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 36., 21., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",767,767,0,50,"encoder/11/1/attention/10/query/Net","encoder/11/1/attention/10/query/Net","encoder/11/1/attention/10/query/Net","Linear","Linear","Linear",21.,22.666700000000002,58.,"{58., 33., 29., 23., 21., 21., 28., 28., 21., 21., 23., 21., 21., 28., 28., 21., 21., 28., 28., 28., 21., 21., 21., 21., 21., 22., 22., 21., 21., 22., 21., 21., 21., 21., 22., 21., 21., 22., 21., 21., 22., 28., 23., 21., 22., 28., 29., 28., 29., 23.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",768,768,0,50,"encoder/11/1/attention/10/elem","encoder/11/1/attention/10/elem","encoder/11/1/attention/10/elem","Elementwise","Elementwise","Elementwise",17.,18.,43.,"{41., 20., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 43., 19., 18., 18., 18., 18., 18., 18., 25., 19., 18., 18., 18., 18., 17., 18., 18., 18., 17., 18., 18., 18., 17., 18., 18., 18., 18., 17., 18., 18., 18., 17.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",769,769,0,50,"encoder/11/1/attention/10/value/Net","encoder/11/1/attention/10/value/Net","encoder/11/1/attention/10/value/Net","Linear","Linear","Linear",21.,24.0667,59.,"{59., 32., 29., 29., 29., 42., 34., 26., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 23., 33., 21., 21., 21., 21., 34., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",770,770,0,50,"encoder/11/1/attention/10/attention/ScoringNet/1","encoder/11/1/attention/10/attention/ScoringNet/1","encoder/11/1/attention/10/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.3,45.,"{45., 34., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",771,771,0,50,"encoder/11/1/attention/11/key/Net","encoder/11/1/attention/11/key/Net","encoder/11/1/attention/11/key/Net","Linear","Linear","Linear",23.,24.2667,59.,"{59., 32., 29., 28., 35., 24., 25., 24., 24., 25., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 25., 25., 24., 24., 24., 23., 32., 25., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 57., 28., 53., 35., 26., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",772,772,0,50,"encoder/11/1/attention/11/query/Net","encoder/11/1/attention/11/query/Net","encoder/11/1/attention/11/query/Net","Linear","Linear","Linear",21.,24.200000000000003,58.,"{58., 58., 30., 29., 30., 30., 30., 22., 22., 22., 21., 21., 22., 22., 21., 22., 33., 24., 24., 24., 25., 24., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 32., 25., 24., 25., 25., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",773,773,0,50,"encoder/11/1/attention/11/elem","encoder/11/1/attention/11/elem","encoder/11/1/attention/11/elem","Elementwise","Elementwise","Elementwise",18.,18.0667,41.,"{41., 21., 19., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 19., 18., 18., 18., 18., 19., 18., 18., 19., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 19., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",774,774,0,50,"encoder/11/1/attention/11/value/Net","encoder/11/1/attention/11/value/Net","encoder/11/1/attention/11/value/Net","Linear","Linear","Linear",21.,24.,62.,"{59., 25., 29., 22., 21., 21., 21., 21., 21., 22., 21., 22., 32., 24., 24., 24., 24., 24., 24., 62., 27., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",775,775,0,50,"encoder/11/1/attention/11/attention/ScoringNet/1","encoder/11/1/attention/11/attention/ScoringNet/1","encoder/11/1/attention/11/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.666700000000002,46.,"{46., 35., 20., 19., 19., 20., 19., 20., 20., 19., 20., 20., 19., 20., 19., 20., 19., 20., 20., 19., 20., 20., 20., 20., 20., 19., 20., 19., 20., 20., 20., 20., 19., 20., 19., 19., 19., 19., 19., 20., 20., 19., 20., 20., 19., 20., 19., 20., 19., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",776,776,0,50,"encoder/11/1/attention/12/key/Net","encoder/11/1/attention/12/key/Net","encoder/11/1/attention/12/key/Net","Linear","Linear","Linear",23.,24.2333,60.,"{60., 32., 29., 37., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 51., 33., 32., 32., 26., 24., 25., 25., 24., 24., 24., 24., 24., 24., 23., 36., 33., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",777,777,0,50,"encoder/11/1/attention/12/query/Net","encoder/11/1/attention/12/query/Net","encoder/11/1/attention/12/query/Net","Linear","Linear","Linear",21.,24.,58.,"{58., 31., 24., 22., 22., 22., 21., 22., 32., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 36., 25., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",778,778,0,50,"encoder/11/1/attention/12/elem","encoder/11/1/attention/12/elem","encoder/11/1/attention/12/elem","Elementwise","Elementwise","Elementwise",18.,18.,41.,"{41., 21., 19., 18., 18., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 19., 18., 18., 18., 18., 19., 18., 19., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",779,779,0,50,"encoder/11/1/attention/12/value/Net","encoder/11/1/attention/12/value/Net","encoder/11/1/attention/12/value/Net","Linear","Linear","Linear",21.,23.8667,59.,"{59., 32., 22., 22., 22., 22., 22., 21., 21., 21., 22., 21., 22., 21., 33., 24., 24., 25., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 47., 25., 25., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",780,780,0,50,"encoder/11/1/attention/12/attention/ScoringNet/1","encoder/11/1/attention/12/attention/ScoringNet/1","encoder/11/1/attention/12/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.0667,45.,"{45., 35., 20., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",781,781,0,50,"encoder/11/1/attention/13","encoder/11/1/attention/13","encoder/11/1/attention/13","Catenate","Catenate","Catenate",55.,56.2,80.,"{80., 59., 58., 57., 57., 56., 57., 56., 55., 56., 57., 56., 56., 56., 56., 56., 57., 56., 56., 55., 56., 56., 79., 58., 57., 56., 57., 56., 56., 56., 57., 56., 56., 57., 56., 56., 56., 56., 56., 56., 56., 56., 56., 57., 56., 56., 56., 56., 57., 56.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",782,782,0,50,"encoder/11/1/attention/14/Net","encoder/11/1/attention/14/Net","encoder/11/1/attention/14/Net","Linear","Linear","Linear",136.,138.13330000000002,244.,"{244., 197., 153., 140., 137., 138., 139., 138., 136., 165., 140., 140., 138., 137., 137., 138., 137., 137., 137., 138., 138., 139., 139., 137., 137., 138., 139., 138., 138., 138., 138., 138., 139., 138., 137., 138., 164., 141., 139., 138., 137., 139., 138., 138., 137., 137., 138., 137., 153., 139.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",783,783,0,50,"encoder/11/1/dropout","encoder/11/1/dropout","encoder/11/1/dropout","Dropout","Dropout","Dropout",18.,18.,37.,"{37., 22., 19., 19., 18., 18., 18., 18., 18., 18., 18., 19., 19., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",784,785,1,50,"encoder/11/1/add","encoder/11/1/norm","encoder/11/1/add-encoder/11/1/norm","Threading","Normalization","Threading-Normalization",161.,162.3333,215.,"{215., 197., 170., 162., 162., 163., 163., 163., 161., 162., 163., 162., 185., 163., 163., 162., 162., 162., 162., 162., 161., 162., 162., 163., 162., 162., 162., 161., 162., 161., 161., 162., 161., 162., 161., 181., 165., 162., 164., 162., 162., 164., 163., 163., 163., 162., 162., 180., 163., 162.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",786,786,0,50,"encoder/11/2/linear1/Net","encoder/11/2/linear1/Net","encoder/11/2/linear1/Net","Linear","Linear","Linear",439.,444.2667,756.,"{756., 694., 556., 458., 445., 444., 444., 477., 445., 445., 444., 469., 442., 440., 442., 441., 442., 442., 443., 441., 469., 441., 441., 439., 448., 441., 441., 440., 465., 463., 442., 441., 442., 441., 440., 441., 442., 476., 447., 444., 445., 445., 444., 445., 446., 445., 476., 445., 445., 444.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",787,787,0,50,"encoder/11/2/gelu","encoder/11/2/gelu","encoder/11/2/gelu","Elementwise","Elementwise","Elementwise",104.,105.2333,140.,"{140., 108., 106., 106., 105., 105., 105., 105., 106., 105., 105., 105., 120., 108., 105., 105., 106., 105., 105., 105., 105., 105., 105., 106., 105., 106., 105., 105., 137., 107., 114., 106., 105., 105., 127., 109., 105., 105., 105., 105., 104., 105., 106., 104., 105., 105., 105., 105., 105., 105.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",788,788,0,50,"encoder/11/2/linear2/Net","encoder/11/2/linear2/Net","encoder/11/2/linear2/Net","Linear","Linear","Linear",432.,439.2667,592.,"{592., 550., 474., 452., 437., 452., 480., 436., 436., 435., 436., 436., 437., 437., 460., 434., 435., 433., 433., 432., 451., 436., 436., 461., 449., 449., 437., 436., 438., 436., 435., 436., 461., 438., 436., 436., 437., 436., 435., 437., 436., 462., 440., 434., 435., 457., 447., 437., 450., 437.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",789,789,0,50,"encoder/11/2/dropout","encoder/11/2/dropout","encoder/11/2/dropout","Dropout","Dropout","Dropout",21.,21.,44.,"{44., 23., 22., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21., 22., 21., 21., 21., 33., 33., 22., 21., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",790,791,1,50,"encoder/11/2/add","encoder/11/2/norm","encoder/11/2/add-encoder/11/2/norm","Threading","Normalization","Threading-Normalization",161.,162.4667,219.,"{219., 167., 163., 162., 162., 162., 163., 161., 162., 163., 162., 163., 163., 188., 165., 163., 177., 165., 162., 163., 162., 163., 162., 161., 163., 162., 170., 162., 162., 163., 162., 164., 174., 163., 163., 163., 162., 185., 162., 162., 162., 162., 162., 161., 162., 162., 162., 163., 162., 162.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",792,792,0,50,"encoder/12/1/attention/1/key/Net","encoder/12/1/attention/1/key/Net","encoder/12/1/attention/1/key/Net","Linear","Linear","Linear",21.,23.8667,72.,"{72., 32., 23., 23., 22., 22., 22., 21., 22., 22., 21., 21., 22., 21., 22., 33., 24., 24., 25., 25., 24., 24., 24., 25., 24., 24., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",793,793,0,50,"encoder/12/1/attention/1/query/Net","encoder/12/1/attention/1/query/Net","encoder/12/1/attention/1/query/Net","Linear","Linear","Linear",21.,23.933300000000003,61.,"{61., 33., 23., 22., 21., 21., 22., 21., 21., 22., 21., 22., 32., 24., 24., 24., 25., 24., 24., 47., 36., 33., 33., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 32.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",794,794,0,50,"encoder/12/1/attention/1/elem","encoder/12/1/attention/1/elem","encoder/12/1/attention/1/elem","Elementwise","Elementwise","Elementwise",17.,18.133300000000002,43.,"{43., 21., 19., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 19., 18., 18., 18., 18., 19., 19., 18., 18., 17., 19., 18., 19., 19., 19., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",795,795,0,50,"encoder/12/1/attention/1/value/Net","encoder/12/1/attention/1/value/Net","encoder/12/1/attention/1/value/Net","Linear","Linear","Linear",21.,24.133300000000002,60.,"{60., 32., 22., 22., 21., 21., 22., 22., 56., 43., 33., 25., 25., 32., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 25., 24., 24., 24., 25., 35., 33., 21., 22., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",796,796,0,50,"encoder/12/1/attention/1/attention/ScoringNet/1","encoder/12/1/attention/1/attention/ScoringNet/1","encoder/12/1/attention/1/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.400000000000002,48.,"{48., 23., 20., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 20., 19., 20., 19., 19., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",797,797,0,50,"encoder/12/1/attention/2/key/Net","encoder/12/1/attention/2/key/Net","encoder/12/1/attention/2/key/Net","Linear","Linear","Linear",21.,24.,61.,"{61., 31., 24., 21., 33., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 23., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",798,798,0,50,"encoder/12/1/attention/2/query/Net","encoder/12/1/attention/2/query/Net","encoder/12/1/attention/2/query/Net","Linear","Linear","Linear",21.,25.3,58.,"{58., 32., 29., 29., 29., 30., 30., 22., 23., 21., 21., 21., 32., 32., 25., 31., 32., 25., 32., 57., 35., 25., 25., 24., 24., 34., 26., 25., 24., 24., 25., 24., 24., 25., 25., 24., 24., 25., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",799,799,0,50,"encoder/12/1/attention/2/elem","encoder/12/1/attention/2/elem","encoder/12/1/attention/2/elem","Elementwise","Elementwise","Elementwise",17.,18.,40.,"{40., 22., 18., 19., 19., 19., 19., 19., 18., 18., 18., 18., 18., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",800,800,0,50,"encoder/12/1/attention/2/value/Net","encoder/12/1/attention/2/value/Net","encoder/12/1/attention/2/value/Net","Linear","Linear","Linear",21.,24.200000000000003,73.,"{59., 32., 31., 29., 23., 22., 21., 21., 21., 23., 21., 32., 24., 24., 24., 24., 24., 24., 64., 37., 32., 32., 26., 24., 24., 24., 24., 24., 73., 28., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",801,801,0,50,"encoder/12/1/attention/2/attention/ScoringNet/1","encoder/12/1/attention/2/attention/ScoringNet/1","encoder/12/1/attention/2/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2667,46.,"{46., 24., 20., 20., 20., 19., 19., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",802,802,0,50,"encoder/12/1/attention/3/key/Net","encoder/12/1/attention/3/key/Net","encoder/12/1/attention/3/key/Net","Linear","Linear","Linear",21.,23.666700000000002,60.,"{60., 32., 23., 22., 23., 22., 22., 29., 23., 21., 22., 21., 21., 21., 21., 28., 29., 28., 28., 23., 21., 21., 22., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 23., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",803,803,0,50,"encoder/12/1/attention/3/query/Net","encoder/12/1/attention/3/query/Net","encoder/12/1/attention/3/query/Net","Linear","Linear","Linear",24.,24.7333,60.,"{47., 32., 34., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 60., 39., 27., 25., 24., 24., 25., 24., 25., 24., 24., 24., 25., 58., 38., 44., 28., 24., 24., 24., 50., 26., 24., 24., 27., 60., 28., 24., 24., 25., 25., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",804,804,0,50,"encoder/12/1/attention/3/elem","encoder/12/1/attention/3/elem","encoder/12/1/attention/3/elem","Elementwise","Elementwise","Elementwise",18.,18.2,41.,"{41., 22., 19., 19., 25., 19., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 26., 19., 19., 19., 19., 19., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",805,805,0,50,"encoder/12/1/attention/3/value/Net","encoder/12/1/attention/3/value/Net","encoder/12/1/attention/3/value/Net","Linear","Linear","Linear",21.,23.9667,63.,"{63., 32., 23., 22., 21., 21., 22., 22., 22., 21., 22., 22., 21., 22., 34., 24., 24., 24., 25., 24., 24., 24., 24., 24., 25., 24., 25., 25., 24., 25., 26., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 62., 34., 27., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",806,806,0,50,"encoder/12/1/attention/3/attention/ScoringNet/1","encoder/12/1/attention/3/attention/ScoringNet/1","encoder/12/1/attention/3/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.4667,49.,"{49., 23., 20., 20., 20., 20., 19., 20., 19., 20., 19., 19., 19., 19., 19., 20., 41., 20., 20., 20., 19., 20., 19., 19., 20., 19., 19., 19., 19., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 19., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",807,807,0,50,"encoder/12/1/attention/4/key/Net","encoder/12/1/attention/4/key/Net","encoder/12/1/attention/4/key/Net","Linear","Linear","Linear",23.,24.,60.,"{60., 32., 36., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 26., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",808,808,0,50,"encoder/12/1/attention/4/query/Net","encoder/12/1/attention/4/query/Net","encoder/12/1/attention/4/query/Net","Linear","Linear","Linear",23.,24.,60.,"{60., 31., 30., 36., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",809,809,0,50,"encoder/12/1/attention/4/elem","encoder/12/1/attention/4/elem","encoder/12/1/attention/4/elem","Elementwise","Elementwise","Elementwise",17.,18.,42.,"{42., 21., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 19., 35., 20., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",810,810,0,50,"encoder/12/1/attention/4/value/Net","encoder/12/1/attention/4/value/Net","encoder/12/1/attention/4/value/Net","Linear","Linear","Linear",21.,23.3333,58.,"{58., 25., 23., 22., 22., 21., 29., 29., 22., 22., 21., 22., 21., 22., 21., 22., 28., 28., 22., 22., 21., 21., 22., 22., 21., 21., 22., 33., 24., 24., 24., 32., 25., 24., 31., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",811,811,0,50,"encoder/12/1/attention/4/attention/ScoringNet/1","encoder/12/1/attention/4/attention/ScoringNet/1","encoder/12/1/attention/4/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.666700000000002,81.,"{81., 25., 21., 20., 20., 20., 19., 19., 20., 20., 20., 19., 20., 19., 20., 20., 19., 20., 20., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 20., 19., 20., 20., 19., 20., 19., 20., 19., 20., 20., 19., 20., 20., 19., 19., 19., 20., 20., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",812,812,0,50,"encoder/12/1/attention/5/key/Net","encoder/12/1/attention/5/key/Net","encoder/12/1/attention/5/key/Net","Linear","Linear","Linear",21.,23.133300000000002,65.,"{65., 32., 29., 23., 21., 21., 44., 23., 21., 21., 22., 21., 21., 21., 21., 21., 22., 21., 22., 21., 22., 21., 21., 21., 21., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 33., 26., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",813,813,0,50,"encoder/12/1/attention/5/query/Net","encoder/12/1/attention/5/query/Net","encoder/12/1/attention/5/query/Net","Linear","Linear","Linear",21.,24.,63.,"{63., 32., 30., 23., 21., 21., 21., 33., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 25., 35., 33., 33., 24., 24., 23., 24., 24., 24., 23., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",814,814,0,50,"encoder/12/1/attention/5/elem","encoder/12/1/attention/5/elem","encoder/12/1/attention/5/elem","Elementwise","Elementwise","Elementwise",18.,18.2333,43.,"{43., 21., 19., 19., 18., 19., 18., 19., 18., 18., 19., 18., 19., 18., 18., 18., 19., 18., 18., 19., 18., 18., 19., 19., 18., 18., 19., 18., 18., 18., 19., 18., 18., 19., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",815,815,0,50,"encoder/12/1/attention/5/value/Net","encoder/12/1/attention/5/value/Net","encoder/12/1/attention/5/value/Net","Linear","Linear","Linear",21.,23.0333,52.,"{52., 32., 31., 23., 22., 22., 21., 22., 22., 21., 22., 21., 21., 22., 21., 22., 21., 21., 21., 21., 21., 22., 21., 21., 21., 21., 33., 24., 24., 24., 24., 24., 24., 24., 25., 24., 25., 24., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",816,816,0,50,"encoder/12/1/attention/5/attention/ScoringNet/1","encoder/12/1/attention/5/attention/ScoringNet/1","encoder/12/1/attention/5/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.5667,52.,"{47., 23., 21., 20., 20., 20., 19., 19., 20., 20., 19., 20., 45., 21., 19., 20., 19., 20., 52., 20., 20., 19., 19., 19., 20., 20., 19., 20., 19., 19., 22., 34., 21., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",817,817,0,50,"encoder/12/1/attention/6/key/Net","encoder/12/1/attention/6/key/Net","encoder/12/1/attention/6/key/Net","Linear","Linear","Linear",21.,24.200000000000003,61.,"{61., 31., 31., 22., 22., 21., 22., 34., 24., 46., 26., 24., 25., 24., 25., 24., 51., 26., 24., 24., 24., 25., 44., 34., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 25., 24., 24., 24., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",818,818,0,50,"encoder/12/1/attention/6/query/Net","encoder/12/1/attention/6/query/Net","encoder/12/1/attention/6/query/Net","Linear","Linear","Linear",21.,23.666700000000002,59.,"{59., 33., 29., 22., 21., 22., 21., 21., 29., 22., 28., 22., 21., 22., 22., 23., 21., 21., 21., 21., 34., 24., 24., 32., 25., 24., 23., 25., 25., 25., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 23., 24., 24., 23.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",819,819,0,50,"encoder/12/1/attention/6/elem","encoder/12/1/attention/6/elem","encoder/12/1/attention/6/elem","Elementwise","Elementwise","Elementwise",17.,18.,46.,"{41., 20., 18., 42., 20., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 46., 20., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",820,820,0,50,"encoder/12/1/attention/6/value/Net","encoder/12/1/attention/6/value/Net","encoder/12/1/attention/6/value/Net","Linear","Linear","Linear",21.,24.3333,60.,"{60., 32., 30., 22., 22., 34., 24., 24., 25., 24., 24., 24., 25., 25., 24., 24., 24., 24., 24., 25., 25., 32., 32., 32., 25., 26., 23., 34., 21., 21., 22., 33., 23., 24., 25., 25., 24., 24., 24., 24., 24., 31., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",821,821,0,50,"encoder/12/1/attention/6/attention/ScoringNet/1","encoder/12/1/attention/6/attention/ScoringNet/1","encoder/12/1/attention/6/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2667,47.,"{47., 23., 20., 19., 19., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 42., 21., 20., 19., 20., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",822,822,0,50,"encoder/12/1/attention/7/key/Net","encoder/12/1/attention/7/key/Net","encoder/12/1/attention/7/key/Net","Linear","Linear","Linear",22.,24.433300000000003,48.,"{48., 32., 30., 23., 22., 35., 24., 25., 25., 24., 25., 25., 24., 24., 24., 25., 25., 25., 24., 25., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 48., 35., 34., 34., 32., 26., 24., 25., 25., 24., 25., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",823,823,0,50,"encoder/12/1/attention/7/query/Net","encoder/12/1/attention/7/query/Net","encoder/12/1/attention/7/query/Net","Linear","Linear","Linear",21.,25.8667,84.,"{47., 31., 29., 23., 21., 21., 21., 22., 34., 24., 24., 24., 24., 24., 31., 32., 33., 33., 33., 32., 32., 33., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 84., 47., 33., 34., 32., 27., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",824,824,0,50,"encoder/12/1/attention/7/elem","encoder/12/1/attention/7/elem","encoder/12/1/attention/7/elem","Elementwise","Elementwise","Elementwise",17.,18.,43.,"{40., 21., 19., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 17., 18., 19., 18., 18., 17., 18., 18., 18., 43., 19., 17., 18., 18., 18., 18., 18., 17., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",825,825,0,50,"encoder/12/1/attention/7/value/Net","encoder/12/1/attention/7/value/Net","encoder/12/1/attention/7/value/Net","Linear","Linear","Linear",24.,24.,58.,"{58., 39., 34., 26., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",826,826,0,50,"encoder/12/1/attention/7/attention/ScoringNet/1","encoder/12/1/attention/7/attention/ScoringNet/1","encoder/12/1/attention/7/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.166700000000002,46.,"{46., 22., 20., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 20., 20., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",827,827,0,50,"encoder/12/1/attention/8/key/Net","encoder/12/1/attention/8/key/Net","encoder/12/1/attention/8/key/Net","Linear","Linear","Linear",21.,24.,71.,"{59., 32., 30., 29., 23., 29., 30., 22., 22., 22., 21., 21., 21., 22., 21., 21., 22., 21., 22., 22., 32., 25., 25., 24., 24., 24., 24., 24., 71., 35., 25., 24., 24., 25., 24., 24., 24., 25., 25., 24., 24., 24., 24., 25., 24., 24., 24., 24., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",828,828,0,50,"encoder/12/1/attention/8/query/Net","encoder/12/1/attention/8/query/Net","encoder/12/1/attention/8/query/Net","Linear","Linear","Linear",21.,24.2333,82.,"{82., 32., 31., 23., 22., 23., 22., 22., 21., 22., 21., 23., 22., 21., 21., 22., 33., 24., 25., 24., 25., 24., 32., 25., 32., 25., 24., 24., 24., 24., 24., 24., 26., 33., 25., 32., 25., 24., 24., 24., 24., 25., 24., 24., 24., 24., 25., 25., 25., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",829,829,0,50,"encoder/12/1/attention/8/elem","encoder/12/1/attention/8/elem","encoder/12/1/attention/8/elem","Elementwise","Elementwise","Elementwise",18.,18.,41.,"{41., 21., 18., 18., 18., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 19., 18., 18., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 19., 18., 19., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",830,830,0,50,"encoder/12/1/attention/8/value/Net","encoder/12/1/attention/8/value/Net","encoder/12/1/attention/8/value/Net","Linear","Linear","Linear",22.,24.166700000000002,61.,"{47., 31., 23., 22., 22., 33., 24., 25., 24., 24., 25., 61., 33., 26., 24., 25., 33., 26., 26., 38., 26., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",831,831,0,50,"encoder/12/1/attention/8/attention/ScoringNet/1","encoder/12/1/attention/8/attention/ScoringNet/1","encoder/12/1/attention/8/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2333,46.,"{46., 24., 20., 20., 19., 19., 19., 20., 19., 20., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 20., 20., 19., 20., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 20., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",832,832,0,50,"encoder/12/1/attention/9/key/Net","encoder/12/1/attention/9/key/Net","encoder/12/1/attention/9/key/Net","Linear","Linear","Linear",21.,26.900000000000002,48.,"{48., 32., 24., 28., 23., 28., 23., 28., 34., 24., 24., 23., 32., 26., 24., 32., 26., 32., 32., 31., 33., 32., 26., 24., 24., 24., 23., 24., 31., 26., 32., 33., 26., 24., 31., 36., 38., 29., 23., 21., 21., 22., 21., 28., 28., 29., 22., 28., 22., 22.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",833,833,0,50,"encoder/12/1/attention/9/query/Net","encoder/12/1/attention/9/query/Net","encoder/12/1/attention/9/query/Net","Linear","Linear","Linear",21.,24.8,58.,"{58., 32., 30., 29., 30., 23., 21., 22., 31., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 24., 52., 25., 25., 23., 24., 24., 32., 25., 24., 25., 23., 24., 24., 44., 33., 25., 24., 24., 24., 24., 25., 24., 24., 24., 24., 24., 32., 32., 24., 32.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",834,834,0,50,"encoder/12/1/attention/9/elem","encoder/12/1/attention/9/elem","encoder/12/1/attention/9/elem","Elementwise","Elementwise","Elementwise",17.,18.,40.,"{40., 21., 19., 19., 18., 19., 18., 18., 18., 18., 17., 18., 18., 18., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 18., 17., 18., 18., 17., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",835,835,0,50,"encoder/12/1/attention/9/value/Net","encoder/12/1/attention/9/value/Net","encoder/12/1/attention/9/value/Net","Linear","Linear","Linear",21.,26.633300000000002,58.,"{58., 32., 37., 24., 32., 25., 32., 26., 32., 32., 32., 33., 32., 25., 24., 24., 24., 32., 32., 32., 32., 28., 23., 39., 23., 21., 22., 21., 22., 21., 31., 29., 28., 23., 22., 33., 25., 25., 25., 25., 24., 25., 25., 24., 25., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",836,836,0,50,"encoder/12/1/attention/9/attention/ScoringNet/1","encoder/12/1/attention/9/attention/ScoringNet/1","encoder/12/1/attention/9/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.,45.,"{45., 23., 20., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",837,837,0,50,"encoder/12/1/attention/10/key/Net","encoder/12/1/attention/10/key/Net","encoder/12/1/attention/10/key/Net","Linear","Linear","Linear",21.,23.7667,59.,"{59., 32., 24., 22., 22., 21., 21., 21., 22., 21., 22., 21., 21., 21., 22., 32., 25., 25., 23., 25., 23., 25., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 25.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",838,838,0,50,"encoder/12/1/attention/10/query/Net","encoder/12/1/attention/10/query/Net","encoder/12/1/attention/10/query/Net","Linear","Linear","Linear",23.,24.,48.,"{47., 31., 48., 37., 25., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 23., 24., 24., 24., 23., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 23., 24., 24., 24., 23., 24., 24., 24., 46., 25., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",839,839,0,50,"encoder/12/1/attention/10/elem","encoder/12/1/attention/10/elem","encoder/12/1/attention/10/elem","Elementwise","Elementwise","Elementwise",17.,18.,41.,"{41., 21., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 19., 18., 19., 18., 18., 18., 19., 18., 18., 18., 17., 18., 17., 18., 19., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",840,840,0,50,"encoder/12/1/attention/10/value/Net","encoder/12/1/attention/10/value/Net","encoder/12/1/attention/10/value/Net","Linear","Linear","Linear",23.,24.,59.,"{59., 32., 30., 29., 23., 40., 37., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 23., 24., 24., 23., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 23., 24., 23., 24., 24., 24., 24., 23., 24., 24., 59.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",841,841,0,50,"encoder/12/1/attention/10/attention/ScoringNet/1","encoder/12/1/attention/10/attention/ScoringNet/1","encoder/12/1/attention/10/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.433300000000003,45.,"{45., 23., 21., 20., 20., 20., 20., 19., 20., 20., 19., 19., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 19., 20., 19., 20., 19., 19., 19., 19., 19., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 20., 19., 19., 20., 19., 19., 19., 20.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",842,842,0,50,"encoder/12/1/attention/11/key/Net","encoder/12/1/attention/11/key/Net","encoder/12/1/attention/11/key/Net","Linear","Linear","Linear",21.,23.5667,60.,"{60., 32., 29., 29., 28., 30., 29., 23., 21., 21., 21., 22., 21., 29., 29., 28., 29., 22., 22., 21., 22., 21., 21., 22., 21., 21., 21., 21., 21., 33., 24., 24., 24., 24., 24., 24., 24., 24., 23., 23., 24., 24., 24., 24., 24., 24., 23., 24., 24., 23.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",843,843,0,50,"encoder/12/1/attention/11/query/Net","encoder/12/1/attention/11/query/Net","encoder/12/1/attention/11/query/Net","Linear","Linear","Linear",21.,23.133300000000002,58.,"{58., 32., 25., 31., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 36., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 34., 24., 24., 23., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",844,844,0,50,"encoder/12/1/attention/11/elem","encoder/12/1/attention/11/elem","encoder/12/1/attention/11/elem","Elementwise","Elementwise","Elementwise",18.,18.133300000000002,39.,"{39., 21., 19., 19., 18., 19., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 19., 18., 18., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",845,845,0,50,"encoder/12/1/attention/11/value/Net","encoder/12/1/attention/11/value/Net","encoder/12/1/attention/11/value/Net","Linear","Linear","Linear",21.,23.933300000000003,70.,"{60., 33., 29., 22., 22., 21., 21., 21., 22., 21., 32., 24., 24., 23., 24., 25., 23., 70., 28., 24., 24., 24., 24., 24., 25., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",846,846,0,50,"encoder/12/1/attention/11/attention/ScoringNet/1","encoder/12/1/attention/11/attention/ScoringNet/1","encoder/12/1/attention/11/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.2,46.,"{46., 34., 20., 20., 20., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 42., 21., 19., 19., 20., 19., 19., 19., 19., 20., 19., 19., 20., 19., 19., 19., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 20., 20., 19., 19., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",847,847,0,50,"encoder/12/1/attention/12/key/Net","encoder/12/1/attention/12/key/Net","encoder/12/1/attention/12/key/Net","Linear","Linear","Linear",21.,21.166700000000002,60.,"{60., 32., 29., 29., 23., 22., 21., 22., 21., 22., 21., 21., 21., 21., 21., 22., 21., 21., 21., 21., 21., 21., 21., 22., 21., 21., 32., 29., 21., 21., 22., 21., 21., 21., 21., 21., 21., 22., 21., 22., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",848,848,0,50,"encoder/12/1/attention/12/query/Net","encoder/12/1/attention/12/query/Net","encoder/12/1/attention/12/query/Net","Linear","Linear","Linear",21.,23.5,61.,"{59., 32., 23., 21., 21., 21., 22., 21., 22., 21., 21., 21., 21., 21., 32., 24., 24., 24., 24., 24., 23., 24., 23., 23., 24., 23., 24., 23., 24., 24., 23., 23., 24., 25., 24., 24., 23., 24., 61., 38., 25., 24., 24., 23., 24., 23., 24., 23., 24., 23.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",849,849,0,50,"encoder/12/1/attention/12/elem","encoder/12/1/attention/12/elem","encoder/12/1/attention/12/elem","Elementwise","Elementwise","Elementwise",18.,18.,39.,"{39., 21., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 20., 18., 18., 18., 18., 18., 19., 18., 25., 19., 18., 18., 18., 19., 18., 18., 18., 19., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",850,850,0,50,"encoder/12/1/attention/12/value/Net","encoder/12/1/attention/12/value/Net","encoder/12/1/attention/12/value/Net","Linear","Linear","Linear",23.,24.,58.,"{58., 32., 43., 33., 24., 25., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 24., 24., 24., 24., 24., 24., 24., 23., 24., 23., 24., 24., 24., 23., 24., 24., 24., 24., 23., 24., 23., 24., 23., 24., 33., 33., 25., 24., 24., 24., 24., 24., 24., 24.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",851,851,0,50,"encoder/12/1/attention/12/attention/ScoringNet/1","encoder/12/1/attention/12/attention/ScoringNet/1","encoder/12/1/attention/12/attention/ScoringNet/1","Dot","Dot","Dot",19.,19.166700000000002,45.,"{45., 34., 21., 20., 19., 19., 19., 19., 20., 19., 19., 19., 20., 19., 19., 19., 19., 20., 20., 44., 20., 19., 19., 19., 19., 19., 19., 19., 20., 19., 20., 19., 19., 19., 19., 19., 19., 19., 19., 19., 20., 19., 20., 19., 19., 19., 20., 19., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",852,852,0,50,"encoder/12/1/attention/13","encoder/12/1/attention/13","encoder/12/1/attention/13","Catenate","Catenate","Catenate",55.,56.066700000000004,80.,"{80., 59., 57., 56., 57., 56., 56., 72., 59., 56., 56., 55., 56., 56., 56., 56., 56., 57., 56., 57., 56., 56., 56., 56., 57., 56., 56., 56., 56., 55., 55., 55., 55., 56., 56., 56., 57., 56., 56., 55., 56., 56., 57., 57., 55., 56., 55., 56., 56., 56.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",853,853,0,50,"encoder/12/1/attention/14/Net","encoder/12/1/attention/14/Net","encoder/12/1/attention/14/Net","Linear","Linear","Linear",137.,138.5667,244.,"{244., 191., 143., 137., 143., 137., 137., 137., 139., 151., 144., 139., 137., 137., 137., 138., 138., 141., 138., 137., 138., 170., 141., 138., 138., 137., 138., 138., 139., 137., 138., 139., 138., 138., 139., 139., 139., 138., 163., 142., 139., 138., 139., 138., 138., 137., 139., 138., 173., 140.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",854,854,0,50,"encoder/12/1/dropout","encoder/12/1/dropout","encoder/12/1/dropout","Dropout","Dropout","Dropout",18.,18.666700000000002,36.,"{36., 21., 19., 18., 19., 18., 19., 19., 19., 18., 19., 19., 18., 19., 18., 18., 19., 18., 18., 19., 19., 18., 18., 18., 19., 21., 23., 18., 19., 19., 18., 18., 19., 19., 18., 19., 19., 19., 18., 18., 18., 19., 19., 19., 19., 19., 18., 18., 19., 19.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",855,856,1,50,"encoder/12/1/add","encoder/12/1/norm","encoder/12/1/add-encoder/12/1/norm","Threading","Normalization","Threading-Normalization",160.,162.5667,217.,"{217., 166., 164., 164., 162., 161., 162., 163., 161., 173., 163., 163., 162., 163., 161., 161., 178., 165., 162., 161., 184., 164., 162., 161., 162., 176., 165., 161., 161., 163., 162., 162., 163., 162., 162., 162., 190., 165., 162., 161., 163., 161., 161., 189., 164., 162., 162., 162., 160., 163.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",857,857,0,50,"encoder/12/2/linear1/Net","encoder/12/2/linear1/Net","encoder/12/2/linear1/Net","Linear","Linear","Linear",440.,444.5,767.,"{767., 717., 504., 490., 453., 442., 442., 441., 452., 443., 442., 459., 479., 442., 441., 441., 440., 441., 467., 444., 442., 469., 441., 441., 441., 441., 442., 442., 441., 440., 476., 443., 441., 448., 442., 440., 442., 442., 467., 446., 460., 445., 442., 441., 441., 449., 443., 467., 442., 441.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",858,858,0,50,"encoder/12/2/gelu","encoder/12/2/gelu","encoder/12/2/gelu","Elementwise","Elementwise","Elementwise",104.,105.1667,144.,"{144., 108., 106., 105., 105., 105., 105., 105., 105., 106., 105., 105., 105., 104., 105., 105., 106., 105., 106., 106., 105., 105., 105., 106., 105., 105., 105., 105., 105., 105., 105., 106., 127., 108., 114., 105., 105., 105., 105., 106., 105., 105., 105., 105., 105., 105., 105., 105., 122., 109.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",859,859,0,50,"encoder/12/2/linear2/Net","encoder/12/2/linear2/Net","encoder/12/2/linear2/Net","Linear","Linear","Linear",431.,436.6333,544.,"{544., 512., 452., 436., 443., 433., 433., 439., 433., 432., 432., 432., 431., 432., 432., 458., 459., 433., 432., 431., 433., 432., 431., 431., 433., 467., 448., 434., 445., 434., 436., 432., 433., 434., 463., 438., 437., 448., 437., 436., 439., 436., 436., 463., 457., 435., 436., 439., 448., 438.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",860,860,0,50,"encoder/12/2/dropout","encoder/12/2/dropout","encoder/12/2/dropout","Dropout","Dropout","Dropout",18.,18.2,42.,"{42., 22., 19., 19., 18., 19., 18., 19., 18., 18., 18., 19., 19., 18., 18., 19., 18., 18., 18., 18., 18., 18., 19., 18., 18., 18., 19., 19., 18., 18., 18., 18., 19., 19., 18., 18., 18., 18., 18., 19., 18., 18., 18., 19., 18., 18., 18., 18., 18., 18.}"
"BERT Trained on BookCorpus and English Wikipedia Data","c5.large",861,862,1,50,"encoder/12/2/add","encoder/12/2/norm","encoder/12/2/add-encoder/12/2/norm","Threading","Normalization","Threading-Normalization",161.,163.26670000000001,220.,"{220., 167., 163., 186., 166., 164., 162., 162., 163., 163., 162., 162., 162., 162., 162., 162., 162., 187., 166., 163., 163., 162., 163., 162., 163., 163., 162., 162., 163., 163., 170., 164., 163., 162., 163., 163., 163., 162., 161., 162., 163., 195., 170., 167., 164., 166., 165., 165., 166., 165.}"
